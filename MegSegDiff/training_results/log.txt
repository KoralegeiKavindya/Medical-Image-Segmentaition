Logging to ./training_results2/
creating data loader...
creating model and diffusion...
training...
---------------------------
| grad_norm    | 20.3     |
| loss         | 1.04     |
| loss_cal     | 0.194    |
| loss_cal_q0  | 0.194    |
| loss_diff    | 1.04     |
| loss_diff_q0 | 1.04     |
| loss_q0      | 1.04     |
| param_norm   | 227      |
| samples      | 1        |
| step         | 0        |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 16.3     |
| loss         | 1.02     |
| loss_cal     | 0.179    |
| loss_cal_q1  | 0.179    |
| loss_diff    | 1.02     |
| loss_diff_q1 | 1.02     |
| loss_q1      | 1.02     |
| param_norm   | 227      |
| samples      | 2        |
| step         | 1        |
---------------------------
---------------------------
| grad_norm    | 19.2     |
| loss         | 1.02     |
| loss_cal     | 0.172    |
| loss_cal_q0  | 0.172    |
| loss_diff    | 1.02     |
| loss_diff_q0 | 1.02     |
| loss_q0      | 1.02     |
| param_norm   | 227      |
| samples      | 3        |
| step         | 2        |
---------------------------
---------------------------
| grad_norm    | 12.5     |
| loss         | 1.03     |
| loss_cal     | 0.176    |
| loss_cal_q0  | 0.176    |
| loss_diff    | 1.03     |
| loss_diff_q0 | 1.03     |
| loss_q0      | 1.03     |
| param_norm   | 227      |
| samples      | 4        |
| step         | 3        |
---------------------------
---------------------------
| grad_norm    | 18.1     |
| loss         | 0.961    |
| loss_cal     | 0.201    |
| loss_cal_q2  | 0.201    |
| loss_diff    | 0.961    |
| loss_diff_q2 | 0.961    |
| loss_q2      | 0.961    |
| param_norm   | 227      |
| samples      | 5        |
| step         | 4        |
---------------------------
---------------------------
| grad_norm    | 17       |
| loss         | 1.01     |
| loss_cal     | 0.194    |
| loss_cal_q2  | 0.194    |
| loss_diff    | 1.01     |
| loss_diff_q2 | 1.01     |
| loss_q2      | 1.01     |
| param_norm   | 227      |
| samples      | 6        |
| step         | 5        |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 16.2     |
| loss         | 0.996    |
| loss_cal     | 0.182    |
| loss_cal_q3  | 0.182    |
| loss_diff    | 0.996    |
| loss_diff_q3 | 0.996    |
| loss_q3      | 0.996    |
| param_norm   | 227      |
| samples      | 7        |
| step         | 6        |
---------------------------
---------------------------
| grad_norm    | 735      |
| loss         | 1        |
| loss_cal     | 0.173    |
| loss_cal_q2  | 0.173    |
| loss_diff    | 1        |
| loss_diff_q2 | 1        |
| loss_q2      | 1        |
| param_norm   | 227      |
| samples      | 8        |
| step         | 7        |
---------------------------
---------------------------
| grad_norm    | 12.6     |
| loss         | 0.998    |
| loss_cal     | 0.177    |
| loss_cal_q0  | 0.177    |
| loss_diff    | 0.998    |
| loss_diff_q0 | 0.998    |
| loss_q0      | 0.998    |
| param_norm   | 227      |
| samples      | 9        |
| step         | 8        |
---------------------------
---------------------------
| grad_norm    | 13.3     |
| loss         | 1        |
| loss_cal     | 0.182    |
| loss_cal_q3  | 0.182    |
| loss_diff    | 1        |
| loss_diff_q3 | 1        |
| loss_q3      | 1        |
| param_norm   | 227      |
| samples      | 10       |
| step         | 9        |
---------------------------
---------------------------
| grad_norm    | 17.3     |
| loss         | 0.962    |
| loss_cal     | 0.175    |
| loss_cal_q3  | 0.175    |
| loss_diff    | 0.962    |
| loss_diff_q3 | 0.962    |
| loss_q3      | 0.962    |
| param_norm   | 227      |
| samples      | 11       |
| step         | 10       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 15       |
| loss         | 0.981    |
| loss_cal     | 0.17     |
| loss_cal_q3  | 0.17     |
| loss_diff    | 0.981    |
| loss_diff_q3 | 0.981    |
| loss_q3      | 0.981    |
| param_norm   | 227      |
| samples      | 12       |
| step         | 11       |
---------------------------
---------------------------
| grad_norm    | 14.9     |
| loss         | 0.97     |
| loss_cal     | 0.18     |
| loss_cal_q3  | 0.18     |
| loss_diff    | 0.97     |
| loss_diff_q3 | 0.97     |
| loss_q3      | 0.97     |
| param_norm   | 227      |
| samples      | 13       |
| step         | 12       |
---------------------------
---------------------------
| grad_norm    | 924      |
| loss         | 0.977    |
| loss_cal     | 0.166    |
| loss_cal_q2  | 0.166    |
| loss_diff    | 0.977    |
| loss_diff_q2 | 0.977    |
| loss_q2      | 0.977    |
| param_norm   | 227      |
| samples      | 14       |
| step         | 13       |
---------------------------
---------------------------
| grad_norm    | 14.7     |
| loss         | 0.992    |
| loss_cal     | 0.176    |
| loss_cal_q1  | 0.176    |
| loss_diff    | 0.992    |
| loss_diff_q1 | 0.992    |
| loss_q1      | 0.992    |
| param_norm   | 227      |
| samples      | 15       |
| step         | 14       |
---------------------------
---------------------------
| grad_norm    | 11.2     |
| loss         | 0.957    |
| loss_cal     | 0.172    |
| loss_cal_q3  | 0.172    |
| loss_diff    | 0.957    |
| loss_diff_q3 | 0.957    |
| loss_q3      | 0.957    |
| param_norm   | 227      |
| samples      | 16       |
| step         | 15       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 622      |
| loss         | 0.951    |
| loss_cal     | 0.165    |
| loss_cal_q3  | 0.165    |
| loss_diff    | 0.951    |
| loss_diff_q3 | 0.951    |
| loss_q3      | 0.951    |
| param_norm   | 227      |
| samples      | 17       |
| step         | 16       |
---------------------------
---------------------------
| grad_norm    | 357      |
| loss         | 0.898    |
| loss_cal     | 0.166    |
| loss_cal_q2  | 0.166    |
| loss_diff    | 0.898    |
| loss_diff_q2 | 0.898    |
| loss_q2      | 0.898    |
| param_norm   | 227      |
| samples      | 18       |
| step         | 17       |
---------------------------
---------------------------
| grad_norm    | 11.2     |
| loss         | 1        |
| loss_cal     | 0.164    |
| loss_cal_q0  | 0.164    |
| loss_diff    | 1        |
| loss_diff_q0 | 1        |
| loss_q0      | 1        |
| param_norm   | 227      |
| samples      | 19       |
| step         | 18       |
---------------------------
---------------------------
| grad_norm    | 12.6     |
| loss         | 1.01     |
| loss_cal     | 0.173    |
| loss_cal_q1  | 0.173    |
| loss_diff    | 1.01     |
| loss_diff_q1 | 1.01     |
| loss_q1      | 1.01     |
| param_norm   | 227      |
| samples      | 20       |
| step         | 19       |
---------------------------
---------------------------
| grad_norm    | 11.5     |
| loss         | 1        |
| loss_cal     | 0.173    |
| loss_cal_q3  | 0.173    |
| loss_diff    | 1        |
| loss_diff_q3 | 1        |
| loss_q3      | 1        |
| param_norm   | 227      |
| samples      | 21       |
| step         | 20       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 9.86     |
| loss         | 0.955    |
| loss_cal     | 0.161    |
| loss_cal_q0  | 0.161    |
| loss_diff    | 0.955    |
| loss_diff_q0 | 0.955    |
| loss_q0      | 0.955    |
| param_norm   | 227      |
| samples      | 22       |
| step         | 21       |
---------------------------
---------------------------
| grad_norm    | 11.9     |
| loss         | 0.988    |
| loss_cal     | 0.161    |
| loss_cal_q1  | 0.161    |
| loss_diff    | 0.988    |
| loss_diff_q1 | 0.988    |
| loss_q1      | 0.988    |
| param_norm   | 227      |
| samples      | 23       |
| step         | 22       |
---------------------------
---------------------------
| grad_norm    | 629      |
| loss         | 0.863    |
| loss_cal     | 0.163    |
| loss_cal_q1  | 0.163    |
| loss_diff    | 0.863    |
| loss_diff_q1 | 0.863    |
| loss_q1      | 0.863    |
| param_norm   | 227      |
| samples      | 24       |
| step         | 23       |
---------------------------
---------------------------
| grad_norm    | 7.51     |
| loss         | 1.01     |
| loss_cal     | 0.165    |
| loss_cal_q3  | 0.165    |
| loss_diff    | 1.01     |
| loss_diff_q3 | 1.01     |
| loss_q3      | 1.01     |
| param_norm   | 227      |
| samples      | 25       |
| step         | 24       |
---------------------------
---------------------------
| grad_norm    | 18       |
| loss         | 1.02     |
| loss_cal     | 0.184    |
| loss_cal_q2  | 0.184    |
| loss_diff    | 1.02     |
| loss_diff_q2 | 1.02     |
| loss_q2      | 1.02     |
| param_norm   | 227      |
| samples      | 26       |
| step         | 25       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 9.72     |
| loss         | 0.94     |
| loss_cal     | 0.173    |
| loss_cal_q2  | 0.173    |
| loss_diff    | 0.94     |
| loss_diff_q2 | 0.94     |
| loss_q2      | 0.94     |
| param_norm   | 227      |
| samples      | 27       |
| step         | 26       |
---------------------------
---------------------------
| grad_norm    | 9.78     |
| loss         | 0.989    |
| loss_cal     | 0.158    |
| loss_cal_q2  | 0.158    |
| loss_diff    | 0.989    |
| loss_diff_q2 | 0.989    |
| loss_q2      | 0.989    |
| param_norm   | 227      |
| samples      | 28       |
| step         | 27       |
---------------------------
---------------------------
| grad_norm    | 10       |
| loss         | 1.03     |
| loss_cal     | 0.16     |
| loss_cal_q0  | 0.16     |
| loss_diff    | 1.03     |
| loss_diff_q0 | 1.03     |
| loss_q0      | 1.03     |
| param_norm   | 227      |
| samples      | 29       |
| step         | 28       |
---------------------------
---------------------------
| grad_norm    | 382      |
| loss         | 0.994    |
| loss_cal     | 0.162    |
| loss_cal_q0  | 0.162    |
| loss_diff    | 0.994    |
| loss_diff_q0 | 0.994    |
| loss_q0      | 0.994    |
| param_norm   | 227      |
| samples      | 30       |
| step         | 29       |
---------------------------
---------------------------
| grad_norm    | 10.5     |
| loss         | 1.03     |
| loss_cal     | 0.167    |
| loss_cal_q2  | 0.167    |
| loss_diff    | 1.03     |
| loss_diff_q2 | 1.03     |
| loss_q2      | 1.03     |
| param_norm   | 227      |
| samples      | 31       |
| step         | 30       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 12.4     |
| loss         | 0.959    |
| loss_cal     | 0.158    |
| loss_cal_q2  | 0.158    |
| loss_diff    | 0.959    |
| loss_diff_q2 | 0.959    |
| loss_q2      | 0.959    |
| param_norm   | 227      |
| samples      | 32       |
| step         | 31       |
---------------------------
---------------------------
| grad_norm    | 10.4     |
| loss         | 0.989    |
| loss_cal     | 0.158    |
| loss_cal_q0  | 0.158    |
| loss_diff    | 0.989    |
| loss_diff_q0 | 0.989    |
| loss_q0      | 0.989    |
| param_norm   | 227      |
| samples      | 33       |
| step         | 32       |
---------------------------
---------------------------
| grad_norm    | 12       |
| loss         | 1.01     |
| loss_cal     | 0.16     |
| loss_cal_q2  | 0.16     |
| loss_diff    | 1.01     |
| loss_diff_q2 | 1.01     |
| loss_q2      | 1.01     |
| param_norm   | 227      |
| samples      | 34       |
| step         | 33       |
---------------------------
---------------------------
| grad_norm    | 10.2     |
| loss         | 0.954    |
| loss_cal     | 0.148    |
| loss_cal_q0  | 0.148    |
| loss_diff    | 0.954    |
| loss_diff_q0 | 0.954    |
| loss_q0      | 0.954    |
| param_norm   | 227      |
| samples      | 35       |
| step         | 34       |
---------------------------
---------------------------
| grad_norm    | 10.8     |
| loss         | 0.955    |
| loss_cal     | 0.155    |
| loss_cal_q1  | 0.155    |
| loss_diff    | 0.955    |
| loss_diff_q1 | 0.955    |
| loss_q1      | 0.955    |
| param_norm   | 227      |
| samples      | 36       |
| step         | 35       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 9.11     |
| loss         | 1.05     |
| loss_cal     | 0.155    |
| loss_cal_q0  | 0.155    |
| loss_diff    | 1.05     |
| loss_diff_q0 | 1.05     |
| loss_q0      | 1.05     |
| param_norm   | 227      |
| samples      | 37       |
| step         | 36       |
---------------------------
---------------------------
| grad_norm    | 7.27     |
| loss         | 1.03     |
| loss_cal     | 0.152    |
| loss_cal_q1  | 0.152    |
| loss_diff    | 1.03     |
| loss_diff_q1 | 1.03     |
| loss_q1      | 1.03     |
| param_norm   | 227      |
| samples      | 38       |
| step         | 37       |
---------------------------
---------------------------
| grad_norm    | 11.3     |
| loss         | 1.03     |
| loss_cal     | 0.162    |
| loss_cal_q0  | 0.162    |
| loss_diff    | 1.03     |
| loss_diff_q0 | 1.03     |
| loss_q0      | 1.03     |
| param_norm   | 227      |
| samples      | 39       |
| step         | 38       |
---------------------------
---------------------------
| grad_norm    | 8.58     |
| loss         | 0.964    |
| loss_cal     | 0.144    |
| loss_cal_q1  | 0.144    |
| loss_diff    | 0.964    |
| loss_diff_q1 | 0.964    |
| loss_q1      | 0.964    |
| param_norm   | 227      |
| samples      | 40       |
| step         | 39       |
---------------------------
---------------------------
| grad_norm    | 9.81     |
| loss         | 0.987    |
| loss_cal     | 0.143    |
| loss_cal_q1  | 0.143    |
| loss_diff    | 0.987    |
| loss_diff_q1 | 0.987    |
| loss_q1      | 0.987    |
| param_norm   | 227      |
| samples      | 41       |
| step         | 40       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 8.14     |
| loss         | 0.985    |
| loss_cal     | 0.144    |
| loss_cal_q2  | 0.144    |
| loss_diff    | 0.985    |
| loss_diff_q2 | 0.985    |
| loss_q2      | 0.985    |
| param_norm   | 227      |
| samples      | 42       |
| step         | 41       |
---------------------------
---------------------------
| grad_norm    | 8.34     |
| loss         | 1.01     |
| loss_cal     | 0.145    |
| loss_cal_q1  | 0.145    |
| loss_diff    | 1.01     |
| loss_diff_q1 | 1.01     |
| loss_q1      | 1.01     |
| param_norm   | 227      |
| samples      | 43       |
| step         | 42       |
---------------------------
---------------------------
| grad_norm    | 452      |
| loss         | 0.713    |
| loss_cal     | 0.15     |
| loss_cal_q3  | 0.15     |
| loss_diff    | 0.713    |
| loss_diff_q3 | 0.713    |
| loss_q3      | 0.713    |
| param_norm   | 227      |
| samples      | 44       |
| step         | 43       |
---------------------------
---------------------------
| grad_norm    | 8.33     |
| loss         | 0.972    |
| loss_cal     | 0.148    |
| loss_cal_q2  | 0.148    |
| loss_diff    | 0.972    |
| loss_diff_q2 | 0.972    |
| loss_q2      | 0.972    |
| param_norm   | 227      |
| samples      | 45       |
| step         | 44       |
---------------------------
---------------------------
| grad_norm    | 7.5      |
| loss         | 0.98     |
| loss_cal     | 0.143    |
| loss_cal_q1  | 0.143    |
| loss_diff    | 0.98     |
| loss_diff_q1 | 0.98     |
| loss_q1      | 0.98     |
| param_norm   | 227      |
| samples      | 46       |
| step         | 45       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 237      |
| loss         | 0.651    |
| loss_cal     | 0.15     |
| loss_cal_q1  | 0.15     |
| loss_diff    | 0.651    |
| loss_diff_q1 | 0.651    |
| loss_q1      | 0.651    |
| param_norm   | 227      |
| samples      | 47       |
| step         | 46       |
---------------------------
---------------------------
| grad_norm    | 6.64     |
| loss         | 1.03     |
| loss_cal     | 0.141    |
| loss_cal_q0  | 0.141    |
| loss_diff    | 1.03     |
| loss_diff_q0 | 1.03     |
| loss_q0      | 1.03     |
| param_norm   | 227      |
| samples      | 48       |
| step         | 47       |
---------------------------
---------------------------
| grad_norm    | 7.22     |
| loss         | 0.987    |
| loss_cal     | 0.145    |
| loss_cal_q3  | 0.145    |
| loss_diff    | 0.987    |
| loss_diff_q3 | 0.987    |
| loss_q3      | 0.987    |
| param_norm   | 227      |
| samples      | 49       |
| step         | 48       |
---------------------------
---------------------------
| grad_norm    | 9.35     |
| loss         | 1.02     |
| loss_cal     | 0.155    |
| loss_cal_q0  | 0.155    |
| loss_diff    | 1.02     |
| loss_diff_q0 | 1.02     |
| loss_q0      | 1.02     |
| param_norm   | 227      |
| samples      | 50       |
| step         | 49       |
---------------------------
---------------------------
| grad_norm    | 6.23     |
| loss         | 0.991    |
| loss_cal     | 0.137    |
| loss_cal_q2  | 0.137    |
| loss_diff    | 0.991    |
| loss_diff_q2 | 0.991    |
| loss_q2      | 0.991    |
| param_norm   | 227      |
| samples      | 51       |
| step         | 50       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 7.87     |
| loss         | 0.962    |
| loss_cal     | 0.144    |
| loss_cal_q2  | 0.144    |
| loss_diff    | 0.962    |
| loss_diff_q2 | 0.962    |
| loss_q2      | 0.962    |
| param_norm   | 227      |
| samples      | 52       |
| step         | 51       |
---------------------------
---------------------------
| grad_norm    | 6.95     |
| loss         | 0.989    |
| loss_cal     | 0.136    |
| loss_cal_q0  | 0.136    |
| loss_diff    | 0.989    |
| loss_diff_q0 | 0.989    |
| loss_q0      | 0.989    |
| param_norm   | 227      |
| samples      | 53       |
| step         | 52       |
---------------------------
---------------------------
| grad_norm    | 392      |
| loss         | 0.537    |
| loss_cal     | 0.143    |
| loss_cal_q1  | 0.143    |
| loss_diff    | 0.537    |
| loss_diff_q1 | 0.537    |
| loss_q1      | 0.537    |
| param_norm   | 227      |
| samples      | 54       |
| step         | 53       |
---------------------------
---------------------------
| grad_norm    | 6.5      |
| loss         | 0.949    |
| loss_cal     | 0.13     |
| loss_cal_q2  | 0.13     |
| loss_diff    | 0.949    |
| loss_diff_q2 | 0.949    |
| loss_q2      | 0.949    |
| param_norm   | 227      |
| samples      | 55       |
| step         | 54       |
---------------------------
---------------------------
| grad_norm    | 6.19     |
| loss         | 1.02     |
| loss_cal     | 0.136    |
| loss_cal_q0  | 0.136    |
| loss_diff    | 1.02     |
| loss_diff_q0 | 1.02     |
| loss_q0      | 1.02     |
| param_norm   | 227      |
| samples      | 56       |
| step         | 55       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 7.98     |
| loss         | 1.02     |
| loss_cal     | 0.143    |
| loss_cal_q3  | 0.143    |
| loss_diff    | 1.02     |
| loss_diff_q3 | 1.02     |
| loss_q3      | 1.02     |
| param_norm   | 227      |
| samples      | 57       |
| step         | 56       |
---------------------------
---------------------------
| grad_norm    | 8.21     |
| loss         | 1.01     |
| loss_cal     | 0.137    |
| loss_cal_q3  | 0.137    |
| loss_diff    | 1.01     |
| loss_diff_q3 | 1.01     |
| loss_q3      | 1.01     |
| param_norm   | 227      |
| samples      | 58       |
| step         | 57       |
---------------------------
---------------------------
| grad_norm    | 7.76     |
| loss         | 1.02     |
| loss_cal     | 0.142    |
| loss_cal_q1  | 0.142    |
| loss_diff    | 1.02     |
| loss_diff_q1 | 1.02     |
| loss_q1      | 1.02     |
| param_norm   | 227      |
| samples      | 59       |
| step         | 58       |
---------------------------
---------------------------
| grad_norm    | 6.85     |
| loss         | 0.978    |
| loss_cal     | 0.134    |
| loss_cal_q2  | 0.134    |
| loss_diff    | 0.978    |
| loss_diff_q2 | 0.978    |
| loss_q2      | 0.978    |
| param_norm   | 227      |
| samples      | 60       |
| step         | 59       |
---------------------------
---------------------------
| grad_norm    | 137      |
| loss         | 0.547    |
| loss_cal     | 0.133    |
| loss_cal_q0  | 0.133    |
| loss_diff    | 0.547    |
| loss_diff_q0 | 0.547    |
| loss_q0      | 0.547    |
| param_norm   | 227      |
| samples      | 61       |
| step         | 60       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 6.29     |
| loss         | 0.97     |
| loss_cal     | 0.141    |
| loss_cal_q0  | 0.141    |
| loss_diff    | 0.97     |
| loss_diff_q0 | 0.97     |
| loss_q0      | 0.97     |
| param_norm   | 227      |
| samples      | 62       |
| step         | 61       |
---------------------------
---------------------------
| grad_norm    | 7.73     |
| loss         | 1.01     |
| loss_cal     | 0.142    |
| loss_cal_q3  | 0.142    |
| loss_diff    | 1.01     |
| loss_diff_q3 | 1.01     |
| loss_q3      | 1.01     |
| param_norm   | 227      |
| samples      | 63       |
| step         | 62       |
---------------------------
---------------------------
| grad_norm    | 5.55     |
| loss         | 0.995    |
| loss_cal     | 0.124    |
| loss_cal_q2  | 0.124    |
| loss_diff    | 0.995    |
| loss_diff_q2 | 0.995    |
| loss_q2      | 0.995    |
| param_norm   | 227      |
| samples      | 64       |
| step         | 63       |
---------------------------
---------------------------
| grad_norm    | 7.22     |
| loss         | 0.996    |
| loss_cal     | 0.143    |
| loss_cal_q1  | 0.143    |
| loss_diff    | 0.996    |
| loss_diff_q1 | 0.996    |
| loss_q1      | 0.996    |
| param_norm   | 227      |
| samples      | 65       |
| step         | 64       |
---------------------------
---------------------------
| grad_norm    | 12.7     |
| loss         | 1.02     |
| loss_cal     | 0.16     |
| loss_cal_q2  | 0.16     |
| loss_diff    | 1.02     |
| loss_diff_q2 | 1.02     |
| loss_q2      | 1.02     |
| param_norm   | 227      |
| samples      | 66       |
| step         | 65       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 125      |
| loss         | 0.373    |
| loss_cal     | 0.13     |
| loss_cal_q1  | 0.13     |
| loss_diff    | 0.373    |
| loss_diff_q1 | 0.373    |
| loss_q1      | 0.373    |
| param_norm   | 227      |
| samples      | 67       |
| step         | 66       |
---------------------------
---------------------------
| grad_norm    | 6.95     |
| loss         | 0.987    |
| loss_cal     | 0.13     |
| loss_cal_q0  | 0.13     |
| loss_diff    | 0.987    |
| loss_diff_q0 | 0.987    |
| loss_q0      | 0.987    |
| param_norm   | 227      |
| samples      | 68       |
| step         | 67       |
---------------------------
---------------------------
| grad_norm    | 5.98     |
| loss         | 0.991    |
| loss_cal     | 0.124    |
| loss_cal_q0  | 0.124    |
| loss_diff    | 0.991    |
| loss_diff_q0 | 0.991    |
| loss_q0      | 0.991    |
| param_norm   | 227      |
| samples      | 69       |
| step         | 68       |
---------------------------
---------------------------
| grad_norm    | 5.08     |
| loss         | 1.02     |
| loss_cal     | 0.119    |
| loss_cal_q0  | 0.119    |
| loss_diff    | 1.02     |
| loss_diff_q0 | 1.02     |
| loss_q0      | 1.02     |
| param_norm   | 227      |
| samples      | 70       |
| step         | 69       |
---------------------------
---------------------------
| grad_norm    | 8.79     |
| loss         | 0.996    |
| loss_cal     | 0.141    |
| loss_cal_q3  | 0.141    |
| loss_diff    | 0.996    |
| loss_diff_q3 | 0.996    |
| loss_q3      | 0.996    |
| param_norm   | 227      |
| samples      | 71       |
| step         | 70       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.97     |
| loss         | 1        |
| loss_cal     | 0.121    |
| loss_cal_q1  | 0.121    |
| loss_diff    | 1        |
| loss_diff_q1 | 1        |
| loss_q1      | 1        |
| param_norm   | 227      |
| samples      | 72       |
| step         | 71       |
---------------------------
---------------------------
| grad_norm    | 5.72     |
| loss         | 1.02     |
| loss_cal     | 0.118    |
| loss_cal_q0  | 0.118    |
| loss_diff    | 1.02     |
| loss_diff_q0 | 1.02     |
| loss_q0      | 1.02     |
| param_norm   | 227      |
| samples      | 73       |
| step         | 72       |
---------------------------
---------------------------
| grad_norm    | 92.3     |
| loss         | 0.327    |
| loss_cal     | 0.127    |
| loss_cal_q1  | 0.127    |
| loss_diff    | 0.327    |
| loss_diff_q1 | 0.327    |
| loss_q1      | 0.327    |
| param_norm   | 227      |
| samples      | 74       |
| step         | 73       |
---------------------------
---------------------------
| grad_norm    | 8.38     |
| loss         | 1.01     |
| loss_cal     | 0.136    |
| loss_cal_q1  | 0.136    |
| loss_diff    | 1.01     |
| loss_diff_q1 | 1.01     |
| loss_q1      | 1.01     |
| param_norm   | 227      |
| samples      | 75       |
| step         | 74       |
---------------------------
---------------------------
| grad_norm    | 5.63     |
| loss         | 1        |
| loss_cal     | 0.119    |
| loss_cal_q3  | 0.119    |
| loss_diff    | 1        |
| loss_diff_q3 | 1        |
| loss_q3      | 1        |
| param_norm   | 227      |
| samples      | 76       |
| step         | 75       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 6.06     |
| loss         | 0.97     |
| loss_cal     | 0.121    |
| loss_cal_q3  | 0.121    |
| loss_diff    | 0.97     |
| loss_diff_q3 | 0.97     |
| loss_q3      | 0.97     |
| param_norm   | 227      |
| samples      | 77       |
| step         | 76       |
---------------------------
---------------------------
| grad_norm    | 7.85     |
| loss         | 1.01     |
| loss_cal     | 0.143    |
| loss_cal_q2  | 0.143    |
| loss_diff    | 1.01     |
| loss_diff_q2 | 1.01     |
| loss_q2      | 1.01     |
| param_norm   | 227      |
| samples      | 78       |
| step         | 77       |
---------------------------
---------------------------
| grad_norm    | 4.1      |
| loss         | 0.982    |
| loss_cal     | 0.105    |
| loss_cal_q2  | 0.105    |
| loss_diff    | 0.982    |
| loss_diff_q2 | 0.982    |
| loss_q2      | 0.982    |
| param_norm   | 227      |
| samples      | 79       |
| step         | 78       |
---------------------------
---------------------------
| grad_norm    | 7.54     |
| loss         | 1        |
| loss_cal     | 0.141    |
| loss_cal_q0  | 0.141    |
| loss_diff    | 1        |
| loss_diff_q0 | 1        |
| loss_q0      | 1        |
| param_norm   | 227      |
| samples      | 80       |
| step         | 79       |
---------------------------
---------------------------
| grad_norm    | 6.08     |
| loss         | 0.973    |
| loss_cal     | 0.122    |
| loss_cal_q3  | 0.122    |
| loss_diff    | 0.973    |
| loss_diff_q3 | 0.973    |
| loss_q3      | 0.973    |
| param_norm   | 227      |
| samples      | 81       |
| step         | 80       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 132      |
| loss         | 0.247    |
| loss_cal     | 0.123    |
| loss_cal_q1  | 0.123    |
| loss_diff    | 0.247    |
| loss_diff_q1 | 0.247    |
| loss_q1      | 0.247    |
| param_norm   | 227      |
| samples      | 82       |
| step         | 81       |
---------------------------
---------------------------
| grad_norm    | 4.88     |
| loss         | 0.993    |
| loss_cal     | 0.119    |
| loss_cal_q1  | 0.119    |
| loss_diff    | 0.993    |
| loss_diff_q1 | 0.993    |
| loss_q1      | 0.993    |
| param_norm   | 227      |
| samples      | 83       |
| step         | 82       |
---------------------------
---------------------------
| grad_norm    | 5.45     |
| loss         | 1.01     |
| loss_cal     | 0.125    |
| loss_cal_q0  | 0.125    |
| loss_diff    | 1.01     |
| loss_diff_q0 | 1.01     |
| loss_q0      | 1.01     |
| param_norm   | 227      |
| samples      | 84       |
| step         | 83       |
---------------------------
---------------------------
| grad_norm    | 4.42     |
| loss         | 1.03     |
| loss_cal     | 0.105    |
| loss_cal_q1  | 0.105    |
| loss_diff    | 1.03     |
| loss_diff_q1 | 1.03     |
| loss_q1      | 1.03     |
| param_norm   | 227      |
| samples      | 85       |
| step         | 84       |
---------------------------
---------------------------
| grad_norm    | 4.61     |
| loss         | 1.02     |
| loss_cal     | 0.112    |
| loss_cal_q2  | 0.112    |
| loss_diff    | 1.02     |
| loss_diff_q2 | 1.02     |
| loss_q2      | 1.02     |
| param_norm   | 227      |
| samples      | 86       |
| step         | 85       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 5.27     |
| loss         | 0.985    |
| loss_cal     | 0.118    |
| loss_cal_q2  | 0.118    |
| loss_diff    | 0.985    |
| loss_diff_q2 | 0.985    |
| loss_q2      | 0.985    |
| param_norm   | 227      |
| samples      | 87       |
| step         | 86       |
---------------------------
---------------------------
| grad_norm    | 4.34     |
| loss         | 1        |
| loss_cal     | 0.112    |
| loss_cal_q2  | 0.112    |
| loss_diff    | 1        |
| loss_diff_q2 | 1        |
| loss_q2      | 1        |
| param_norm   | 227      |
| samples      | 88       |
| step         | 87       |
---------------------------
---------------------------
| grad_norm    | 4.8      |
| loss         | 1.04     |
| loss_cal     | 0.112    |
| loss_cal_q0  | 0.112    |
| loss_diff    | 1.04     |
| loss_diff_q0 | 1.04     |
| loss_q0      | 1.04     |
| param_norm   | 227      |
| samples      | 89       |
| step         | 88       |
---------------------------
---------------------------
| grad_norm    | 4.81     |
| loss         | 0.988    |
| loss_cal     | 0.111    |
| loss_cal_q0  | 0.111    |
| loss_diff    | 0.988    |
| loss_diff_q0 | 0.988    |
| loss_q0      | 0.988    |
| param_norm   | 227      |
| samples      | 90       |
| step         | 89       |
---------------------------
---------------------------
| grad_norm    | 5.04     |
| loss         | 0.977    |
| loss_cal     | 0.11     |
| loss_cal_q1  | 0.11     |
| loss_diff    | 0.977    |
| loss_diff_q1 | 0.977    |
| loss_q1      | 0.977    |
| param_norm   | 227      |
| samples      | 91       |
| step         | 90       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 5.18     |
| loss         | 0.975    |
| loss_cal     | 0.13     |
| loss_cal_q1  | 0.13     |
| loss_diff    | 0.975    |
| loss_diff_q1 | 0.975    |
| loss_q1      | 0.975    |
| param_norm   | 227      |
| samples      | 92       |
| step         | 91       |
---------------------------
---------------------------
| grad_norm    | 4.78     |
| loss         | 0.99     |
| loss_cal     | 0.12     |
| loss_cal_q3  | 0.12     |
| loss_diff    | 0.99     |
| loss_diff_q3 | 0.99     |
| loss_q3      | 0.99     |
| param_norm   | 227      |
| samples      | 93       |
| step         | 92       |
---------------------------
---------------------------
| grad_norm    | 5.21     |
| loss         | 0.475    |
| loss_cal     | 0.104    |
| loss_cal_q0  | 0.104    |
| loss_diff    | 0.475    |
| loss_diff_q0 | 0.475    |
| loss_q0      | 0.475    |
| param_norm   | 227      |
| samples      | 94       |
| step         | 93       |
---------------------------
---------------------------
| grad_norm    | 4.4      |
| loss         | 1.01     |
| loss_cal     | 0.11     |
| loss_cal_q3  | 0.11     |
| loss_diff    | 1.01     |
| loss_diff_q3 | 1.01     |
| loss_q3      | 1.01     |
| param_norm   | 227      |
| samples      | 95       |
| step         | 94       |
---------------------------
---------------------------
| grad_norm    | 4.97     |
| loss         | 0.952    |
| loss_cal     | 0.122    |
| loss_cal_q0  | 0.122    |
| loss_diff    | 0.952    |
| loss_diff_q0 | 0.952    |
| loss_q0      | 0.952    |
| param_norm   | 227      |
| samples      | 96       |
| step         | 95       |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.23     |
| loss         | 0.955    |
| loss_cal     | 0.106    |
| loss_cal_q0  | 0.106    |
| loss_diff    | 0.955    |
| loss_diff_q0 | 0.955    |
| loss_q0      | 0.955    |
| param_norm   | 227      |
| samples      | 97       |
| step         | 96       |
---------------------------
---------------------------
| grad_norm    | 5.77     |
| loss         | 0.979    |
| loss_cal     | 0.121    |
| loss_cal_q3  | 0.121    |
| loss_diff    | 0.979    |
| loss_diff_q3 | 0.979    |
| loss_q3      | 0.979    |
| param_norm   | 227      |
| samples      | 98       |
| step         | 97       |
---------------------------
---------------------------
| grad_norm    | 4.2      |
| loss         | 0.981    |
| loss_cal     | 0.107    |
| loss_cal_q2  | 0.107    |
| loss_diff    | 0.981    |
| loss_diff_q2 | 0.981    |
| loss_q2      | 0.981    |
| param_norm   | 227      |
| samples      | 99       |
| step         | 98       |
---------------------------
---------------------------
| grad_norm    | 147      |
| loss         | 0.175    |
| loss_cal     | 0.114    |
| loss_cal_q3  | 0.114    |
| loss_diff    | 0.175    |
| loss_diff_q3 | 0.175    |
| loss_q3      | 0.175    |
| param_norm   | 227      |
| samples      | 100      |
| step         | 99       |
---------------------------
---------------------------
| grad_norm    | 4.43     |
| loss         | 1.01     |
| loss_cal     | 0.11     |
| loss_cal_q0  | 0.11     |
| loss_diff    | 1.01     |
| loss_diff_q0 | 1.01     |
| loss_q0      | 1.01     |
| param_norm   | 227      |
| samples      | 101      |
| step         | 100      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.83     |
| loss         | 0.994    |
| loss_cal     | 0.12     |
| loss_cal_q2  | 0.12     |
| loss_diff    | 0.994    |
| loss_diff_q2 | 0.994    |
| loss_q2      | 0.994    |
| param_norm   | 227      |
| samples      | 102      |
| step         | 101      |
---------------------------
---------------------------
| grad_norm    | 4.32     |
| loss         | 0.974    |
| loss_cal     | 0.103    |
| loss_cal_q1  | 0.103    |
| loss_diff    | 0.974    |
| loss_diff_q1 | 0.974    |
| loss_q1      | 0.974    |
| param_norm   | 227      |
| samples      | 103      |
| step         | 102      |
---------------------------
---------------------------
| grad_norm    | 4.66     |
| loss         | 1.01     |
| loss_cal     | 0.111    |
| loss_cal_q2  | 0.111    |
| loss_diff    | 1.01     |
| loss_diff_q2 | 1.01     |
| loss_q2      | 1.01     |
| param_norm   | 227      |
| samples      | 104      |
| step         | 103      |
---------------------------
---------------------------
| grad_norm    | 4.38     |
| loss         | 0.997    |
| loss_cal     | 0.115    |
| loss_cal_q1  | 0.115    |
| loss_diff    | 0.997    |
| loss_diff_q1 | 0.997    |
| loss_q1      | 0.997    |
| param_norm   | 227      |
| samples      | 105      |
| step         | 104      |
---------------------------
---------------------------
| grad_norm    | 4.96     |
| loss         | 0.978    |
| loss_cal     | 0.11     |
| loss_cal_q3  | 0.11     |
| loss_diff    | 0.978    |
| loss_diff_q3 | 0.978    |
| loss_q3      | 0.978    |
| param_norm   | 227      |
| samples      | 106      |
| step         | 105      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.67     |
| loss         | 0.983    |
| loss_cal     | 0.0924   |
| loss_cal_q1  | 0.0924   |
| loss_diff    | 0.983    |
| loss_diff_q1 | 0.983    |
| loss_q1      | 0.983    |
| param_norm   | 227      |
| samples      | 107      |
| step         | 106      |
---------------------------
---------------------------
| grad_norm    | 3.8      |
| loss         | 1.03     |
| loss_cal     | 0.108    |
| loss_cal_q0  | 0.108    |
| loss_diff    | 1.03     |
| loss_diff_q0 | 1.03     |
| loss_q0      | 1.03     |
| param_norm   | 227      |
| samples      | 108      |
| step         | 107      |
---------------------------
---------------------------
| grad_norm    | 3.75     |
| loss         | 0.969    |
| loss_cal     | 0.0988   |
| loss_cal_q1  | 0.0988   |
| loss_diff    | 0.969    |
| loss_diff_q1 | 0.969    |
| loss_q1      | 0.969    |
| param_norm   | 227      |
| samples      | 109      |
| step         | 108      |
---------------------------
---------------------------
| grad_norm    | 3.61     |
| loss         | 1.01     |
| loss_cal     | 0.0904   |
| loss_cal_q1  | 0.0904   |
| loss_diff    | 1.01     |
| loss_diff_q1 | 1.01     |
| loss_q1      | 1.01     |
| param_norm   | 227      |
| samples      | 110      |
| step         | 109      |
---------------------------
---------------------------
| grad_norm    | 3.78     |
| loss         | 0.971    |
| loss_cal     | 0.0951   |
| loss_cal_q0  | 0.0951   |
| loss_diff    | 0.971    |
| loss_diff_q0 | 0.971    |
| loss_q0      | 0.971    |
| param_norm   | 227      |
| samples      | 111      |
| step         | 110      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.61     |
| loss         | 0.961    |
| loss_cal     | 0.0928   |
| loss_cal_q3  | 0.0928   |
| loss_diff    | 0.961    |
| loss_diff_q3 | 0.961    |
| loss_q3      | 0.961    |
| param_norm   | 227      |
| samples      | 112      |
| step         | 111      |
---------------------------
---------------------------
| grad_norm    | 4.03     |
| loss         | 1        |
| loss_cal     | 0.104    |
| loss_cal_q1  | 0.104    |
| loss_diff    | 1        |
| loss_diff_q1 | 1        |
| loss_q1      | 1        |
| param_norm   | 227      |
| samples      | 113      |
| step         | 112      |
---------------------------
---------------------------
| grad_norm    | 3.79     |
| loss         | 1.01     |
| loss_cal     | 0.11     |
| loss_cal_q0  | 0.11     |
| loss_diff    | 1.01     |
| loss_diff_q0 | 1.01     |
| loss_q0      | 1.01     |
| param_norm   | 227      |
| samples      | 114      |
| step         | 113      |
---------------------------
---------------------------
| grad_norm    | 3.63     |
| loss         | 1        |
| loss_cal     | 0.0906   |
| loss_cal_q0  | 0.0906   |
| loss_diff    | 1        |
| loss_diff_q0 | 1        |
| loss_q0      | 1        |
| param_norm   | 227      |
| samples      | 115      |
| step         | 114      |
---------------------------
---------------------------
| grad_norm    | 4.42     |
| loss         | 1.03     |
| loss_cal     | 0.106    |
| loss_cal_q0  | 0.106    |
| loss_diff    | 1.03     |
| loss_diff_q0 | 1.03     |
| loss_q0      | 1.03     |
| param_norm   | 227      |
| samples      | 116      |
| step         | 115      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.93     |
| loss         | 0.966    |
| loss_cal     | 0.105    |
| loss_cal_q2  | 0.105    |
| loss_diff    | 0.966    |
| loss_diff_q2 | 0.966    |
| loss_q2      | 0.966    |
| param_norm   | 227      |
| samples      | 117      |
| step         | 116      |
---------------------------
---------------------------
| grad_norm    | 3.73     |
| loss         | 0.975    |
| loss_cal     | 0.0899   |
| loss_cal_q3  | 0.0899   |
| loss_diff    | 0.975    |
| loss_diff_q3 | 0.975    |
| loss_q3      | 0.975    |
| param_norm   | 227      |
| samples      | 118      |
| step         | 117      |
---------------------------
---------------------------
| grad_norm    | 3.6      |
| loss         | 0.928    |
| loss_cal     | 0.0887   |
| loss_cal_q2  | 0.0887   |
| loss_diff    | 0.928    |
| loss_diff_q2 | 0.928    |
| loss_q2      | 0.928    |
| param_norm   | 227      |
| samples      | 119      |
| step         | 118      |
---------------------------
---------------------------
| grad_norm    | 4.87     |
| loss         | 1.01     |
| loss_cal     | 0.117    |
| loss_cal_q1  | 0.117    |
| loss_diff    | 1.01     |
| loss_diff_q1 | 1.01     |
| loss_q1      | 1.01     |
| param_norm   | 227      |
| samples      | 120      |
| step         | 119      |
---------------------------
---------------------------
| grad_norm    | 3.42     |
| loss         | 0.985    |
| loss_cal     | 0.0858   |
| loss_cal_q3  | 0.0858   |
| loss_diff    | 0.985    |
| loss_diff_q3 | 0.985    |
| loss_q3      | 0.985    |
| param_norm   | 227      |
| samples      | 121      |
| step         | 120      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.32     |
| loss         | 1        |
| loss_cal     | 0.104    |
| loss_cal_q0  | 0.104    |
| loss_diff    | 1        |
| loss_diff_q0 | 1        |
| loss_q0      | 1        |
| param_norm   | 227      |
| samples      | 122      |
| step         | 121      |
---------------------------
---------------------------
| grad_norm    | 3.61     |
| loss         | 0.952    |
| loss_cal     | 0.104    |
| loss_cal_q1  | 0.104    |
| loss_diff    | 0.952    |
| loss_diff_q1 | 0.952    |
| loss_q1      | 0.952    |
| param_norm   | 227      |
| samples      | 123      |
| step         | 122      |
---------------------------
---------------------------
| grad_norm    | 3.5      |
| loss         | 0.974    |
| loss_cal     | 0.0988   |
| loss_cal_q1  | 0.0988   |
| loss_diff    | 0.974    |
| loss_diff_q1 | 0.974    |
| loss_q1      | 0.974    |
| param_norm   | 227      |
| samples      | 124      |
| step         | 123      |
---------------------------
---------------------------
| grad_norm    | 3.3      |
| loss         | 0.976    |
| loss_cal     | 0.0863   |
| loss_cal_q2  | 0.0863   |
| loss_diff    | 0.976    |
| loss_diff_q2 | 0.976    |
| loss_q2      | 0.976    |
| param_norm   | 227      |
| samples      | 125      |
| step         | 124      |
---------------------------
---------------------------
| grad_norm    | 3.54     |
| loss         | 0.975    |
| loss_cal     | 0.0999   |
| loss_cal_q3  | 0.0999   |
| loss_diff    | 0.975    |
| loss_diff_q3 | 0.975    |
| loss_q3      | 0.975    |
| param_norm   | 227      |
| samples      | 126      |
| step         | 125      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.25     |
| loss         | 1        |
| loss_cal     | 0.0869   |
| loss_cal_q0  | 0.0869   |
| loss_diff    | 1        |
| loss_diff_q0 | 1        |
| loss_q0      | 1        |
| param_norm   | 227      |
| samples      | 127      |
| step         | 126      |
---------------------------
---------------------------
| grad_norm    | 3.73     |
| loss         | 1        |
| loss_cal     | 0.088    |
| loss_cal_q3  | 0.088    |
| loss_diff    | 1        |
| loss_diff_q3 | 1        |
| loss_q3      | 1        |
| param_norm   | 227      |
| samples      | 128      |
| step         | 127      |
---------------------------
---------------------------
| grad_norm    | 3.52     |
| loss         | 1.01     |
| loss_cal     | 0.0864   |
| loss_cal_q2  | 0.0864   |
| loss_diff    | 1.01     |
| loss_diff_q2 | 1.01     |
| loss_q2      | 1.01     |
| param_norm   | 227      |
| samples      | 129      |
| step         | 128      |
---------------------------
---------------------------
| grad_norm    | 3.6      |
| loss         | 0.978    |
| loss_cal     | 0.0828   |
| loss_cal_q3  | 0.0828   |
| loss_diff    | 0.978    |
| loss_diff_q3 | 0.978    |
| loss_q3      | 0.978    |
| param_norm   | 227      |
| samples      | 130      |
| step         | 129      |
---------------------------
---------------------------
| grad_norm    | 4.61     |
| loss         | 1.01     |
| loss_cal     | 0.0944   |
| loss_cal_q3  | 0.0944   |
| loss_diff    | 1.01     |
| loss_diff_q3 | 1.01     |
| loss_q3      | 1.01     |
| param_norm   | 227      |
| samples      | 131      |
| step         | 130      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.57     |
| loss         | 1.02     |
| loss_cal     | 0.0973   |
| loss_cal_q2  | 0.0973   |
| loss_diff    | 1.02     |
| loss_diff_q2 | 1.02     |
| loss_q2      | 1.02     |
| param_norm   | 227      |
| samples      | 132      |
| step         | 131      |
---------------------------
---------------------------
| grad_norm    | 50.8     |
| loss         | 0.112    |
| loss_cal     | 0.086    |
| loss_cal_q1  | 0.086    |
| loss_diff    | 0.112    |
| loss_diff_q1 | 0.112    |
| loss_q1      | 0.112    |
| param_norm   | 227      |
| samples      | 133      |
| step         | 132      |
---------------------------
---------------------------
| grad_norm    | 4.18     |
| loss         | 0.988    |
| loss_cal     | 0.0933   |
| loss_cal_q1  | 0.0933   |
| loss_diff    | 0.988    |
| loss_diff_q1 | 0.988    |
| loss_q1      | 0.988    |
| param_norm   | 227      |
| samples      | 134      |
| step         | 133      |
---------------------------
---------------------------
| grad_norm    | 4.29     |
| loss         | 1.03     |
| loss_cal     | 0.118    |
| loss_cal_q0  | 0.118    |
| loss_diff    | 1.03     |
| loss_diff_q0 | 1.03     |
| loss_q0      | 1.03     |
| param_norm   | 227      |
| samples      | 135      |
| step         | 134      |
---------------------------
---------------------------
| grad_norm    | 3.1      |
| loss         | 0.986    |
| loss_cal     | 0.0817   |
| loss_cal_q2  | 0.0817   |
| loss_diff    | 0.986    |
| loss_diff_q2 | 0.986    |
| loss_q2      | 0.986    |
| param_norm   | 227      |
| samples      | 136      |
| step         | 135      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.82     |
| loss         | 1.02     |
| loss_cal     | 0.0745   |
| loss_cal_q0  | 0.0745   |
| loss_diff    | 1.02     |
| loss_diff_q0 | 1.02     |
| loss_q0      | 1.02     |
| param_norm   | 227      |
| samples      | 137      |
| step         | 136      |
---------------------------
---------------------------
| grad_norm    | 3.2      |
| loss         | 0.798    |
| loss_cal     | 0.0782   |
| loss_cal_q3  | 0.0782   |
| loss_diff    | 0.798    |
| loss_diff_q3 | 0.798    |
| loss_q3      | 0.798    |
| param_norm   | 227      |
| samples      | 138      |
| step         | 137      |
---------------------------
---------------------------
| grad_norm    | 3.48     |
| loss         | 0.976    |
| loss_cal     | 0.0989   |
| loss_cal_q3  | 0.0989   |
| loss_diff    | 0.976    |
| loss_diff_q3 | 0.976    |
| loss_q3      | 0.976    |
| param_norm   | 227      |
| samples      | 139      |
| step         | 138      |
---------------------------
---------------------------
| grad_norm    | 2.86     |
| loss         | 0.992    |
| loss_cal     | 0.0735   |
| loss_cal_q0  | 0.0735   |
| loss_diff    | 0.992    |
| loss_diff_q0 | 0.992    |
| loss_q0      | 0.992    |
| param_norm   | 227      |
| samples      | 140      |
| step         | 139      |
---------------------------
---------------------------
| grad_norm    | 3.25     |
| loss         | 0.951    |
| loss_cal     | 0.0885   |
| loss_cal_q1  | 0.0885   |
| loss_diff    | 0.951    |
| loss_diff_q1 | 0.951    |
| loss_q1      | 0.951    |
| param_norm   | 227      |
| samples      | 141      |
| step         | 140      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.83     |
| loss         | 0.958    |
| loss_cal     | 0.105    |
| loss_cal_q0  | 0.105    |
| loss_diff    | 0.958    |
| loss_diff_q0 | 0.958    |
| loss_q0      | 0.958    |
| param_norm   | 227      |
| samples      | 142      |
| step         | 141      |
---------------------------
---------------------------
| grad_norm    | 3.9      |
| loss         | 0.965    |
| loss_cal     | 0.108    |
| loss_cal_q1  | 0.108    |
| loss_diff    | 0.965    |
| loss_diff_q1 | 0.965    |
| loss_q1      | 0.965    |
| param_norm   | 227      |
| samples      | 143      |
| step         | 142      |
---------------------------
---------------------------
| grad_norm    | 3.01     |
| loss         | 1.01     |
| loss_cal     | 0.0809   |
| loss_cal_q1  | 0.0809   |
| loss_diff    | 1.01     |
| loss_diff_q1 | 1.01     |
| loss_q1      | 1.01     |
| param_norm   | 227      |
| samples      | 144      |
| step         | 143      |
---------------------------
---------------------------
| grad_norm    | 3.56     |
| loss         | 0.993    |
| loss_cal     | 0.102    |
| loss_cal_q2  | 0.102    |
| loss_diff    | 0.993    |
| loss_diff_q2 | 0.993    |
| loss_q2      | 0.993    |
| param_norm   | 227      |
| samples      | 145      |
| step         | 144      |
---------------------------
---------------------------
| grad_norm    | 70       |
| loss         | 0.107    |
| loss_cal     | 0.0791   |
| loss_cal_q2  | 0.0791   |
| loss_diff    | 0.107    |
| loss_diff_q2 | 0.107    |
| loss_q2      | 0.107    |
| param_norm   | 227      |
| samples      | 146      |
| step         | 145      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.68     |
| loss         | 0.995    |
| loss_cal     | 0.113    |
| loss_cal_q0  | 0.113    |
| loss_diff    | 0.995    |
| loss_diff_q0 | 0.995    |
| loss_q0      | 0.995    |
| param_norm   | 227      |
| samples      | 147      |
| step         | 146      |
---------------------------
---------------------------
| grad_norm    | 3.06     |
| loss         | 0.978    |
| loss_cal     | 0.0745   |
| loss_cal_q1  | 0.0745   |
| loss_diff    | 0.978    |
| loss_diff_q1 | 0.978    |
| loss_q1      | 0.978    |
| param_norm   | 227      |
| samples      | 148      |
| step         | 147      |
---------------------------
---------------------------
| grad_norm    | 3.25     |
| loss         | 0.999    |
| loss_cal     | 0.0819   |
| loss_cal_q0  | 0.0819   |
| loss_diff    | 0.999    |
| loss_diff_q0 | 0.999    |
| loss_q0      | 0.999    |
| param_norm   | 227      |
| samples      | 149      |
| step         | 148      |
---------------------------
---------------------------
| grad_norm    | 2.98     |
| loss         | 0.972    |
| loss_cal     | 0.0783   |
| loss_cal_q0  | 0.0783   |
| loss_diff    | 0.972    |
| loss_diff_q0 | 0.972    |
| loss_q0      | 0.972    |
| param_norm   | 227      |
| samples      | 150      |
| step         | 149      |
---------------------------
---------------------------
| grad_norm    | 3.33     |
| loss         | 0.975    |
| loss_cal     | 0.0883   |
| loss_cal_q0  | 0.0883   |
| loss_diff    | 0.975    |
| loss_diff_q0 | 0.975    |
| loss_q0      | 0.975    |
| param_norm   | 227      |
| samples      | 151      |
| step         | 150      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.19     |
| loss         | 0.98     |
| loss_cal     | 0.0801   |
| loss_cal_q0  | 0.0801   |
| loss_diff    | 0.98     |
| loss_diff_q0 | 0.98     |
| loss_q0      | 0.98     |
| param_norm   | 227      |
| samples      | 152      |
| step         | 151      |
---------------------------
---------------------------
| grad_norm    | 2.99     |
| loss         | 1        |
| loss_cal     | 0.077    |
| loss_cal_q2  | 0.077    |
| loss_diff    | 1        |
| loss_diff_q2 | 1        |
| loss_q2      | 1        |
| param_norm   | 227      |
| samples      | 153      |
| step         | 152      |
---------------------------
---------------------------
| grad_norm    | 3.24     |
| loss         | 0.962    |
| loss_cal     | 0.0972   |
| loss_cal_q3  | 0.0972   |
| loss_diff    | 0.962    |
| loss_diff_q3 | 0.962    |
| loss_q3      | 0.962    |
| param_norm   | 227      |
| samples      | 154      |
| step         | 153      |
---------------------------
---------------------------
| grad_norm    | 2.85     |
| loss         | 0.914    |
| loss_cal     | 0.0727   |
| loss_cal_q3  | 0.0727   |
| loss_diff    | 0.914    |
| loss_diff_q3 | 0.914    |
| loss_q3      | 0.914    |
| param_norm   | 227      |
| samples      | 155      |
| step         | 154      |
---------------------------
---------------------------
| grad_norm    | 2.89     |
| loss         | 0.98     |
| loss_cal     | 0.0741   |
| loss_cal_q1  | 0.0741   |
| loss_diff    | 0.98     |
| loss_diff_q1 | 0.98     |
| loss_q1      | 0.98     |
| param_norm   | 227      |
| samples      | 156      |
| step         | 155      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.29     |
| loss         | 0.976    |
| loss_cal     | 0.0885   |
| loss_cal_q3  | 0.0885   |
| loss_diff    | 0.976    |
| loss_diff_q3 | 0.976    |
| loss_q3      | 0.976    |
| param_norm   | 227      |
| samples      | 157      |
| step         | 156      |
---------------------------
---------------------------
| grad_norm    | 3.09     |
| loss         | 0.979    |
| loss_cal     | 0.0851   |
| loss_cal_q1  | 0.0851   |
| loss_diff    | 0.979    |
| loss_diff_q1 | 0.979    |
| loss_q1      | 0.979    |
| param_norm   | 227      |
| samples      | 158      |
| step         | 157      |
---------------------------
---------------------------
| grad_norm    | 3.32     |
| loss         | 0.991    |
| loss_cal     | 0.077    |
| loss_cal_q1  | 0.077    |
| loss_diff    | 0.991    |
| loss_diff_q1 | 0.991    |
| loss_q1      | 0.991    |
| param_norm   | 227      |
| samples      | 159      |
| step         | 158      |
---------------------------
---------------------------
| grad_norm    | 3.07     |
| loss         | 0.988    |
| loss_cal     | 0.0777   |
| loss_cal_q0  | 0.0777   |
| loss_diff    | 0.988    |
| loss_diff_q0 | 0.988    |
| loss_q0      | 0.988    |
| param_norm   | 227      |
| samples      | 160      |
| step         | 159      |
---------------------------
---------------------------
| grad_norm    | 3.08     |
| loss         | 0.934    |
| loss_cal     | 0.0765   |
| loss_cal_q1  | 0.0765   |
| loss_diff    | 0.934    |
| loss_diff_q1 | 0.934    |
| loss_q1      | 0.934    |
| param_norm   | 227      |
| samples      | 161      |
| step         | 160      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.73     |
| loss         | 0.983    |
| loss_cal     | 0.0709   |
| loss_cal_q1  | 0.0709   |
| loss_diff    | 0.983    |
| loss_diff_q1 | 0.983    |
| loss_q1      | 0.983    |
| param_norm   | 227      |
| samples      | 162      |
| step         | 161      |
---------------------------
---------------------------
| grad_norm    | 3.09     |
| loss         | 0.979    |
| loss_cal     | 0.0808   |
| loss_cal_q0  | 0.0808   |
| loss_diff    | 0.979    |
| loss_diff_q0 | 0.979    |
| loss_q0      | 0.979    |
| param_norm   | 227      |
| samples      | 163      |
| step         | 162      |
---------------------------
---------------------------
| grad_norm    | 2.95     |
| loss         | 0.989    |
| loss_cal     | 0.0837   |
| loss_cal_q3  | 0.0837   |
| loss_diff    | 0.989    |
| loss_diff_q3 | 0.989    |
| loss_q3      | 0.989    |
| param_norm   | 227      |
| samples      | 164      |
| step         | 163      |
---------------------------
---------------------------
| grad_norm    | 3.33     |
| loss         | 0.975    |
| loss_cal     | 0.0883   |
| loss_cal_q2  | 0.0883   |
| loss_diff    | 0.975    |
| loss_diff_q2 | 0.975    |
| loss_q2      | 0.975    |
| param_norm   | 227      |
| samples      | 165      |
| step         | 164      |
---------------------------
---------------------------
| grad_norm    | 25       |
| loss         | 0.0837   |
| loss_cal     | 0.0705   |
| loss_cal_q3  | 0.0705   |
| loss_diff    | 0.0837   |
| loss_diff_q3 | 0.0837   |
| loss_q3      | 0.0837   |
| param_norm   | 227      |
| samples      | 166      |
| step         | 165      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.97     |
| loss         | 0.965    |
| loss_cal     | 0.0786   |
| loss_cal_q3  | 0.0786   |
| loss_diff    | 0.965    |
| loss_diff_q3 | 0.965    |
| loss_q3      | 0.965    |
| param_norm   | 227      |
| samples      | 167      |
| step         | 166      |
---------------------------
---------------------------
| grad_norm    | 3.32     |
| loss         | 1.02     |
| loss_cal     | 0.0921   |
| loss_cal_q1  | 0.0921   |
| loss_diff    | 1.02     |
| loss_diff_q1 | 1.02     |
| loss_q1      | 1.02     |
| param_norm   | 227      |
| samples      | 168      |
| step         | 167      |
---------------------------
---------------------------
| grad_norm    | 2.96     |
| loss         | 0.946    |
| loss_cal     | 0.0739   |
| loss_cal_q2  | 0.0739   |
| loss_diff    | 0.946    |
| loss_diff_q2 | 0.946    |
| loss_q2      | 0.946    |
| param_norm   | 227      |
| samples      | 169      |
| step         | 168      |
---------------------------
---------------------------
| grad_norm    | 2.99     |
| loss         | 1        |
| loss_cal     | 0.0867   |
| loss_cal_q3  | 0.0867   |
| loss_diff    | 1        |
| loss_diff_q3 | 1        |
| loss_q3      | 1        |
| param_norm   | 227      |
| samples      | 170      |
| step         | 169      |
---------------------------
---------------------------
| grad_norm    | 3.5      |
| loss         | 0.976    |
| loss_cal     | 0.0863   |
| loss_cal_q0  | 0.0863   |
| loss_diff    | 0.976    |
| loss_diff_q0 | 0.976    |
| loss_q0      | 0.976    |
| param_norm   | 227      |
| samples      | 171      |
| step         | 170      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.03     |
| loss         | 0.956    |
| loss_cal     | 0.0736   |
| loss_cal_q2  | 0.0736   |
| loss_diff    | 0.956    |
| loss_diff_q2 | 0.956    |
| loss_q2      | 0.956    |
| param_norm   | 227      |
| samples      | 172      |
| step         | 171      |
---------------------------
---------------------------
| grad_norm    | 3.18     |
| loss         | 0.976    |
| loss_cal     | 0.0879   |
| loss_cal_q1  | 0.0879   |
| loss_diff    | 0.976    |
| loss_diff_q1 | 0.976    |
| loss_q1      | 0.976    |
| param_norm   | 227      |
| samples      | 173      |
| step         | 172      |
---------------------------
---------------------------
| grad_norm    | 2.74     |
| loss         | 0.958    |
| loss_cal     | 0.0866   |
| loss_cal_q1  | 0.0866   |
| loss_diff    | 0.958    |
| loss_diff_q1 | 0.958    |
| loss_q1      | 0.958    |
| param_norm   | 227      |
| samples      | 174      |
| step         | 173      |
---------------------------
---------------------------
| grad_norm    | 2.89     |
| loss         | 0.954    |
| loss_cal     | 0.0658   |
| loss_cal_q2  | 0.0658   |
| loss_diff    | 0.954    |
| loss_diff_q2 | 0.954    |
| loss_q2      | 0.954    |
| param_norm   | 227      |
| samples      | 175      |
| step         | 174      |
---------------------------
---------------------------
| grad_norm    | 3.07     |
| loss         | 0.8      |
| loss_cal     | 0.0632   |
| loss_cal_q2  | 0.0632   |
| loss_diff    | 0.8      |
| loss_diff_q2 | 0.8      |
| loss_q2      | 0.8      |
| param_norm   | 227      |
| samples      | 176      |
| step         | 175      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.76     |
| loss         | 0.954    |
| loss_cal     | 0.0698   |
| loss_cal_q1  | 0.0698   |
| loss_diff    | 0.954    |
| loss_diff_q1 | 0.954    |
| loss_q1      | 0.954    |
| param_norm   | 227      |
| samples      | 177      |
| step         | 176      |
---------------------------
---------------------------
| grad_norm    | 2.79     |
| loss         | 0.936    |
| loss_cal     | 0.0659   |
| loss_cal_q0  | 0.0659   |
| loss_diff    | 0.936    |
| loss_diff_q0 | 0.936    |
| loss_q0      | 0.936    |
| param_norm   | 227      |
| samples      | 178      |
| step         | 177      |
---------------------------
---------------------------
| grad_norm    | 2.77     |
| loss         | 0.979    |
| loss_cal     | 0.0699   |
| loss_cal_q2  | 0.0699   |
| loss_diff    | 0.979    |
| loss_diff_q2 | 0.979    |
| loss_q2      | 0.979    |
| param_norm   | 227      |
| samples      | 179      |
| step         | 178      |
---------------------------
---------------------------
| grad_norm    | 2.94     |
| loss         | 0.873    |
| loss_cal     | 0.0648   |
| loss_cal_q1  | 0.0648   |
| loss_diff    | 0.873    |
| loss_diff_q1 | 0.873    |
| loss_q1      | 0.873    |
| param_norm   | 227      |
| samples      | 180      |
| step         | 179      |
---------------------------
---------------------------
| grad_norm    | 2.99     |
| loss         | 0.956    |
| loss_cal     | 0.0843   |
| loss_cal_q1  | 0.0843   |
| loss_diff    | 0.956    |
| loss_diff_q1 | 0.956    |
| loss_q1      | 0.956    |
| param_norm   | 227      |
| samples      | 181      |
| step         | 180      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.05     |
| loss         | 0.959    |
| loss_cal     | 0.0679   |
| loss_cal_q1  | 0.0679   |
| loss_diff    | 0.959    |
| loss_diff_q1 | 0.959    |
| loss_q1      | 0.959    |
| param_norm   | 227      |
| samples      | 182      |
| step         | 181      |
---------------------------
---------------------------
| grad_norm    | 2.87     |
| loss         | 0.89     |
| loss_cal     | 0.0786   |
| loss_cal_q2  | 0.0786   |
| loss_diff    | 0.89     |
| loss_diff_q2 | 0.89     |
| loss_q2      | 0.89     |
| param_norm   | 227      |
| samples      | 183      |
| step         | 182      |
---------------------------
---------------------------
| grad_norm    | 3.08     |
| loss         | 1.01     |
| loss_cal     | 0.0697   |
| loss_cal_q0  | 0.0697   |
| loss_diff    | 1.01     |
| loss_diff_q0 | 1.01     |
| loss_q0      | 1.01     |
| param_norm   | 227      |
| samples      | 184      |
| step         | 183      |
---------------------------
---------------------------
| grad_norm    | 2.68     |
| loss         | 1.06     |
| loss_cal     | 0.0753   |
| loss_cal_q1  | 0.0753   |
| loss_diff    | 1.06     |
| loss_diff_q1 | 1.06     |
| loss_q1      | 1.06     |
| param_norm   | 227      |
| samples      | 185      |
| step         | 184      |
---------------------------
---------------------------
| grad_norm    | 2.79     |
| loss         | 0.939    |
| loss_cal     | 0.0629   |
| loss_cal_q3  | 0.0629   |
| loss_diff    | 0.939    |
| loss_diff_q3 | 0.939    |
| loss_q3      | 0.939    |
| param_norm   | 227      |
| samples      | 186      |
| step         | 185      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.01     |
| loss         | 0.949    |
| loss_cal     | 0.0846   |
| loss_cal_q1  | 0.0846   |
| loss_diff    | 0.949    |
| loss_diff_q1 | 0.949    |
| loss_q1      | 0.949    |
| param_norm   | 227      |
| samples      | 187      |
| step         | 186      |
---------------------------
---------------------------
| grad_norm    | 2.71     |
| loss         | 0.982    |
| loss_cal     | 0.0685   |
| loss_cal_q1  | 0.0685   |
| loss_diff    | 0.982    |
| loss_diff_q1 | 0.982    |
| loss_q1      | 0.982    |
| param_norm   | 227      |
| samples      | 188      |
| step         | 187      |
---------------------------
---------------------------
| grad_norm    | 2.78     |
| loss         | 0.95     |
| loss_cal     | 0.065    |
| loss_cal_q3  | 0.065    |
| loss_diff    | 0.95     |
| loss_diff_q3 | 0.95     |
| loss_q3      | 0.95     |
| param_norm   | 227      |
| samples      | 189      |
| step         | 188      |
---------------------------
---------------------------
| grad_norm    | 3.36     |
| loss         | 0.933    |
| loss_cal     | 0.0619   |
| loss_cal_q3  | 0.0619   |
| loss_diff    | 0.933    |
| loss_diff_q3 | 0.933    |
| loss_q3      | 0.933    |
| param_norm   | 227      |
| samples      | 190      |
| step         | 189      |
---------------------------
---------------------------
| grad_norm    | 3.04     |
| loss         | 0.91     |
| loss_cal     | 0.0697   |
| loss_cal_q1  | 0.0697   |
| loss_diff    | 0.91     |
| loss_diff_q1 | 0.91     |
| loss_q1      | 0.91     |
| param_norm   | 227      |
| samples      | 191      |
| step         | 190      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.68     |
| loss         | 0.988    |
| loss_cal     | 0.0728   |
| loss_cal_q3  | 0.0728   |
| loss_diff    | 0.988    |
| loss_diff_q3 | 0.988    |
| loss_q3      | 0.988    |
| param_norm   | 227      |
| samples      | 192      |
| step         | 191      |
---------------------------
---------------------------
| grad_norm    | 3.61     |
| loss         | 0.976    |
| loss_cal     | 0.0951   |
| loss_cal_q2  | 0.0951   |
| loss_diff    | 0.976    |
| loss_diff_q2 | 0.976    |
| loss_q2      | 0.976    |
| param_norm   | 227      |
| samples      | 193      |
| step         | 192      |
---------------------------
---------------------------
| grad_norm    | 2.79     |
| loss         | 0.923    |
| loss_cal     | 0.0648   |
| loss_cal_q1  | 0.0648   |
| loss_diff    | 0.923    |
| loss_diff_q1 | 0.923    |
| loss_q1      | 0.923    |
| param_norm   | 227      |
| samples      | 194      |
| step         | 193      |
---------------------------
---------------------------
| grad_norm    | 3.2      |
| loss         | 0.944    |
| loss_cal     | 0.107    |
| loss_cal_q2  | 0.107    |
| loss_diff    | 0.944    |
| loss_diff_q2 | 0.944    |
| loss_q2      | 0.944    |
| param_norm   | 227      |
| samples      | 195      |
| step         | 194      |
---------------------------
---------------------------
| grad_norm    | 3.06     |
| loss         | 0.963    |
| loss_cal     | 0.101    |
| loss_cal_q1  | 0.101    |
| loss_diff    | 0.963    |
| loss_diff_q1 | 0.963    |
| loss_q1      | 0.963    |
| param_norm   | 227      |
| samples      | 196      |
| step         | 195      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.76     |
| loss         | 0.976    |
| loss_cal     | 0.0777   |
| loss_cal_q2  | 0.0777   |
| loss_diff    | 0.976    |
| loss_diff_q2 | 0.976    |
| loss_q2      | 0.976    |
| param_norm   | 227      |
| samples      | 197      |
| step         | 196      |
---------------------------
---------------------------
| grad_norm    | 2.71     |
| loss         | 0.103    |
| loss_cal     | 0.0577   |
| loss_cal_q3  | 0.0577   |
| loss_diff    | 0.103    |
| loss_diff_q3 | 0.103    |
| loss_q3      | 0.103    |
| param_norm   | 227      |
| samples      | 198      |
| step         | 197      |
---------------------------
---------------------------
| grad_norm    | 2.45     |
| loss         | 1.01     |
| loss_cal     | 0.0607   |
| loss_cal_q0  | 0.0607   |
| loss_diff    | 1.01     |
| loss_diff_q0 | 1.01     |
| loss_q0      | 1.01     |
| param_norm   | 227      |
| samples      | 199      |
| step         | 198      |
---------------------------
---------------------------
| grad_norm    | 4.23     |
| loss         | 0.765    |
| loss_cal     | 0.0586   |
| loss_cal_q1  | 0.0586   |
| loss_diff    | 0.765    |
| loss_diff_q1 | 0.765    |
| loss_q1      | 0.765    |
| param_norm   | 227      |
| samples      | 200      |
| step         | 199      |
---------------------------
---------------------------
| grad_norm    | 21.3     |
| loss         | 0.0633   |
| loss_cal     | 0.0602   |
| loss_cal_q2  | 0.0602   |
| loss_diff    | 0.0633   |
| loss_diff_q2 | 0.0633   |
| loss_q2      | 0.0633   |
| param_norm   | 227      |
| samples      | 201      |
| step         | 200      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.28     |
| loss         | 0.943    |
| loss_cal     | 0.0846   |
| loss_cal_q3  | 0.0846   |
| loss_diff    | 0.943    |
| loss_diff_q3 | 0.943    |
| loss_q3      | 0.943    |
| param_norm   | 227      |
| samples      | 202      |
| step         | 201      |
---------------------------
---------------------------
| grad_norm    | 2.66     |
| loss         | 0.95     |
| loss_cal     | 0.0592   |
| loss_cal_q3  | 0.0592   |
| loss_diff    | 0.95     |
| loss_diff_q3 | 0.95     |
| loss_q3      | 0.95     |
| param_norm   | 227      |
| samples      | 203      |
| step         | 202      |
---------------------------
---------------------------
| grad_norm    | 3.14     |
| loss         | 0.984    |
| loss_cal     | 0.0655   |
| loss_cal_q0  | 0.0655   |
| loss_diff    | 0.984    |
| loss_diff_q0 | 0.984    |
| loss_q0      | 0.984    |
| param_norm   | 227      |
| samples      | 204      |
| step         | 203      |
---------------------------
---------------------------
| grad_norm    | 2.61     |
| loss         | 1        |
| loss_cal     | 0.0627   |
| loss_cal_q0  | 0.0627   |
| loss_diff    | 1        |
| loss_diff_q0 | 1        |
| loss_q0      | 1        |
| param_norm   | 227      |
| samples      | 205      |
| step         | 204      |
---------------------------
---------------------------
| grad_norm    | 2.77     |
| loss         | 0.976    |
| loss_cal     | 0.0611   |
| loss_cal_q0  | 0.0611   |
| loss_diff    | 0.976    |
| loss_diff_q0 | 0.976    |
| loss_q0      | 0.976    |
| param_norm   | 227      |
| samples      | 206      |
| step         | 205      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.78     |
| loss         | 0.931    |
| loss_cal     | 0.0588   |
| loss_cal_q1  | 0.0588   |
| loss_diff    | 0.931    |
| loss_diff_q1 | 0.931    |
| loss_q1      | 0.931    |
| param_norm   | 227      |
| samples      | 207      |
| step         | 206      |
---------------------------
---------------------------
| grad_norm    | 2.61     |
| loss         | 0.903    |
| loss_cal     | 0.066    |
| loss_cal_q3  | 0.066    |
| loss_diff    | 0.903    |
| loss_diff_q3 | 0.903    |
| loss_q3      | 0.903    |
| param_norm   | 227      |
| samples      | 208      |
| step         | 207      |
---------------------------
---------------------------
| grad_norm    | 25.1     |
| loss         | 0.106    |
| loss_cal     | 0.0579   |
| loss_cal_q2  | 0.0579   |
| loss_diff    | 0.106    |
| loss_diff_q2 | 0.106    |
| loss_q2      | 0.106    |
| param_norm   | 227      |
| samples      | 209      |
| step         | 208      |
---------------------------
---------------------------
| grad_norm    | 2.95     |
| loss         | 0.928    |
| loss_cal     | 0.0863   |
| loss_cal_q1  | 0.0863   |
| loss_diff    | 0.928    |
| loss_diff_q1 | 0.928    |
| loss_q1      | 0.928    |
| param_norm   | 227      |
| samples      | 210      |
| step         | 209      |
---------------------------
---------------------------
| grad_norm    | 16.7     |
| loss         | 0.0712   |
| loss_cal     | 0.0558   |
| loss_cal_q2  | 0.0558   |
| loss_diff    | 0.0712   |
| loss_diff_q2 | 0.0712   |
| loss_q2      | 0.0712   |
| param_norm   | 227      |
| samples      | 211      |
| step         | 210      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.48     |
| loss         | 0.969    |
| loss_cal     | 0.0677   |
| loss_cal_q1  | 0.0677   |
| loss_diff    | 0.969    |
| loss_diff_q1 | 0.969    |
| loss_q1      | 0.969    |
| param_norm   | 227      |
| samples      | 212      |
| step         | 211      |
---------------------------
---------------------------
| grad_norm    | 2.85     |
| loss         | 0.9      |
| loss_cal     | 0.0681   |
| loss_cal_q3  | 0.0681   |
| loss_diff    | 0.9      |
| loss_diff_q3 | 0.9      |
| loss_q3      | 0.9      |
| param_norm   | 227      |
| samples      | 213      |
| step         | 212      |
---------------------------
---------------------------
| grad_norm    | 2.43     |
| loss         | 0.948    |
| loss_cal     | 0.0673   |
| loss_cal_q2  | 0.0673   |
| loss_diff    | 0.948    |
| loss_diff_q2 | 0.948    |
| loss_q2      | 0.948    |
| param_norm   | 227      |
| samples      | 214      |
| step         | 213      |
---------------------------
---------------------------
| grad_norm    | 3.61     |
| loss         | 0.763    |
| loss_cal     | 0.0552   |
| loss_cal_q0  | 0.0552   |
| loss_diff    | 0.763    |
| loss_diff_q0 | 0.763    |
| loss_q0      | 0.763    |
| param_norm   | 227      |
| samples      | 215      |
| step         | 214      |
---------------------------
---------------------------
| grad_norm    | 2.57     |
| loss         | 0.955    |
| loss_cal     | 0.0603   |
| loss_cal_q3  | 0.0603   |
| loss_diff    | 0.955    |
| loss_diff_q3 | 0.955    |
| loss_q3      | 0.955    |
| param_norm   | 227      |
| samples      | 216      |
| step         | 215      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.52     |
| loss         | 1        |
| loss_cal     | 0.0718   |
| loss_cal_q1  | 0.0718   |
| loss_diff    | 1        |
| loss_diff_q1 | 1        |
| loss_q1      | 1        |
| param_norm   | 227      |
| samples      | 217      |
| step         | 216      |
---------------------------
---------------------------
| grad_norm    | 2.5      |
| loss         | 0.964    |
| loss_cal     | 0.0542   |
| loss_cal_q0  | 0.0542   |
| loss_diff    | 0.964    |
| loss_diff_q0 | 0.964    |
| loss_q0      | 0.964    |
| param_norm   | 227      |
| samples      | 218      |
| step         | 217      |
---------------------------
---------------------------
| grad_norm    | 3.91     |
| loss         | 0.883    |
| loss_cal     | 0.0842   |
| loss_cal_q2  | 0.0842   |
| loss_diff    | 0.883    |
| loss_diff_q2 | 0.883    |
| loss_q2      | 0.883    |
| param_norm   | 227      |
| samples      | 219      |
| step         | 218      |
---------------------------
---------------------------
| grad_norm    | 3.14     |
| loss         | 0.811    |
| loss_cal     | 0.0805   |
| loss_cal_q1  | 0.0805   |
| loss_diff    | 0.811    |
| loss_diff_q1 | 0.811    |
| loss_q1      | 0.811    |
| param_norm   | 227      |
| samples      | 220      |
| step         | 219      |
---------------------------
---------------------------
| grad_norm    | 2.41     |
| loss         | 0.899    |
| loss_cal     | 0.058    |
| loss_cal_q1  | 0.058    |
| loss_diff    | 0.899    |
| loss_diff_q1 | 0.899    |
| loss_q1      | 0.899    |
| param_norm   | 227      |
| samples      | 221      |
| step         | 220      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.95     |
| loss         | 0.443    |
| loss_cal     | 0.0545   |
| loss_cal_q1  | 0.0545   |
| loss_diff    | 0.443    |
| loss_diff_q1 | 0.443    |
| loss_q1      | 0.443    |
| param_norm   | 227      |
| samples      | 222      |
| step         | 221      |
---------------------------
---------------------------
| grad_norm    | 2.48     |
| loss         | 0.905    |
| loss_cal     | 0.0564   |
| loss_cal_q3  | 0.0564   |
| loss_diff    | 0.905    |
| loss_diff_q3 | 0.905    |
| loss_q3      | 0.905    |
| param_norm   | 227      |
| samples      | 223      |
| step         | 222      |
---------------------------
---------------------------
| grad_norm    | 3.31     |
| loss         | 0.848    |
| loss_cal     | 0.0566   |
| loss_cal_q0  | 0.0566   |
| loss_diff    | 0.848    |
| loss_diff_q0 | 0.848    |
| loss_q0      | 0.848    |
| param_norm   | 227      |
| samples      | 224      |
| step         | 223      |
---------------------------
---------------------------
| grad_norm    | 2.68     |
| loss         | 0.92     |
| loss_cal     | 0.0612   |
| loss_cal_q1  | 0.0612   |
| loss_diff    | 0.92     |
| loss_diff_q1 | 0.92     |
| loss_q1      | 0.92     |
| param_norm   | 227      |
| samples      | 225      |
| step         | 224      |
---------------------------
---------------------------
| grad_norm    | 21.2     |
| loss         | 0.162    |
| loss_cal     | 0.0515   |
| loss_cal_q1  | 0.0515   |
| loss_diff    | 0.162    |
| loss_diff_q1 | 0.162    |
| loss_q1      | 0.162    |
| param_norm   | 227      |
| samples      | 226      |
| step         | 225      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.33     |
| loss         | 0.982    |
| loss_cal     | 0.0548   |
| loss_cal_q0  | 0.0548   |
| loss_diff    | 0.982    |
| loss_diff_q0 | 0.982    |
| loss_q0      | 0.982    |
| param_norm   | 227      |
| samples      | 227      |
| step         | 226      |
---------------------------
---------------------------
| grad_norm    | 2.29     |
| loss         | 0.958    |
| loss_cal     | 0.0667   |
| loss_cal_q0  | 0.0667   |
| loss_diff    | 0.958    |
| loss_diff_q0 | 0.958    |
| loss_q0      | 0.958    |
| param_norm   | 227      |
| samples      | 228      |
| step         | 227      |
---------------------------
---------------------------
| grad_norm    | 19.3     |
| loss         | 0.0928   |
| loss_cal     | 0.0518   |
| loss_cal_q2  | 0.0518   |
| loss_diff    | 0.0928   |
| loss_diff_q2 | 0.0928   |
| loss_q2      | 0.0928   |
| param_norm   | 227      |
| samples      | 229      |
| step         | 228      |
---------------------------
---------------------------
| grad_norm    | 2.79     |
| loss         | 0.902    |
| loss_cal     | 0.0709   |
| loss_cal_q3  | 0.0709   |
| loss_diff    | 0.902    |
| loss_diff_q3 | 0.902    |
| loss_q3      | 0.902    |
| param_norm   | 227      |
| samples      | 230      |
| step         | 229      |
---------------------------
---------------------------
| grad_norm    | 2.35     |
| loss         | 1        |
| loss_cal     | 0.0601   |
| loss_cal_q0  | 0.0601   |
| loss_diff    | 1        |
| loss_diff_q0 | 1        |
| loss_q0      | 1        |
| param_norm   | 227      |
| samples      | 231      |
| step         | 230      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 5.01     |
| loss         | 0.466    |
| loss_cal     | 0.0539   |
| loss_cal_q0  | 0.0539   |
| loss_diff    | 0.466    |
| loss_diff_q0 | 0.466    |
| loss_q0      | 0.466    |
| param_norm   | 227      |
| samples      | 232      |
| step         | 231      |
---------------------------
---------------------------
| grad_norm    | 2.4      |
| loss         | 0.929    |
| loss_cal     | 0.0662   |
| loss_cal_q2  | 0.0662   |
| loss_diff    | 0.929    |
| loss_diff_q2 | 0.929    |
| loss_q2      | 0.929    |
| param_norm   | 227      |
| samples      | 233      |
| step         | 232      |
---------------------------
---------------------------
| grad_norm    | 4.52     |
| loss         | 0.654    |
| loss_cal     | 0.053    |
| loss_cal_q3  | 0.053    |
| loss_diff    | 0.654    |
| loss_diff_q3 | 0.654    |
| loss_q3      | 0.654    |
| param_norm   | 227      |
| samples      | 234      |
| step         | 233      |
---------------------------
---------------------------
| grad_norm    | 33.4     |
| loss         | 0.0703   |
| loss_cal     | 0.0544   |
| loss_cal_q2  | 0.0544   |
| loss_diff    | 0.0703   |
| loss_diff_q2 | 0.0703   |
| loss_q2      | 0.0703   |
| param_norm   | 227      |
| samples      | 235      |
| step         | 234      |
---------------------------
---------------------------
| grad_norm    | 4.16     |
| loss         | 0.265    |
| loss_cal     | 0.0504   |
| loss_cal_q3  | 0.0504   |
| loss_diff    | 0.265    |
| loss_diff_q3 | 0.265    |
| loss_q3      | 0.265    |
| param_norm   | 227      |
| samples      | 236      |
| step         | 235      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 5.45     |
| loss         | 0.782    |
| loss_cal     | 0.0648   |
| loss_cal_q1  | 0.0648   |
| loss_diff    | 0.782    |
| loss_diff_q1 | 0.782    |
| loss_q1      | 0.782    |
| param_norm   | 227      |
| samples      | 237      |
| step         | 236      |
---------------------------
---------------------------
| grad_norm    | 3.31     |
| loss         | 0.901    |
| loss_cal     | 0.0608   |
| loss_cal_q0  | 0.0608   |
| loss_diff    | 0.901    |
| loss_diff_q0 | 0.901    |
| loss_q0      | 0.901    |
| param_norm   | 227      |
| samples      | 238      |
| step         | 237      |
---------------------------
---------------------------
| grad_norm    | 4.15     |
| loss         | 0.865    |
| loss_cal     | 0.051    |
| loss_cal_q0  | 0.051    |
| loss_diff    | 0.865    |
| loss_diff_q0 | 0.865    |
| loss_q0      | 0.865    |
| param_norm   | 227      |
| samples      | 239      |
| step         | 238      |
---------------------------
---------------------------
| grad_norm    | 4.07     |
| loss         | 0.815    |
| loss_cal     | 0.0536   |
| loss_cal_q3  | 0.0536   |
| loss_diff    | 0.815    |
| loss_diff_q3 | 0.815    |
| loss_q3      | 0.815    |
| param_norm   | 227      |
| samples      | 240      |
| step         | 239      |
---------------------------
---------------------------
| grad_norm    | 2.36     |
| loss         | 0.957    |
| loss_cal     | 0.0679   |
| loss_cal_q3  | 0.0679   |
| loss_diff    | 0.957    |
| loss_diff_q3 | 0.957    |
| loss_q3      | 0.957    |
| param_norm   | 227      |
| samples      | 241      |
| step         | 240      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 6.01     |
| loss         | 0.466    |
| loss_cal     | 0.0568   |
| loss_cal_q2  | 0.0568   |
| loss_diff    | 0.466    |
| loss_diff_q2 | 0.466    |
| loss_q2      | 0.466    |
| param_norm   | 227      |
| samples      | 242      |
| step         | 241      |
---------------------------
---------------------------
| grad_norm    | 3.99     |
| loss         | 0.431    |
| loss_cal     | 0.0517   |
| loss_cal_q0  | 0.0517   |
| loss_diff    | 0.431    |
| loss_diff_q0 | 0.431    |
| loss_q0      | 0.431    |
| param_norm   | 228      |
| samples      | 243      |
| step         | 242      |
---------------------------
---------------------------
| grad_norm    | 3.87     |
| loss         | 0.396    |
| loss_cal     | 0.0527   |
| loss_cal_q2  | 0.0527   |
| loss_diff    | 0.396    |
| loss_diff_q2 | 0.396    |
| loss_q2      | 0.396    |
| param_norm   | 228      |
| samples      | 244      |
| step         | 243      |
---------------------------
---------------------------
| grad_norm    | 5.1      |
| loss         | 0.435    |
| loss_cal     | 0.052    |
| loss_cal_q2  | 0.052    |
| loss_diff    | 0.435    |
| loss_diff_q2 | 0.435    |
| loss_q2      | 0.435    |
| param_norm   | 228      |
| samples      | 245      |
| step         | 244      |
---------------------------
---------------------------
| grad_norm    | 4.92     |
| loss         | 0.545    |
| loss_cal     | 0.053    |
| loss_cal_q0  | 0.053    |
| loss_diff    | 0.545    |
| loss_diff_q0 | 0.545    |
| loss_q0      | 0.545    |
| param_norm   | 228      |
| samples      | 246      |
| step         | 245      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.33     |
| loss         | 0.185    |
| loss_cal     | 0.0484   |
| loss_cal_q2  | 0.0484   |
| loss_diff    | 0.185    |
| loss_diff_q2 | 0.185    |
| loss_q2      | 0.185    |
| param_norm   | 228      |
| samples      | 247      |
| step         | 246      |
---------------------------
---------------------------
| grad_norm    | 3.31     |
| loss         | 0.819    |
| loss_cal     | 0.0485   |
| loss_cal_q0  | 0.0485   |
| loss_diff    | 0.819    |
| loss_diff_q0 | 0.819    |
| loss_q0      | 0.819    |
| param_norm   | 228      |
| samples      | 248      |
| step         | 247      |
---------------------------
---------------------------
| grad_norm    | 3.65     |
| loss         | 0.612    |
| loss_cal     | 0.05     |
| loss_cal_q3  | 0.05     |
| loss_diff    | 0.612    |
| loss_diff_q3 | 0.612    |
| loss_q3      | 0.612    |
| param_norm   | 228      |
| samples      | 249      |
| step         | 248      |
---------------------------
---------------------------
| grad_norm    | 5.72     |
| loss         | 0.582    |
| loss_cal     | 0.078    |
| loss_cal_q3  | 0.078    |
| loss_diff    | 0.582    |
| loss_diff_q3 | 0.582    |
| loss_q3      | 0.582    |
| param_norm   | 228      |
| samples      | 250      |
| step         | 249      |
---------------------------
---------------------------
| grad_norm    | 3.12     |
| loss         | 0.184    |
| loss_cal     | 0.0485   |
| loss_cal_q3  | 0.0485   |
| loss_diff    | 0.184    |
| loss_diff_q3 | 0.184    |
| loss_q3      | 0.184    |
| param_norm   | 228      |
| samples      | 251      |
| step         | 250      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.46     |
| loss         | 0.781    |
| loss_cal     | 0.0548   |
| loss_cal_q3  | 0.0548   |
| loss_diff    | 0.781    |
| loss_diff_q3 | 0.781    |
| loss_q3      | 0.781    |
| param_norm   | 228      |
| samples      | 252      |
| step         | 251      |
---------------------------
---------------------------
| grad_norm    | 4.44     |
| loss         | 0.437    |
| loss_cal     | 0.0673   |
| loss_cal_q0  | 0.0673   |
| loss_diff    | 0.437    |
| loss_diff_q0 | 0.437    |
| loss_q0      | 0.437    |
| param_norm   | 228      |
| samples      | 253      |
| step         | 252      |
---------------------------
---------------------------
| grad_norm    | 3.28     |
| loss         | 0.255    |
| loss_cal     | 0.0487   |
| loss_cal_q3  | 0.0487   |
| loss_diff    | 0.255    |
| loss_diff_q3 | 0.255    |
| loss_q3      | 0.255    |
| param_norm   | 228      |
| samples      | 254      |
| step         | 253      |
---------------------------
---------------------------
| grad_norm    | 3.08     |
| loss         | 0.214    |
| loss_cal     | 0.0489   |
| loss_cal_q3  | 0.0489   |
| loss_diff    | 0.214    |
| loss_diff_q3 | 0.214    |
| loss_q3      | 0.214    |
| param_norm   | 228      |
| samples      | 255      |
| step         | 254      |
---------------------------
---------------------------
| grad_norm    | 5.46     |
| loss         | 0.644    |
| loss_cal     | 0.0803   |
| loss_cal_q0  | 0.0803   |
| loss_diff    | 0.644    |
| loss_diff_q0 | 0.644    |
| loss_q0      | 0.644    |
| param_norm   | 228      |
| samples      | 256      |
| step         | 255      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.51     |
| loss         | 0.482    |
| loss_cal     | 0.0615   |
| loss_cal_q3  | 0.0615   |
| loss_diff    | 0.482    |
| loss_diff_q3 | 0.482    |
| loss_q3      | 0.482    |
| param_norm   | 228      |
| samples      | 257      |
| step         | 256      |
---------------------------
---------------------------
| grad_norm    | 3.26     |
| loss         | 0.496    |
| loss_cal     | 0.0592   |
| loss_cal_q0  | 0.0592   |
| loss_diff    | 0.496    |
| loss_diff_q0 | 0.496    |
| loss_q0      | 0.496    |
| param_norm   | 228      |
| samples      | 258      |
| step         | 257      |
---------------------------
---------------------------
| grad_norm    | 3.06     |
| loss         | 0.383    |
| loss_cal     | 0.0492   |
| loss_cal_q1  | 0.0492   |
| loss_diff    | 0.383    |
| loss_diff_q1 | 0.383    |
| loss_q1      | 0.383    |
| param_norm   | 228      |
| samples      | 259      |
| step         | 258      |
---------------------------
---------------------------
| grad_norm    | 3.22     |
| loss         | 0.155    |
| loss_cal     | 0.0481   |
| loss_cal_q2  | 0.0481   |
| loss_diff    | 0.155    |
| loss_diff_q2 | 0.155    |
| loss_q2      | 0.155    |
| param_norm   | 228      |
| samples      | 260      |
| step         | 259      |
---------------------------
---------------------------
| grad_norm    | 2.66     |
| loss         | 0.206    |
| loss_cal     | 0.0472   |
| loss_cal_q0  | 0.0472   |
| loss_diff    | 0.206    |
| loss_diff_q0 | 0.206    |
| loss_q0      | 0.206    |
| param_norm   | 228      |
| samples      | 261      |
| step         | 260      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.51     |
| loss         | 0.575    |
| loss_cal     | 0.0687   |
| loss_cal_q2  | 0.0687   |
| loss_diff    | 0.575    |
| loss_diff_q2 | 0.575    |
| loss_q2      | 0.575    |
| param_norm   | 228      |
| samples      | 262      |
| step         | 261      |
---------------------------
---------------------------
| grad_norm    | 5.46     |
| loss         | 0.701    |
| loss_cal     | 0.0846   |
| loss_cal_q2  | 0.0846   |
| loss_diff    | 0.701    |
| loss_diff_q2 | 0.701    |
| loss_q2      | 0.701    |
| param_norm   | 228      |
| samples      | 263      |
| step         | 262      |
---------------------------
---------------------------
| grad_norm    | 2.48     |
| loss         | 0.281    |
| loss_cal     | 0.0468   |
| loss_cal_q1  | 0.0468   |
| loss_diff    | 0.281    |
| loss_diff_q1 | 0.281    |
| loss_q1      | 0.281    |
| param_norm   | 228      |
| samples      | 264      |
| step         | 263      |
---------------------------
---------------------------
| grad_norm    | 4.14     |
| loss         | 0.434    |
| loss_cal     | 0.111    |
| loss_cal_q3  | 0.111    |
| loss_diff    | 0.434    |
| loss_diff_q3 | 0.434    |
| loss_q3      | 0.434    |
| param_norm   | 228      |
| samples      | 265      |
| step         | 264      |
---------------------------
---------------------------
| grad_norm    | 5.12     |
| loss         | 0.413    |
| loss_cal     | 0.0485   |
| loss_cal_q0  | 0.0485   |
| loss_diff    | 0.413    |
| loss_diff_q0 | 0.413    |
| loss_q0      | 0.413    |
| param_norm   | 228      |
| samples      | 266      |
| step         | 265      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.34     |
| loss         | 0.364    |
| loss_cal     | 0.0593   |
| loss_cal_q1  | 0.0593   |
| loss_diff    | 0.364    |
| loss_diff_q1 | 0.364    |
| loss_q1      | 0.364    |
| param_norm   | 228      |
| samples      | 267      |
| step         | 266      |
---------------------------
---------------------------
| grad_norm    | 2.77     |
| loss         | 0.342    |
| loss_cal     | 0.0489   |
| loss_cal_q3  | 0.0489   |
| loss_diff    | 0.342    |
| loss_diff_q3 | 0.342    |
| loss_q3      | 0.342    |
| param_norm   | 228      |
| samples      | 268      |
| step         | 267      |
---------------------------
---------------------------
| grad_norm    | 4.29     |
| loss         | 0.306    |
| loss_cal     | 0.0467   |
| loss_cal_q0  | 0.0467   |
| loss_diff    | 0.306    |
| loss_diff_q0 | 0.306    |
| loss_q0      | 0.306    |
| param_norm   | 228      |
| samples      | 269      |
| step         | 268      |
---------------------------
---------------------------
| grad_norm    | 4        |
| loss         | 0.819    |
| loss_cal     | 0.0517   |
| loss_cal_q0  | 0.0517   |
| loss_diff    | 0.819    |
| loss_diff_q0 | 0.819    |
| loss_q0      | 0.819    |
| param_norm   | 228      |
| samples      | 270      |
| step         | 269      |
---------------------------
---------------------------
| grad_norm    | 2.53     |
| loss         | 0.261    |
| loss_cal     | 0.0487   |
| loss_cal_q0  | 0.0487   |
| loss_diff    | 0.261    |
| loss_diff_q0 | 0.261    |
| loss_q0      | 0.261    |
| param_norm   | 228      |
| samples      | 271      |
| step         | 270      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 9.94     |
| loss         | 0.114    |
| loss_cal     | 0.0463   |
| loss_cal_q3  | 0.0463   |
| loss_diff    | 0.114    |
| loss_diff_q3 | 0.114    |
| loss_q3      | 0.114    |
| param_norm   | 228      |
| samples      | 272      |
| step         | 271      |
---------------------------
---------------------------
| grad_norm    | 2.35     |
| loss         | 0.147    |
| loss_cal     | 0.0453   |
| loss_cal_q2  | 0.0453   |
| loss_diff    | 0.147    |
| loss_diff_q2 | 0.147    |
| loss_q2      | 0.147    |
| param_norm   | 228      |
| samples      | 273      |
| step         | 272      |
---------------------------
---------------------------
| grad_norm    | 4.24     |
| loss         | 0.651    |
| loss_cal     | 0.0507   |
| loss_cal_q0  | 0.0507   |
| loss_diff    | 0.651    |
| loss_diff_q0 | 0.651    |
| loss_q0      | 0.651    |
| param_norm   | 228      |
| samples      | 274      |
| step         | 273      |
---------------------------
---------------------------
| grad_norm    | 2.57     |
| loss         | 0.936    |
| loss_cal     | 0.0496   |
| loss_cal_q0  | 0.0496   |
| loss_diff    | 0.936    |
| loss_diff_q0 | 0.936    |
| loss_q0      | 0.936    |
| param_norm   | 228      |
| samples      | 275      |
| step         | 274      |
---------------------------
---------------------------
| grad_norm    | 2.4      |
| loss         | 0.133    |
| loss_cal     | 0.0466   |
| loss_cal_q0  | 0.0466   |
| loss_diff    | 0.133    |
| loss_diff_q0 | 0.133    |
| loss_q0      | 0.133    |
| param_norm   | 228      |
| samples      | 276      |
| step         | 275      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.1      |
| loss         | 0.195    |
| loss_cal     | 0.0453   |
| loss_cal_q0  | 0.0453   |
| loss_diff    | 0.195    |
| loss_diff_q0 | 0.195    |
| loss_q0      | 0.195    |
| param_norm   | 228      |
| samples      | 277      |
| step         | 276      |
---------------------------
---------------------------
| grad_norm    | 2.26     |
| loss         | 0.205    |
| loss_cal     | 0.0446   |
| loss_cal_q0  | 0.0446   |
| loss_diff    | 0.205    |
| loss_diff_q0 | 0.205    |
| loss_q0      | 0.205    |
| param_norm   | 228      |
| samples      | 278      |
| step         | 277      |
---------------------------
---------------------------
| grad_norm    | 2.34     |
| loss         | 0.252    |
| loss_cal     | 0.0464   |
| loss_cal_q1  | 0.0464   |
| loss_diff    | 0.252    |
| loss_diff_q1 | 0.252    |
| loss_q1      | 0.252    |
| param_norm   | 228      |
| samples      | 279      |
| step         | 278      |
---------------------------
---------------------------
| grad_norm    | 2.63     |
| loss         | 0.214    |
| loss_cal     | 0.0456   |
| loss_cal_q0  | 0.0456   |
| loss_diff    | 0.214    |
| loss_diff_q0 | 0.214    |
| loss_q0      | 0.214    |
| param_norm   | 228      |
| samples      | 280      |
| step         | 279      |
---------------------------
---------------------------
| grad_norm    | 4.45     |
| loss         | 0.468    |
| loss_cal     | 0.0668   |
| loss_cal_q2  | 0.0668   |
| loss_diff    | 0.468    |
| loss_diff_q2 | 0.468    |
| loss_q2      | 0.468    |
| param_norm   | 228      |
| samples      | 281      |
| step         | 280      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.06     |
| loss         | 0.175    |
| loss_cal     | 0.0451   |
| loss_cal_q2  | 0.0451   |
| loss_diff    | 0.175    |
| loss_diff_q2 | 0.175    |
| loss_q2      | 0.175    |
| param_norm   | 228      |
| samples      | 282      |
| step         | 281      |
---------------------------
---------------------------
| grad_norm    | 3.23     |
| loss         | 0.35     |
| loss_cal     | 0.081    |
| loss_cal_q2  | 0.081    |
| loss_diff    | 0.35     |
| loss_diff_q2 | 0.35     |
| loss_q2      | 0.35     |
| param_norm   | 228      |
| samples      | 283      |
| step         | 282      |
---------------------------
---------------------------
| grad_norm    | 1.9      |
| loss         | 0.162    |
| loss_cal     | 0.0437   |
| loss_cal_q1  | 0.0437   |
| loss_diff    | 0.162    |
| loss_diff_q1 | 0.162    |
| loss_q1      | 0.162    |
| param_norm   | 228      |
| samples      | 284      |
| step         | 283      |
---------------------------
---------------------------
| grad_norm    | 4.43     |
| loss         | 0.579    |
| loss_cal     | 0.0526   |
| loss_cal_q0  | 0.0526   |
| loss_diff    | 0.579    |
| loss_diff_q0 | 0.579    |
| loss_q0      | 0.579    |
| param_norm   | 228      |
| samples      | 285      |
| step         | 284      |
---------------------------
---------------------------
| grad_norm    | 15.4     |
| loss         | 0.074    |
| loss_cal     | 0.0433   |
| loss_cal_q3  | 0.0433   |
| loss_diff    | 0.074    |
| loss_diff_q3 | 0.074    |
| loss_q3      | 0.074    |
| param_norm   | 228      |
| samples      | 286      |
| step         | 285      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.08     |
| loss         | 0.176    |
| loss_cal     | 0.0456   |
| loss_cal_q2  | 0.0456   |
| loss_diff    | 0.176    |
| loss_diff_q2 | 0.176    |
| loss_q2      | 0.176    |
| param_norm   | 228      |
| samples      | 287      |
| step         | 286      |
---------------------------
---------------------------
| grad_norm    | 20.9     |
| loss         | 0.0691   |
| loss_cal     | 0.0443   |
| loss_cal_q2  | 0.0443   |
| loss_diff    | 0.0691   |
| loss_diff_q2 | 0.0691   |
| loss_q2      | 0.0691   |
| param_norm   | 228      |
| samples      | 288      |
| step         | 287      |
---------------------------
---------------------------
| grad_norm    | 4.51     |
| loss         | 0.872    |
| loss_cal     | 0.0582   |
| loss_cal_q0  | 0.0582   |
| loss_diff    | 0.872    |
| loss_diff_q0 | 0.872    |
| loss_q0      | 0.872    |
| param_norm   | 228      |
| samples      | 289      |
| step         | 288      |
---------------------------
---------------------------
| grad_norm    | 2.41     |
| loss         | 0.178    |
| loss_cal     | 0.0446   |
| loss_cal_q3  | 0.0446   |
| loss_diff    | 0.178    |
| loss_diff_q3 | 0.178    |
| loss_q3      | 0.178    |
| param_norm   | 228      |
| samples      | 290      |
| step         | 289      |
---------------------------
---------------------------
| grad_norm    | 2.74     |
| loss         | 0.294    |
| loss_cal     | 0.0438   |
| loss_cal_q2  | 0.0438   |
| loss_diff    | 0.294    |
| loss_diff_q2 | 0.294    |
| loss_q2      | 0.294    |
| param_norm   | 228      |
| samples      | 291      |
| step         | 290      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.62     |
| loss         | 0.31     |
| loss_cal     | 0.057    |
| loss_cal_q1  | 0.057    |
| loss_diff    | 0.31     |
| loss_diff_q1 | 0.31     |
| loss_q1      | 0.31     |
| param_norm   | 228      |
| samples      | 292      |
| step         | 291      |
---------------------------
---------------------------
| grad_norm    | 1.91     |
| loss         | 0.166    |
| loss_cal     | 0.0435   |
| loss_cal_q1  | 0.0435   |
| loss_diff    | 0.166    |
| loss_diff_q1 | 0.166    |
| loss_q1      | 0.166    |
| param_norm   | 228      |
| samples      | 293      |
| step         | 292      |
---------------------------
---------------------------
| grad_norm    | 2.67     |
| loss         | 0.297    |
| loss_cal     | 0.0468   |
| loss_cal_q1  | 0.0468   |
| loss_diff    | 0.297    |
| loss_diff_q1 | 0.297    |
| loss_q1      | 0.297    |
| param_norm   | 228      |
| samples      | 294      |
| step         | 293      |
---------------------------
---------------------------
| grad_norm    | 1.93     |
| loss         | 0.103    |
| loss_cal     | 0.042    |
| loss_cal_q0  | 0.042    |
| loss_diff    | 0.103    |
| loss_diff_q0 | 0.103    |
| loss_q0      | 0.103    |
| param_norm   | 228      |
| samples      | 295      |
| step         | 294      |
---------------------------
---------------------------
| grad_norm    | 2.79     |
| loss         | 0.374    |
| loss_cal     | 0.0748   |
| loss_cal_q3  | 0.0748   |
| loss_diff    | 0.374    |
| loss_diff_q3 | 0.374    |
| loss_q3      | 0.374    |
| param_norm   | 228      |
| samples      | 296      |
| step         | 295      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 12.8     |
| loss         | 0.0699   |
| loss_cal     | 0.0418   |
| loss_cal_q2  | 0.0418   |
| loss_diff    | 0.0699   |
| loss_diff_q2 | 0.0699   |
| loss_q2      | 0.0699   |
| param_norm   | 228      |
| samples      | 297      |
| step         | 296      |
---------------------------
---------------------------
| grad_norm    | 14.1     |
| loss         | 0.0625   |
| loss_cal     | 0.0421   |
| loss_cal_q3  | 0.0421   |
| loss_diff    | 0.0625   |
| loss_diff_q3 | 0.0625   |
| loss_q3      | 0.0625   |
| param_norm   | 228      |
| samples      | 298      |
| step         | 297      |
---------------------------
---------------------------
| grad_norm    | 2.49     |
| loss         | 0.302    |
| loss_cal     | 0.0596   |
| loss_cal_q0  | 0.0596   |
| loss_diff    | 0.302    |
| loss_diff_q0 | 0.302    |
| loss_q0      | 0.302    |
| param_norm   | 228      |
| samples      | 299      |
| step         | 298      |
---------------------------
---------------------------
| grad_norm    | 1.95     |
| loss         | 0.123    |
| loss_cal     | 0.0432   |
| loss_cal_q1  | 0.0432   |
| loss_diff    | 0.123    |
| loss_diff_q1 | 0.123    |
| loss_q1      | 0.123    |
| param_norm   | 228      |
| samples      | 300      |
| step         | 299      |
---------------------------
---------------------------
| grad_norm    | 2.03     |
| loss         | 0.194    |
| loss_cal     | 0.0427   |
| loss_cal_q2  | 0.0427   |
| loss_diff    | 0.194    |
| loss_diff_q2 | 0.194    |
| loss_q2      | 0.194    |
| param_norm   | 228      |
| samples      | 301      |
| step         | 300      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.96     |
| loss         | 0.82     |
| loss_cal     | 0.0624   |
| loss_cal_q0  | 0.0624   |
| loss_diff    | 0.82     |
| loss_diff_q0 | 0.82     |
| loss_q0      | 0.82     |
| param_norm   | 228      |
| samples      | 302      |
| step         | 301      |
---------------------------
---------------------------
| grad_norm    | 1.88     |
| loss         | 0.0859   |
| loss_cal     | 0.0416   |
| loss_cal_q2  | 0.0416   |
| loss_diff    | 0.0859   |
| loss_diff_q2 | 0.0859   |
| loss_q2      | 0.0859   |
| param_norm   | 228      |
| samples      | 303      |
| step         | 302      |
---------------------------
---------------------------
| grad_norm    | 2.7      |
| loss         | 0.983    |
| loss_cal     | 0.0637   |
| loss_cal_q0  | 0.0637   |
| loss_diff    | 0.983    |
| loss_diff_q0 | 0.983    |
| loss_q0      | 0.983    |
| param_norm   | 228      |
| samples      | 304      |
| step         | 303      |
---------------------------
---------------------------
| grad_norm    | 2.69     |
| loss         | 0.252    |
| loss_cal     | 0.0631   |
| loss_cal_q0  | 0.0631   |
| loss_diff    | 0.252    |
| loss_diff_q0 | 0.252    |
| loss_q0      | 0.252    |
| param_norm   | 228      |
| samples      | 305      |
| step         | 304      |
---------------------------
---------------------------
| grad_norm    | 3.04     |
| loss         | 0.94     |
| loss_cal     | 0.0529   |
| loss_cal_q0  | 0.0529   |
| loss_diff    | 0.94     |
| loss_diff_q0 | 0.94     |
| loss_q0      | 0.94     |
| param_norm   | 228      |
| samples      | 306      |
| step         | 305      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.45     |
| loss         | 0.288    |
| loss_cal     | 0.0556   |
| loss_cal_q3  | 0.0556   |
| loss_diff    | 0.288    |
| loss_diff_q3 | 0.288    |
| loss_q3      | 0.288    |
| param_norm   | 228      |
| samples      | 307      |
| step         | 306      |
---------------------------
---------------------------
| grad_norm    | 5.11     |
| loss         | 0.691    |
| loss_cal     | 0.0524   |
| loss_cal_q0  | 0.0524   |
| loss_diff    | 0.691    |
| loss_diff_q0 | 0.691    |
| loss_q0      | 0.691    |
| param_norm   | 228      |
| samples      | 308      |
| step         | 307      |
---------------------------
---------------------------
| grad_norm    | 13.7     |
| loss         | 0.0511   |
| loss_cal     | 0.0404   |
| loss_cal_q3  | 0.0404   |
| loss_diff    | 0.0511   |
| loss_diff_q3 | 0.0511   |
| loss_q3      | 0.0511   |
| param_norm   | 228      |
| samples      | 309      |
| step         | 308      |
---------------------------
---------------------------
| grad_norm    | 2.23     |
| loss         | 0.235    |
| loss_cal     | 0.0445   |
| loss_cal_q3  | 0.0445   |
| loss_diff    | 0.235    |
| loss_diff_q3 | 0.235    |
| loss_q3      | 0.235    |
| param_norm   | 228      |
| samples      | 310      |
| step         | 309      |
---------------------------
---------------------------
| grad_norm    | 2        |
| loss         | 0.104    |
| loss_cal     | 0.04     |
| loss_cal_q3  | 0.04     |
| loss_diff    | 0.104    |
| loss_diff_q3 | 0.104    |
| loss_q3      | 0.104    |
| param_norm   | 228      |
| samples      | 311      |
| step         | 310      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.3      |
| loss         | 0.263    |
| loss_cal     | 0.0394   |
| loss_cal_q0  | 0.0394   |
| loss_diff    | 0.263    |
| loss_diff_q0 | 0.263    |
| loss_q0      | 0.263    |
| param_norm   | 228      |
| samples      | 312      |
| step         | 311      |
---------------------------
---------------------------
| grad_norm    | 11.8     |
| loss         | 0.0506   |
| loss_cal     | 0.0395   |
| loss_cal_q1  | 0.0395   |
| loss_diff    | 0.0506   |
| loss_diff_q1 | 0.0506   |
| loss_q1      | 0.0506   |
| param_norm   | 228      |
| samples      | 313      |
| step         | 312      |
---------------------------
---------------------------
| grad_norm    | 4.28     |
| loss         | 0.38     |
| loss_cal     | 0.0649   |
| loss_cal_q2  | 0.0649   |
| loss_diff    | 0.38     |
| loss_diff_q2 | 0.38     |
| loss_q2      | 0.38     |
| param_norm   | 228      |
| samples      | 314      |
| step         | 313      |
---------------------------
---------------------------
| grad_norm    | 9.01     |
| loss         | 0.0543   |
| loss_cal     | 0.0401   |
| loss_cal_q3  | 0.0401   |
| loss_diff    | 0.0543   |
| loss_diff_q3 | 0.0543   |
| loss_q3      | 0.0543   |
| param_norm   | 228      |
| samples      | 315      |
| step         | 314      |
---------------------------
---------------------------
| grad_norm    | 3.32     |
| loss         | 0.342    |
| loss_cal     | 0.0409   |
| loss_cal_q0  | 0.0409   |
| loss_diff    | 0.342    |
| loss_diff_q0 | 0.342    |
| loss_q0      | 0.342    |
| param_norm   | 228      |
| samples      | 316      |
| step         | 315      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.86     |
| loss         | 0.329    |
| loss_cal     | 0.0461   |
| loss_cal_q1  | 0.0461   |
| loss_diff    | 0.329    |
| loss_diff_q1 | 0.329    |
| loss_q1      | 0.329    |
| param_norm   | 228      |
| samples      | 317      |
| step         | 316      |
---------------------------
---------------------------
| grad_norm    | 2.14     |
| loss         | 0.247    |
| loss_cal     | 0.0408   |
| loss_cal_q0  | 0.0408   |
| loss_diff    | 0.247    |
| loss_diff_q0 | 0.247    |
| loss_q0      | 0.247    |
| param_norm   | 228      |
| samples      | 318      |
| step         | 317      |
---------------------------
---------------------------
| grad_norm    | 2.09     |
| loss         | 0.231    |
| loss_cal     | 0.0424   |
| loss_cal_q2  | 0.0424   |
| loss_diff    | 0.231    |
| loss_diff_q2 | 0.231    |
| loss_q2      | 0.231    |
| param_norm   | 228      |
| samples      | 319      |
| step         | 318      |
---------------------------
---------------------------
| grad_norm    | 9.32     |
| loss         | 0.0571   |
| loss_cal     | 0.0393   |
| loss_cal_q2  | 0.0393   |
| loss_diff    | 0.0571   |
| loss_diff_q2 | 0.0571   |
| loss_q2      | 0.0571   |
| param_norm   | 228      |
| samples      | 320      |
| step         | 319      |
---------------------------
---------------------------
| grad_norm    | 3.18     |
| loss         | 0.343    |
| loss_cal     | 0.0677   |
| loss_cal_q2  | 0.0677   |
| loss_diff    | 0.343    |
| loss_diff_q2 | 0.343    |
| loss_q2      | 0.343    |
| param_norm   | 228      |
| samples      | 321      |
| step         | 320      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.93     |
| loss         | 0.136    |
| loss_cal     | 0.0387   |
| loss_cal_q3  | 0.0387   |
| loss_diff    | 0.136    |
| loss_diff_q3 | 0.136    |
| loss_q3      | 0.136    |
| param_norm   | 228      |
| samples      | 322      |
| step         | 321      |
---------------------------
---------------------------
| grad_norm    | 3.29     |
| loss         | 0.41     |
| loss_cal     | 0.0674   |
| loss_cal_q1  | 0.0674   |
| loss_diff    | 0.41     |
| loss_diff_q1 | 0.41     |
| loss_q1      | 0.41     |
| param_norm   | 228      |
| samples      | 323      |
| step         | 322      |
---------------------------
---------------------------
| grad_norm    | 1.81     |
| loss         | 0.129    |
| loss_cal     | 0.0407   |
| loss_cal_q2  | 0.0407   |
| loss_diff    | 0.129    |
| loss_diff_q2 | 0.129    |
| loss_q2      | 0.129    |
| param_norm   | 228      |
| samples      | 324      |
| step         | 323      |
---------------------------
---------------------------
| grad_norm    | 3.19     |
| loss         | 0.852    |
| loss_cal     | 0.0675   |
| loss_cal_q0  | 0.0675   |
| loss_diff    | 0.852    |
| loss_diff_q0 | 0.852    |
| loss_q0      | 0.852    |
| param_norm   | 228      |
| samples      | 325      |
| step         | 324      |
---------------------------
---------------------------
| grad_norm    | 2.36     |
| loss         | 0.219    |
| loss_cal     | 0.0556   |
| loss_cal_q2  | 0.0556   |
| loss_diff    | 0.219    |
| loss_diff_q2 | 0.219    |
| loss_q2      | 0.219    |
| param_norm   | 228      |
| samples      | 326      |
| step         | 325      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.24     |
| loss         | 0.21     |
| loss_cal     | 0.0414   |
| loss_cal_q1  | 0.0414   |
| loss_diff    | 0.21     |
| loss_diff_q1 | 0.21     |
| loss_q1      | 0.21     |
| param_norm   | 228      |
| samples      | 327      |
| step         | 326      |
---------------------------
---------------------------
| grad_norm    | 3.64     |
| loss         | 0.327    |
| loss_cal     | 0.0498   |
| loss_cal_q1  | 0.0498   |
| loss_diff    | 0.327    |
| loss_diff_q1 | 0.327    |
| loss_q1      | 0.327    |
| param_norm   | 228      |
| samples      | 328      |
| step         | 327      |
---------------------------
---------------------------
| grad_norm    | 4.5      |
| loss         | 0.735    |
| loss_cal     | 0.0486   |
| loss_cal_q0  | 0.0486   |
| loss_diff    | 0.735    |
| loss_diff_q0 | 0.735    |
| loss_q0      | 0.735    |
| param_norm   | 228      |
| samples      | 329      |
| step         | 328      |
---------------------------
---------------------------
| grad_norm    | 1.85     |
| loss         | 0.0899   |
| loss_cal     | 0.0395   |
| loss_cal_q1  | 0.0395   |
| loss_diff    | 0.0899   |
| loss_diff_q1 | 0.0899   |
| loss_q1      | 0.0899   |
| param_norm   | 228      |
| samples      | 330      |
| step         | 329      |
---------------------------
---------------------------
| grad_norm    | 3.75     |
| loss         | 0.324    |
| loss_cal     | 0.0727   |
| loss_cal_q2  | 0.0727   |
| loss_diff    | 0.324    |
| loss_diff_q2 | 0.324    |
| loss_q2      | 0.324    |
| param_norm   | 228      |
| samples      | 331      |
| step         | 330      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.54     |
| loss         | 0.338    |
| loss_cal     | 0.0725   |
| loss_cal_q2  | 0.0725   |
| loss_diff    | 0.338    |
| loss_diff_q2 | 0.338    |
| loss_q2      | 0.338    |
| param_norm   | 228      |
| samples      | 332      |
| step         | 331      |
---------------------------
---------------------------
| grad_norm    | 3.88     |
| loss         | 0.435    |
| loss_cal     | 0.0453   |
| loss_cal_q0  | 0.0453   |
| loss_diff    | 0.435    |
| loss_diff_q0 | 0.435    |
| loss_q0      | 0.435    |
| param_norm   | 228      |
| samples      | 333      |
| step         | 332      |
---------------------------
---------------------------
| grad_norm    | 2.25     |
| loss         | 0.202    |
| loss_cal     | 0.0411   |
| loss_cal_q2  | 0.0411   |
| loss_diff    | 0.202    |
| loss_diff_q2 | 0.202    |
| loss_q2      | 0.202    |
| param_norm   | 228      |
| samples      | 334      |
| step         | 333      |
---------------------------
---------------------------
| grad_norm    | 2.14     |
| loss         | 0.24     |
| loss_cal     | 0.0504   |
| loss_cal_q3  | 0.0504   |
| loss_diff    | 0.24     |
| loss_diff_q3 | 0.24     |
| loss_q3      | 0.24     |
| param_norm   | 228      |
| samples      | 335      |
| step         | 334      |
---------------------------
---------------------------
| grad_norm    | 5.06     |
| loss         | 0.55     |
| loss_cal     | 0.0402   |
| loss_cal_q0  | 0.0402   |
| loss_diff    | 0.55     |
| loss_diff_q0 | 0.55     |
| loss_q0      | 0.55     |
| param_norm   | 228      |
| samples      | 336      |
| step         | 335      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.99     |
| loss         | 0.157    |
| loss_cal     | 0.0393   |
| loss_cal_q1  | 0.0393   |
| loss_diff    | 0.157    |
| loss_diff_q1 | 0.157    |
| loss_q1      | 0.157    |
| param_norm   | 228      |
| samples      | 337      |
| step         | 336      |
---------------------------
---------------------------
| grad_norm    | 2.25     |
| loss         | 0.199    |
| loss_cal     | 0.0406   |
| loss_cal_q2  | 0.0406   |
| loss_diff    | 0.199    |
| loss_diff_q2 | 0.199    |
| loss_q2      | 0.199    |
| param_norm   | 228      |
| samples      | 338      |
| step         | 337      |
---------------------------
---------------------------
| grad_norm    | 2.01     |
| loss         | 0.225    |
| loss_cal     | 0.0403   |
| loss_cal_q2  | 0.0403   |
| loss_diff    | 0.225    |
| loss_diff_q2 | 0.225    |
| loss_q2      | 0.225    |
| param_norm   | 228      |
| samples      | 339      |
| step         | 338      |
---------------------------
---------------------------
| grad_norm    | 2.25     |
| loss         | 0.157    |
| loss_cal     | 0.0508   |
| loss_cal_q3  | 0.0508   |
| loss_diff    | 0.157    |
| loss_diff_q3 | 0.157    |
| loss_q3      | 0.157    |
| param_norm   | 228      |
| samples      | 340      |
| step         | 339      |
---------------------------
---------------------------
| grad_norm    | 1.79     |
| loss         | 0.203    |
| loss_cal     | 0.0373   |
| loss_cal_q3  | 0.0373   |
| loss_diff    | 0.203    |
| loss_diff_q3 | 0.203    |
| loss_q3      | 0.203    |
| param_norm   | 228      |
| samples      | 341      |
| step         | 340      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.47     |
| loss         | 0.283    |
| loss_cal     | 0.0397   |
| loss_cal_q0  | 0.0397   |
| loss_diff    | 0.283    |
| loss_diff_q0 | 0.283    |
| loss_q0      | 0.283    |
| param_norm   | 228      |
| samples      | 342      |
| step         | 341      |
---------------------------
---------------------------
| grad_norm    | 2.14     |
| loss         | 0.212    |
| loss_cal     | 0.0381   |
| loss_cal_q1  | 0.0381   |
| loss_diff    | 0.212    |
| loss_diff_q1 | 0.212    |
| loss_q1      | 0.212    |
| param_norm   | 228      |
| samples      | 343      |
| step         | 342      |
---------------------------
---------------------------
| grad_norm    | 2.1      |
| loss         | 0.253    |
| loss_cal     | 0.0383   |
| loss_cal_q1  | 0.0383   |
| loss_diff    | 0.253    |
| loss_diff_q1 | 0.253    |
| loss_q1      | 0.253    |
| param_norm   | 228      |
| samples      | 344      |
| step         | 343      |
---------------------------
---------------------------
| grad_norm    | 1.94     |
| loss         | 0.239    |
| loss_cal     | 0.038    |
| loss_cal_q1  | 0.038    |
| loss_diff    | 0.239    |
| loss_diff_q1 | 0.239    |
| loss_q1      | 0.239    |
| param_norm   | 228      |
| samples      | 345      |
| step         | 344      |
---------------------------
---------------------------
| grad_norm    | 1.69     |
| loss         | 0.0706   |
| loss_cal     | 0.0369   |
| loss_cal_q1  | 0.0369   |
| loss_diff    | 0.0706   |
| loss_diff_q1 | 0.0706   |
| loss_q1      | 0.0706   |
| param_norm   | 228      |
| samples      | 346      |
| step         | 345      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.18     |
| loss         | 0.446    |
| loss_cal     | 0.0604   |
| loss_cal_q2  | 0.0604   |
| loss_diff    | 0.446    |
| loss_diff_q2 | 0.446    |
| loss_q2      | 0.446    |
| param_norm   | 228      |
| samples      | 347      |
| step         | 346      |
---------------------------
---------------------------
| grad_norm    | 2.39     |
| loss         | 0.322    |
| loss_cal     | 0.0438   |
| loss_cal_q3  | 0.0438   |
| loss_diff    | 0.322    |
| loss_diff_q3 | 0.322    |
| loss_q3      | 0.322    |
| param_norm   | 228      |
| samples      | 348      |
| step         | 347      |
---------------------------
---------------------------
| grad_norm    | 3.07     |
| loss         | 0.354    |
| loss_cal     | 0.0717   |
| loss_cal_q1  | 0.0717   |
| loss_diff    | 0.354    |
| loss_diff_q1 | 0.354    |
| loss_q1      | 0.354    |
| param_norm   | 228      |
| samples      | 349      |
| step         | 348      |
---------------------------
---------------------------
| grad_norm    | 3.96     |
| loss         | 0.453    |
| loss_cal     | 0.0545   |
| loss_cal_q0  | 0.0545   |
| loss_diff    | 0.453    |
| loss_diff_q0 | 0.453    |
| loss_q0      | 0.453    |
| param_norm   | 228      |
| samples      | 350      |
| step         | 349      |
---------------------------
---------------------------
| grad_norm    | 3.09     |
| loss         | 0.268    |
| loss_cal     | 0.0719   |
| loss_cal_q2  | 0.0719   |
| loss_diff    | 0.268    |
| loss_diff_q2 | 0.268    |
| loss_q2      | 0.268    |
| param_norm   | 228      |
| samples      | 351      |
| step         | 350      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.8      |
| loss         | 0.173    |
| loss_cal     | 0.0377   |
| loss_cal_q0  | 0.0377   |
| loss_diff    | 0.173    |
| loss_diff_q0 | 0.173    |
| loss_q0      | 0.173    |
| param_norm   | 228      |
| samples      | 352      |
| step         | 351      |
---------------------------
---------------------------
| grad_norm    | 2.87     |
| loss         | 0.19     |
| loss_cal     | 0.0697   |
| loss_cal_q2  | 0.0697   |
| loss_diff    | 0.19     |
| loss_diff_q2 | 0.19     |
| loss_q2      | 0.19     |
| param_norm   | 228      |
| samples      | 353      |
| step         | 352      |
---------------------------
---------------------------
| grad_norm    | 5.13     |
| loss         | 0.0482   |
| loss_cal     | 0.0356   |
| loss_cal_q3  | 0.0356   |
| loss_diff    | 0.0482   |
| loss_diff_q3 | 0.0482   |
| loss_q3      | 0.0482   |
| param_norm   | 228      |
| samples      | 354      |
| step         | 353      |
---------------------------
---------------------------
| grad_norm    | 2.96     |
| loss         | 0.372    |
| loss_cal     | 0.0522   |
| loss_cal_q2  | 0.0522   |
| loss_diff    | 0.372    |
| loss_diff_q2 | 0.372    |
| loss_q2      | 0.372    |
| param_norm   | 228      |
| samples      | 355      |
| step         | 354      |
---------------------------
---------------------------
| grad_norm    | 2.25     |
| loss         | 0.113    |
| loss_cal     | 0.0489   |
| loss_cal_q1  | 0.0489   |
| loss_diff    | 0.113    |
| loss_diff_q1 | 0.113    |
| loss_q1      | 0.113    |
| param_norm   | 228      |
| samples      | 356      |
| step         | 355      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.79     |
| loss         | 0.418    |
| loss_cal     | 0.0527   |
| loss_cal_q1  | 0.0527   |
| loss_diff    | 0.418    |
| loss_diff_q1 | 0.418    |
| loss_q1      | 0.418    |
| param_norm   | 228      |
| samples      | 357      |
| step         | 356      |
---------------------------
---------------------------
| grad_norm    | 2.04     |
| loss         | 0.189    |
| loss_cal     | 0.0366   |
| loss_cal_q2  | 0.0366   |
| loss_diff    | 0.189    |
| loss_diff_q2 | 0.189    |
| loss_q2      | 0.189    |
| param_norm   | 228      |
| samples      | 358      |
| step         | 357      |
---------------------------
---------------------------
| grad_norm    | 1.77     |
| loss         | 0.144    |
| loss_cal     | 0.0377   |
| loss_cal_q1  | 0.0377   |
| loss_diff    | 0.144    |
| loss_diff_q1 | 0.144    |
| loss_q1      | 0.144    |
| param_norm   | 228      |
| samples      | 359      |
| step         | 358      |
---------------------------
---------------------------
| grad_norm    | 3.14     |
| loss         | 0.224    |
| loss_cal     | 0.0393   |
| loss_cal_q3  | 0.0393   |
| loss_diff    | 0.224    |
| loss_diff_q3 | 0.224    |
| loss_q3      | 0.224    |
| param_norm   | 228      |
| samples      | 360      |
| step         | 359      |
---------------------------
---------------------------
| grad_norm    | 4        |
| loss         | 0.395    |
| loss_cal     | 0.0422   |
| loss_cal_q3  | 0.0422   |
| loss_diff    | 0.395    |
| loss_diff_q3 | 0.395    |
| loss_q3      | 0.395    |
| param_norm   | 228      |
| samples      | 361      |
| step         | 360      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.96     |
| loss         | 0.329    |
| loss_cal     | 0.0417   |
| loss_cal_q3  | 0.0417   |
| loss_diff    | 0.329    |
| loss_diff_q3 | 0.329    |
| loss_q3      | 0.329    |
| param_norm   | 228      |
| samples      | 362      |
| step         | 361      |
---------------------------
---------------------------
| grad_norm    | 2.66     |
| loss         | 0.18     |
| loss_cal     | 0.0375   |
| loss_cal_q1  | 0.0375   |
| loss_diff    | 0.18     |
| loss_diff_q1 | 0.18     |
| loss_q1      | 0.18     |
| param_norm   | 228      |
| samples      | 363      |
| step         | 362      |
---------------------------
---------------------------
| grad_norm    | 2.61     |
| loss         | 0.189    |
| loss_cal     | 0.0351   |
| loss_cal_q0  | 0.0351   |
| loss_diff    | 0.189    |
| loss_diff_q0 | 0.189    |
| loss_q0      | 0.189    |
| param_norm   | 228      |
| samples      | 364      |
| step         | 363      |
---------------------------
---------------------------
| grad_norm    | 1.89     |
| loss         | 0.195    |
| loss_cal     | 0.0359   |
| loss_cal_q1  | 0.0359   |
| loss_diff    | 0.195    |
| loss_diff_q1 | 0.195    |
| loss_q1      | 0.195    |
| param_norm   | 228      |
| samples      | 365      |
| step         | 364      |
---------------------------
---------------------------
| grad_norm    | 1.99     |
| loss         | 0.222    |
| loss_cal     | 0.039    |
| loss_cal_q1  | 0.039    |
| loss_diff    | 0.222    |
| loss_diff_q1 | 0.222    |
| loss_q1      | 0.222    |
| param_norm   | 228      |
| samples      | 366      |
| step         | 365      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.65     |
| loss         | 0.117    |
| loss_cal     | 0.0356   |
| loss_cal_q0  | 0.0356   |
| loss_diff    | 0.117    |
| loss_diff_q0 | 0.117    |
| loss_q0      | 0.117    |
| param_norm   | 228      |
| samples      | 367      |
| step         | 366      |
---------------------------
---------------------------
| grad_norm    | 6.94     |
| loss         | 0.859    |
| loss_cal     | 0.0378   |
| loss_cal_q0  | 0.0378   |
| loss_diff    | 0.859    |
| loss_diff_q0 | 0.859    |
| loss_q0      | 0.859    |
| param_norm   | 228      |
| samples      | 368      |
| step         | 367      |
---------------------------
---------------------------
| grad_norm    | 1.61     |
| loss         | 0.0621   |
| loss_cal     | 0.0348   |
| loss_cal_q1  | 0.0348   |
| loss_diff    | 0.0621   |
| loss_diff_q1 | 0.0621   |
| loss_q1      | 0.0621   |
| param_norm   | 228      |
| samples      | 369      |
| step         | 368      |
---------------------------
---------------------------
| grad_norm    | 3.37     |
| loss         | 0.285    |
| loss_cal     | 0.0356   |
| loss_cal_q0  | 0.0356   |
| loss_diff    | 0.285    |
| loss_diff_q0 | 0.285    |
| loss_q0      | 0.285    |
| param_norm   | 228      |
| samples      | 370      |
| step         | 369      |
---------------------------
---------------------------
| grad_norm    | 8.07     |
| loss         | 0.0515   |
| loss_cal     | 0.0341   |
| loss_cal_q3  | 0.0341   |
| loss_diff    | 0.0515   |
| loss_diff_q3 | 0.0515   |
| loss_q3      | 0.0515   |
| param_norm   | 228      |
| samples      | 371      |
| step         | 370      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.98     |
| loss         | 0.694    |
| loss_cal     | 0.0366   |
| loss_cal_q0  | 0.0366   |
| loss_diff    | 0.694    |
| loss_diff_q0 | 0.694    |
| loss_q0      | 0.694    |
| param_norm   | 228      |
| samples      | 372      |
| step         | 371      |
---------------------------
---------------------------
| grad_norm    | 1.89     |
| loss         | 0.242    |
| loss_cal     | 0.0374   |
| loss_cal_q1  | 0.0374   |
| loss_diff    | 0.242    |
| loss_diff_q1 | 0.242    |
| loss_q1      | 0.242    |
| param_norm   | 228      |
| samples      | 373      |
| step         | 372      |
---------------------------
---------------------------
| grad_norm    | 2.48     |
| loss         | 0.336    |
| loss_cal     | 0.0602   |
| loss_cal_q2  | 0.0602   |
| loss_diff    | 0.336    |
| loss_diff_q2 | 0.336    |
| loss_q2      | 0.336    |
| param_norm   | 228      |
| samples      | 374      |
| step         | 373      |
---------------------------
---------------------------
| grad_norm    | 1.7      |
| loss         | 0.163    |
| loss_cal     | 0.0348   |
| loss_cal_q1  | 0.0348   |
| loss_diff    | 0.163    |
| loss_diff_q1 | 0.163    |
| loss_q1      | 0.163    |
| param_norm   | 228      |
| samples      | 375      |
| step         | 374      |
---------------------------
---------------------------
| grad_norm    | 1.56     |
| loss         | 0.0687   |
| loss_cal     | 0.0339   |
| loss_cal_q3  | 0.0339   |
| loss_diff    | 0.0687   |
| loss_diff_q3 | 0.0687   |
| loss_q3      | 0.0687   |
| param_norm   | 228      |
| samples      | 376      |
| step         | 375      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.88     |
| loss         | 0.153    |
| loss_cal     | 0.0356   |
| loss_cal_q3  | 0.0356   |
| loss_diff    | 0.153    |
| loss_diff_q3 | 0.153    |
| loss_q3      | 0.153    |
| param_norm   | 228      |
| samples      | 377      |
| step         | 376      |
---------------------------
---------------------------
| grad_norm    | 3.48     |
| loss         | 0.465    |
| loss_cal     | 0.0556   |
| loss_cal_q0  | 0.0556   |
| loss_diff    | 0.465    |
| loss_diff_q0 | 0.465    |
| loss_q0      | 0.465    |
| param_norm   | 228      |
| samples      | 378      |
| step         | 377      |
---------------------------
---------------------------
| grad_norm    | 1.89     |
| loss         | 0.219    |
| loss_cal     | 0.036    |
| loss_cal_q2  | 0.036    |
| loss_diff    | 0.219    |
| loss_diff_q2 | 0.219    |
| loss_q2      | 0.219    |
| param_norm   | 228      |
| samples      | 379      |
| step         | 378      |
---------------------------
---------------------------
| grad_norm    | 1.62     |
| loss         | 0.141    |
| loss_cal     | 0.0343   |
| loss_cal_q2  | 0.0343   |
| loss_diff    | 0.141    |
| loss_diff_q2 | 0.141    |
| loss_q2      | 0.141    |
| param_norm   | 228      |
| samples      | 380      |
| step         | 379      |
---------------------------
---------------------------
| grad_norm    | 5.96     |
| loss         | 0.0509   |
| loss_cal     | 0.0328   |
| loss_cal_q1  | 0.0328   |
| loss_diff    | 0.0509   |
| loss_diff_q1 | 0.0509   |
| loss_q1      | 0.0509   |
| param_norm   | 228      |
| samples      | 381      |
| step         | 380      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.66     |
| loss         | 0.119    |
| loss_cal     | 0.0344   |
| loss_cal_q2  | 0.0344   |
| loss_diff    | 0.119    |
| loss_diff_q2 | 0.119    |
| loss_q2      | 0.119    |
| param_norm   | 228      |
| samples      | 382      |
| step         | 381      |
---------------------------
---------------------------
| grad_norm    | 2.53     |
| loss         | 0.304    |
| loss_cal     | 0.0499   |
| loss_cal_q3  | 0.0499   |
| loss_diff    | 0.304    |
| loss_diff_q3 | 0.304    |
| loss_q3      | 0.304    |
| param_norm   | 228      |
| samples      | 383      |
| step         | 382      |
---------------------------
---------------------------
| grad_norm    | 1.89     |
| loss         | 0.0818   |
| loss_cal     | 0.0339   |
| loss_cal_q0  | 0.0339   |
| loss_diff    | 0.0818   |
| loss_diff_q0 | 0.0818   |
| loss_q0      | 0.0818   |
| param_norm   | 228      |
| samples      | 384      |
| step         | 383      |
---------------------------
---------------------------
| grad_norm    | 2.08     |
| loss         | 0.314    |
| loss_cal     | 0.035    |
| loss_cal_q3  | 0.035    |
| loss_diff    | 0.314    |
| loss_diff_q3 | 0.314    |
| loss_q3      | 0.314    |
| param_norm   | 228      |
| samples      | 385      |
| step         | 384      |
---------------------------
---------------------------
| grad_norm    | 1.44     |
| loss         | 0.102    |
| loss_cal     | 0.0325   |
| loss_cal_q3  | 0.0325   |
| loss_diff    | 0.102    |
| loss_diff_q3 | 0.102    |
| loss_q3      | 0.102    |
| param_norm   | 228      |
| samples      | 386      |
| step         | 385      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.48     |
| loss         | 0.822    |
| loss_cal     | 0.049    |
| loss_cal_q0  | 0.049    |
| loss_diff    | 0.822    |
| loss_diff_q0 | 0.822    |
| loss_q0      | 0.822    |
| param_norm   | 228      |
| samples      | 387      |
| step         | 386      |
---------------------------
---------------------------
| grad_norm    | 2.16     |
| loss         | 0.293    |
| loss_cal     | 0.0354   |
| loss_cal_q1  | 0.0354   |
| loss_diff    | 0.293    |
| loss_diff_q1 | 0.293    |
| loss_q1      | 0.293    |
| param_norm   | 228      |
| samples      | 388      |
| step         | 387      |
---------------------------
---------------------------
| grad_norm    | 4.06     |
| loss         | 0.387    |
| loss_cal     | 0.0645   |
| loss_cal_q1  | 0.0645   |
| loss_diff    | 0.387    |
| loss_diff_q1 | 0.387    |
| loss_q1      | 0.387    |
| param_norm   | 228      |
| samples      | 389      |
| step         | 388      |
---------------------------
---------------------------
| grad_norm    | 2.35     |
| loss         | 0.296    |
| loss_cal     | 0.05     |
| loss_cal_q1  | 0.05     |
| loss_diff    | 0.296    |
| loss_diff_q1 | 0.296    |
| loss_q1      | 0.296    |
| param_norm   | 228      |
| samples      | 390      |
| step         | 389      |
---------------------------
---------------------------
| grad_norm    | 1.88     |
| loss         | 0.316    |
| loss_cal     | 0.0496   |
| loss_cal_q1  | 0.0496   |
| loss_diff    | 0.316    |
| loss_diff_q1 | 0.316    |
| loss_q1      | 0.316    |
| param_norm   | 228      |
| samples      | 391      |
| step         | 390      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.35     |
| loss         | 0.344    |
| loss_cal     | 0.0357   |
| loss_cal_q1  | 0.0357   |
| loss_diff    | 0.344    |
| loss_diff_q1 | 0.344    |
| loss_q1      | 0.344    |
| param_norm   | 228      |
| samples      | 392      |
| step         | 391      |
---------------------------
---------------------------
| grad_norm    | 2.75     |
| loss         | 0.374    |
| loss_cal     | 0.0379   |
| loss_cal_q3  | 0.0379   |
| loss_diff    | 0.374    |
| loss_diff_q3 | 0.374    |
| loss_q3      | 0.374    |
| param_norm   | 228      |
| samples      | 393      |
| step         | 392      |
---------------------------
---------------------------
| grad_norm    | 2.31     |
| loss         | 0.249    |
| loss_cal     | 0.0359   |
| loss_cal_q2  | 0.0359   |
| loss_diff    | 0.249    |
| loss_diff_q2 | 0.249    |
| loss_q2      | 0.249    |
| param_norm   | 228      |
| samples      | 394      |
| step         | 393      |
---------------------------
---------------------------
| grad_norm    | 4.63     |
| loss         | 0.715    |
| loss_cal     | 0.0641   |
| loss_cal_q0  | 0.0641   |
| loss_diff    | 0.715    |
| loss_diff_q0 | 0.715    |
| loss_q0      | 0.715    |
| param_norm   | 228      |
| samples      | 395      |
| step         | 394      |
---------------------------
---------------------------
| grad_norm    | 2.56     |
| loss         | 0.318    |
| loss_cal     | 0.0521   |
| loss_cal_q3  | 0.0521   |
| loss_diff    | 0.318    |
| loss_diff_q3 | 0.318    |
| loss_q3      | 0.318    |
| param_norm   | 228      |
| samples      | 396      |
| step         | 395      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.86     |
| loss         | 0.977    |
| loss_cal     | 0.0489   |
| loss_cal_q0  | 0.0489   |
| loss_diff    | 0.977    |
| loss_diff_q0 | 0.977    |
| loss_q0      | 0.977    |
| param_norm   | 228      |
| samples      | 397      |
| step         | 396      |
---------------------------
---------------------------
| grad_norm    | 6.94     |
| loss         | 0.0445   |
| loss_cal     | 0.0318   |
| loss_cal_q2  | 0.0318   |
| loss_diff    | 0.0445   |
| loss_diff_q2 | 0.0445   |
| loss_q2      | 0.0445   |
| param_norm   | 228      |
| samples      | 398      |
| step         | 397      |
---------------------------
---------------------------
| grad_norm    | 1.95     |
| loss         | 0.122    |
| loss_cal     | 0.0344   |
| loss_cal_q3  | 0.0344   |
| loss_diff    | 0.122    |
| loss_diff_q3 | 0.122    |
| loss_q3      | 0.122    |
| param_norm   | 228      |
| samples      | 399      |
| step         | 398      |
---------------------------
---------------------------
| grad_norm    | 1.81     |
| loss         | 0.145    |
| loss_cal     | 0.0334   |
| loss_cal_q2  | 0.0334   |
| loss_diff    | 0.145    |
| loss_diff_q2 | 0.145    |
| loss_q2      | 0.145    |
| param_norm   | 228      |
| samples      | 400      |
| step         | 399      |
---------------------------
---------------------------
| grad_norm    | 2.95     |
| loss         | 0.228    |
| loss_cal     | 0.0435   |
| loss_cal_q3  | 0.0435   |
| loss_diff    | 0.228    |
| loss_diff_q3 | 0.228    |
| loss_q3      | 0.228    |
| param_norm   | 228      |
| samples      | 401      |
| step         | 400      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.68     |
| loss         | 0.307    |
| loss_cal     | 0.0381   |
| loss_cal_q3  | 0.0381   |
| loss_diff    | 0.307    |
| loss_diff_q3 | 0.307    |
| loss_q3      | 0.307    |
| param_norm   | 228      |
| samples      | 402      |
| step         | 401      |
---------------------------
---------------------------
| grad_norm    | 2.6      |
| loss         | 0.31     |
| loss_cal     | 0.0552   |
| loss_cal_q2  | 0.0552   |
| loss_diff    | 0.31     |
| loss_diff_q2 | 0.31     |
| loss_q2      | 0.31     |
| param_norm   | 228      |
| samples      | 403      |
| step         | 402      |
---------------------------
---------------------------
| grad_norm    | 2.62     |
| loss         | 0.256    |
| loss_cal     | 0.0377   |
| loss_cal_q2  | 0.0377   |
| loss_diff    | 0.256    |
| loss_diff_q2 | 0.256    |
| loss_q2      | 0.256    |
| param_norm   | 228      |
| samples      | 404      |
| step         | 403      |
---------------------------
---------------------------
| grad_norm    | 2.47     |
| loss         | 0.142    |
| loss_cal     | 0.0348   |
| loss_cal_q1  | 0.0348   |
| loss_diff    | 0.142    |
| loss_diff_q1 | 0.142    |
| loss_q1      | 0.142    |
| param_norm   | 228      |
| samples      | 405      |
| step         | 404      |
---------------------------
---------------------------
| grad_norm    | 2.75     |
| loss         | 0.16     |
| loss_cal     | 0.0492   |
| loss_cal_q2  | 0.0492   |
| loss_diff    | 0.16     |
| loss_diff_q2 | 0.16     |
| loss_q2      | 0.16     |
| param_norm   | 228      |
| samples      | 406      |
| step         | 405      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.21     |
| loss         | 0.207    |
| loss_cal     | 0.0363   |
| loss_cal_q1  | 0.0363   |
| loss_diff    | 0.207    |
| loss_diff_q1 | 0.207    |
| loss_q1      | 0.207    |
| param_norm   | 228      |
| samples      | 407      |
| step         | 406      |
---------------------------
---------------------------
| grad_norm    | 4.29     |
| loss         | 0.29     |
| loss_cal     | 0.0337   |
| loss_cal_q2  | 0.0337   |
| loss_diff    | 0.29     |
| loss_diff_q2 | 0.29     |
| loss_q2      | 0.29     |
| param_norm   | 228      |
| samples      | 408      |
| step         | 407      |
---------------------------
---------------------------
| grad_norm    | 5.18     |
| loss         | 0.275    |
| loss_cal     | 0.0641   |
| loss_cal_q1  | 0.0641   |
| loss_diff    | 0.275    |
| loss_diff_q1 | 0.275    |
| loss_q1      | 0.275    |
| param_norm   | 228      |
| samples      | 409      |
| step         | 408      |
---------------------------
---------------------------
| grad_norm    | 1.78     |
| loss         | 0.161    |
| loss_cal     | 0.0335   |
| loss_cal_q3  | 0.0335   |
| loss_diff    | 0.161    |
| loss_diff_q3 | 0.161    |
| loss_q3      | 0.161    |
| param_norm   | 228      |
| samples      | 410      |
| step         | 409      |
---------------------------
---------------------------
| grad_norm    | 2.94     |
| loss         | 0.277    |
| loss_cal     | 0.0433   |
| loss_cal_q2  | 0.0433   |
| loss_diff    | 0.277    |
| loss_diff_q2 | 0.277    |
| loss_q2      | 0.277    |
| param_norm   | 228      |
| samples      | 411      |
| step         | 410      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.06     |
| loss         | 0.283    |
| loss_cal     | 0.0657   |
| loss_cal_q1  | 0.0657   |
| loss_diff    | 0.283    |
| loss_diff_q1 | 0.283    |
| loss_q1      | 0.283    |
| param_norm   | 228      |
| samples      | 412      |
| step         | 411      |
---------------------------
---------------------------
| grad_norm    | 1.43     |
| loss         | 0.061    |
| loss_cal     | 0.0316   |
| loss_cal_q1  | 0.0316   |
| loss_diff    | 0.061    |
| loss_diff_q1 | 0.061    |
| loss_q1      | 0.061    |
| param_norm   | 228      |
| samples      | 413      |
| step         | 412      |
---------------------------
---------------------------
| grad_norm    | 3.42     |
| loss         | 0.21     |
| loss_cal     | 0.0353   |
| loss_cal_q3  | 0.0353   |
| loss_diff    | 0.21     |
| loss_diff_q3 | 0.21     |
| loss_q3      | 0.21     |
| param_norm   | 228      |
| samples      | 414      |
| step         | 413      |
---------------------------
---------------------------
| grad_norm    | 3.74     |
| loss         | 0.238    |
| loss_cal     | 0.0731   |
| loss_cal_q2  | 0.0731   |
| loss_diff    | 0.238    |
| loss_diff_q2 | 0.238    |
| loss_q2      | 0.238    |
| param_norm   | 228      |
| samples      | 415      |
| step         | 414      |
---------------------------
---------------------------
| grad_norm    | 1.79     |
| loss         | 0.176    |
| loss_cal     | 0.033    |
| loss_cal_q1  | 0.033    |
| loss_diff    | 0.176    |
| loss_diff_q1 | 0.176    |
| loss_q1      | 0.176    |
| param_norm   | 228      |
| samples      | 416      |
| step         | 415      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 5.03     |
| loss         | 0.205    |
| loss_cal     | 0.0505   |
| loss_cal_q1  | 0.0505   |
| loss_diff    | 0.205    |
| loss_diff_q1 | 0.205    |
| loss_q1      | 0.205    |
| param_norm   | 228      |
| samples      | 417      |
| step         | 416      |
---------------------------
---------------------------
| grad_norm    | 7.17     |
| loss         | 0.0468   |
| loss_cal     | 0.0308   |
| loss_cal_q3  | 0.0308   |
| loss_diff    | 0.0468   |
| loss_diff_q3 | 0.0468   |
| loss_q3      | 0.0468   |
| param_norm   | 228      |
| samples      | 418      |
| step         | 417      |
---------------------------
---------------------------
| grad_norm    | 2.98     |
| loss         | 0.184    |
| loss_cal     | 0.0647   |
| loss_cal_q3  | 0.0647   |
| loss_diff    | 0.184    |
| loss_diff_q3 | 0.184    |
| loss_q3      | 0.184    |
| param_norm   | 228      |
| samples      | 419      |
| step         | 418      |
---------------------------
---------------------------
| grad_norm    | 5.11     |
| loss         | 0.308    |
| loss_cal     | 0.0537   |
| loss_cal_q0  | 0.0537   |
| loss_diff    | 0.308    |
| loss_diff_q0 | 0.308    |
| loss_q0      | 0.308    |
| param_norm   | 228      |
| samples      | 420      |
| step         | 419      |
---------------------------
---------------------------
| grad_norm    | 2.78     |
| loss         | 0.201    |
| loss_cal     | 0.0347   |
| loss_cal_q2  | 0.0347   |
| loss_diff    | 0.201    |
| loss_diff_q2 | 0.201    |
| loss_q2      | 0.201    |
| param_norm   | 228      |
| samples      | 421      |
| step         | 420      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.79     |
| loss         | 0.283    |
| loss_cal     | 0.0308   |
| loss_cal_q0  | 0.0308   |
| loss_diff    | 0.283    |
| loss_diff_q0 | 0.283    |
| loss_q0      | 0.283    |
| param_norm   | 228      |
| samples      | 422      |
| step         | 421      |
---------------------------
---------------------------
| grad_norm    | 4.53     |
| loss         | 0.234    |
| loss_cal     | 0.0524   |
| loss_cal_q1  | 0.0524   |
| loss_diff    | 0.234    |
| loss_diff_q1 | 0.234    |
| loss_q1      | 0.234    |
| param_norm   | 228      |
| samples      | 423      |
| step         | 422      |
---------------------------
---------------------------
| grad_norm    | 2.84     |
| loss         | 0.285    |
| loss_cal     | 0.0695   |
| loss_cal_q2  | 0.0695   |
| loss_diff    | 0.285    |
| loss_diff_q2 | 0.285    |
| loss_q2      | 0.285    |
| param_norm   | 228      |
| samples      | 424      |
| step         | 423      |
---------------------------
---------------------------
| grad_norm    | 2.81     |
| loss         | 0.196    |
| loss_cal     | 0.0497   |
| loss_cal_q2  | 0.0497   |
| loss_diff    | 0.196    |
| loss_diff_q2 | 0.196    |
| loss_q2      | 0.196    |
| param_norm   | 228      |
| samples      | 425      |
| step         | 424      |
---------------------------
---------------------------
| grad_norm    | 4.01     |
| loss         | 0.238    |
| loss_cal     | 0.0352   |
| loss_cal_q0  | 0.0352   |
| loss_diff    | 0.238    |
| loss_diff_q0 | 0.238    |
| loss_q0      | 0.238    |
| param_norm   | 228      |
| samples      | 426      |
| step         | 425      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.57     |
| loss         | 0.257    |
| loss_cal     | 0.0673   |
| loss_cal_q3  | 0.0673   |
| loss_diff    | 0.257    |
| loss_diff_q3 | 0.257    |
| loss_q3      | 0.257    |
| param_norm   | 228      |
| samples      | 427      |
| step         | 426      |
---------------------------
---------------------------
| grad_norm    | 2.73     |
| loss         | 0.223    |
| loss_cal     | 0.0576   |
| loss_cal_q3  | 0.0576   |
| loss_diff    | 0.223    |
| loss_diff_q3 | 0.223    |
| loss_q3      | 0.223    |
| param_norm   | 228      |
| samples      | 428      |
| step         | 427      |
---------------------------
---------------------------
| grad_norm    | 2.45     |
| loss         | 0.192    |
| loss_cal     | 0.0358   |
| loss_cal_q2  | 0.0358   |
| loss_diff    | 0.192    |
| loss_diff_q2 | 0.192    |
| loss_q2      | 0.192    |
| param_norm   | 228      |
| samples      | 429      |
| step         | 428      |
---------------------------
---------------------------
| grad_norm    | 3.43     |
| loss         | 0.296    |
| loss_cal     | 0.0584   |
| loss_cal_q1  | 0.0584   |
| loss_diff    | 0.296    |
| loss_diff_q1 | 0.296    |
| loss_q1      | 0.296    |
| param_norm   | 228      |
| samples      | 430      |
| step         | 429      |
---------------------------
---------------------------
| grad_norm    | 2.91     |
| loss         | 0.265    |
| loss_cal     | 0.043    |
| loss_cal_q2  | 0.043    |
| loss_diff    | 0.265    |
| loss_diff_q2 | 0.265    |
| loss_q2      | 0.265    |
| param_norm   | 228      |
| samples      | 431      |
| step         | 430      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.75     |
| loss         | 0.042    |
| loss_cal     | 0.03     |
| loss_cal_q2  | 0.03     |
| loss_diff    | 0.042    |
| loss_diff_q2 | 0.042    |
| loss_q2      | 0.042    |
| param_norm   | 228      |
| samples      | 432      |
| step         | 431      |
---------------------------
---------------------------
| grad_norm    | 7.13     |
| loss         | 0.323    |
| loss_cal     | 0.0728   |
| loss_cal_q1  | 0.0728   |
| loss_diff    | 0.323    |
| loss_diff_q1 | 0.323    |
| loss_q1      | 0.323    |
| param_norm   | 228      |
| samples      | 433      |
| step         | 432      |
---------------------------
---------------------------
| grad_norm    | 3.2      |
| loss         | 0.208    |
| loss_cal     | 0.0368   |
| loss_cal_q1  | 0.0368   |
| loss_diff    | 0.208    |
| loss_diff_q1 | 0.208    |
| loss_q1      | 0.208    |
| param_norm   | 228      |
| samples      | 434      |
| step         | 433      |
---------------------------
---------------------------
| grad_norm    | 1.87     |
| loss         | 0.111    |
| loss_cal     | 0.0305   |
| loss_cal_q0  | 0.0305   |
| loss_diff    | 0.111    |
| loss_diff_q0 | 0.111    |
| loss_q0      | 0.111    |
| param_norm   | 228      |
| samples      | 435      |
| step         | 434      |
---------------------------
---------------------------
| grad_norm    | 4.45     |
| loss         | 0.267    |
| loss_cal     | 0.0631   |
| loss_cal_q1  | 0.0631   |
| loss_diff    | 0.267    |
| loss_diff_q1 | 0.267    |
| loss_q1      | 0.267    |
| param_norm   | 228      |
| samples      | 436      |
| step         | 435      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.16     |
| loss         | 0.196    |
| loss_cal     | 0.048    |
| loss_cal_q2  | 0.048    |
| loss_diff    | 0.196    |
| loss_diff_q2 | 0.196    |
| loss_q2      | 0.196    |
| param_norm   | 228      |
| samples      | 437      |
| step         | 436      |
---------------------------
---------------------------
| grad_norm    | 3.11     |
| loss         | 0.231    |
| loss_cal     | 0.0434   |
| loss_cal_q2  | 0.0434   |
| loss_diff    | 0.231    |
| loss_diff_q2 | 0.231    |
| loss_q2      | 0.231    |
| param_norm   | 228      |
| samples      | 438      |
| step         | 437      |
---------------------------
---------------------------
| grad_norm    | 8.21     |
| loss         | 0.422    |
| loss_cal     | 0.0498   |
| loss_cal_q0  | 0.0498   |
| loss_diff    | 0.422    |
| loss_diff_q0 | 0.422    |
| loss_q0      | 0.422    |
| param_norm   | 228      |
| samples      | 439      |
| step         | 438      |
---------------------------
---------------------------
| grad_norm    | 1.77     |
| loss         | 0.0693   |
| loss_cal     | 0.0321   |
| loss_cal_q1  | 0.0321   |
| loss_diff    | 0.0693   |
| loss_diff_q1 | 0.0693   |
| loss_q1      | 0.0693   |
| param_norm   | 228      |
| samples      | 440      |
| step         | 439      |
---------------------------
---------------------------
| grad_norm    | 2.29     |
| loss         | 0.203    |
| loss_cal     | 0.0371   |
| loss_cal_q2  | 0.0371   |
| loss_diff    | 0.203    |
| loss_diff_q2 | 0.203    |
| loss_q2      | 0.203    |
| param_norm   | 228      |
| samples      | 441      |
| step         | 440      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.13     |
| loss         | 0.174    |
| loss_cal     | 0.0318   |
| loss_cal_q0  | 0.0318   |
| loss_diff    | 0.174    |
| loss_diff_q0 | 0.174    |
| loss_q0      | 0.174    |
| param_norm   | 228      |
| samples      | 442      |
| step         | 441      |
---------------------------
---------------------------
| grad_norm    | 3.2      |
| loss         | 0.237    |
| loss_cal     | 0.0498   |
| loss_cal_q1  | 0.0498   |
| loss_diff    | 0.237    |
| loss_diff_q1 | 0.237    |
| loss_q1      | 0.237    |
| param_norm   | 228      |
| samples      | 443      |
| step         | 442      |
---------------------------
---------------------------
| grad_norm    | 2.26     |
| loss         | 0.157    |
| loss_cal     | 0.0338   |
| loss_cal_q1  | 0.0338   |
| loss_diff    | 0.157    |
| loss_diff_q1 | 0.157    |
| loss_q1      | 0.157    |
| param_norm   | 228      |
| samples      | 444      |
| step         | 443      |
---------------------------
---------------------------
| grad_norm    | 1.97     |
| loss         | 0.168    |
| loss_cal     | 0.0405   |
| loss_cal_q1  | 0.0405   |
| loss_diff    | 0.168    |
| loss_diff_q1 | 0.168    |
| loss_q1      | 0.168    |
| param_norm   | 228      |
| samples      | 445      |
| step         | 444      |
---------------------------
---------------------------
| grad_norm    | 2.53     |
| loss         | 0.241    |
| loss_cal     | 0.0468   |
| loss_cal_q2  | 0.0468   |
| loss_diff    | 0.241    |
| loss_diff_q2 | 0.241    |
| loss_q2      | 0.241    |
| param_norm   | 228      |
| samples      | 446      |
| step         | 445      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.93     |
| loss         | 0.722    |
| loss_cal     | 0.0395   |
| loss_cal_q0  | 0.0395   |
| loss_diff    | 0.722    |
| loss_diff_q0 | 0.722    |
| loss_q0      | 0.722    |
| param_norm   | 228      |
| samples      | 447      |
| step         | 446      |
---------------------------
---------------------------
| grad_norm    | 2.17     |
| loss         | 0.191    |
| loss_cal     | 0.0324   |
| loss_cal_q3  | 0.0324   |
| loss_diff    | 0.191    |
| loss_diff_q3 | 0.191    |
| loss_q3      | 0.191    |
| param_norm   | 228      |
| samples      | 448      |
| step         | 447      |
---------------------------
---------------------------
| grad_norm    | 3.06     |
| loss         | 0.298    |
| loss_cal     | 0.063    |
| loss_cal_q3  | 0.063    |
| loss_diff    | 0.298    |
| loss_diff_q3 | 0.298    |
| loss_q3      | 0.298    |
| param_norm   | 228      |
| samples      | 449      |
| step         | 448      |
---------------------------
---------------------------
| grad_norm    | 2.31     |
| loss         | 0.144    |
| loss_cal     | 0.0326   |
| loss_cal_q3  | 0.0326   |
| loss_diff    | 0.144    |
| loss_diff_q3 | 0.144    |
| loss_q3      | 0.144    |
| param_norm   | 228      |
| samples      | 450      |
| step         | 449      |
---------------------------
---------------------------
| grad_norm    | 2.27     |
| loss         | 0.127    |
| loss_cal     | 0.0304   |
| loss_cal_q1  | 0.0304   |
| loss_diff    | 0.127    |
| loss_diff_q1 | 0.127    |
| loss_q1      | 0.127    |
| param_norm   | 228      |
| samples      | 451      |
| step         | 450      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.48     |
| loss         | 0.073    |
| loss_cal     | 0.0287   |
| loss_cal_q1  | 0.0287   |
| loss_diff    | 0.073    |
| loss_diff_q1 | 0.073    |
| loss_q1      | 0.073    |
| param_norm   | 228      |
| samples      | 452      |
| step         | 451      |
---------------------------
---------------------------
| grad_norm    | 3.1      |
| loss         | 0.196    |
| loss_cal     | 0.0343   |
| loss_cal_q2  | 0.0343   |
| loss_diff    | 0.196    |
| loss_diff_q2 | 0.196    |
| loss_q2      | 0.196    |
| param_norm   | 228      |
| samples      | 453      |
| step         | 452      |
---------------------------
---------------------------
| grad_norm    | 1.37     |
| loss         | 0.0512   |
| loss_cal     | 0.0298   |
| loss_cal_q1  | 0.0298   |
| loss_diff    | 0.0512   |
| loss_diff_q1 | 0.0512   |
| loss_q1      | 0.0512   |
| param_norm   | 228      |
| samples      | 454      |
| step         | 453      |
---------------------------
---------------------------
| grad_norm    | 2.36     |
| loss         | 0.16     |
| loss_cal     | 0.031    |
| loss_cal_q2  | 0.031    |
| loss_diff    | 0.16     |
| loss_diff_q2 | 0.16     |
| loss_q2      | 0.16     |
| param_norm   | 228      |
| samples      | 455      |
| step         | 454      |
---------------------------
---------------------------
| grad_norm    | 3.19     |
| loss         | 0.187    |
| loss_cal     | 0.0306   |
| loss_cal_q2  | 0.0306   |
| loss_diff    | 0.187    |
| loss_diff_q2 | 0.187    |
| loss_q2      | 0.187    |
| param_norm   | 228      |
| samples      | 456      |
| step         | 455      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 5.02     |
| loss         | 0.259    |
| loss_cal     | 0.0558   |
| loss_cal_q0  | 0.0558   |
| loss_diff    | 0.259    |
| loss_diff_q0 | 0.259    |
| loss_q0      | 0.259    |
| param_norm   | 228      |
| samples      | 457      |
| step         | 456      |
---------------------------
---------------------------
| grad_norm    | 1.34     |
| loss         | 0.0556   |
| loss_cal     | 0.0287   |
| loss_cal_q3  | 0.0287   |
| loss_diff    | 0.0556   |
| loss_diff_q3 | 0.0556   |
| loss_q3      | 0.0556   |
| param_norm   | 228      |
| samples      | 458      |
| step         | 457      |
---------------------------
---------------------------
| grad_norm    | 1.9      |
| loss         | 0.157    |
| loss_cal     | 0.0306   |
| loss_cal_q2  | 0.0306   |
| loss_diff    | 0.157    |
| loss_diff_q2 | 0.157    |
| loss_q2      | 0.157    |
| param_norm   | 228      |
| samples      | 459      |
| step         | 458      |
---------------------------
---------------------------
| grad_norm    | 1.7      |
| loss         | 0.143    |
| loss_cal     | 0.0306   |
| loss_cal_q1  | 0.0306   |
| loss_diff    | 0.143    |
| loss_diff_q1 | 0.143    |
| loss_q1      | 0.143    |
| param_norm   | 228      |
| samples      | 460      |
| step         | 459      |
---------------------------
---------------------------
| grad_norm    | 1.66     |
| loss         | 0.108    |
| loss_cal     | 0.0289   |
| loss_cal_q1  | 0.0289   |
| loss_diff    | 0.108    |
| loss_diff_q1 | 0.108    |
| loss_q1      | 0.108    |
| param_norm   | 228      |
| samples      | 461      |
| step         | 460      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.78     |
| loss         | 0.203    |
| loss_cal     | 0.0292   |
| loss_cal_q1  | 0.0292   |
| loss_diff    | 0.203    |
| loss_diff_q1 | 0.203    |
| loss_q1      | 0.203    |
| param_norm   | 228      |
| samples      | 462      |
| step         | 461      |
---------------------------
---------------------------
| grad_norm    | 1.92     |
| loss         | 0.127    |
| loss_cal     | 0.0301   |
| loss_cal_q1  | 0.0301   |
| loss_diff    | 0.127    |
| loss_diff_q1 | 0.127    |
| loss_q1      | 0.127    |
| param_norm   | 228      |
| samples      | 463      |
| step         | 462      |
---------------------------
---------------------------
| grad_norm    | 4.77     |
| loss         | 0.297    |
| loss_cal     | 0.0311   |
| loss_cal_q1  | 0.0311   |
| loss_diff    | 0.297    |
| loss_diff_q1 | 0.297    |
| loss_q1      | 0.297    |
| param_norm   | 228      |
| samples      | 464      |
| step         | 463      |
---------------------------
---------------------------
| grad_norm    | 3.02     |
| loss         | 0.284    |
| loss_cal     | 0.0309   |
| loss_cal_q1  | 0.0309   |
| loss_diff    | 0.284    |
| loss_diff_q1 | 0.284    |
| loss_q1      | 0.284    |
| param_norm   | 228      |
| samples      | 465      |
| step         | 464      |
---------------------------
---------------------------
| grad_norm    | 2.75     |
| loss         | 0.145    |
| loss_cal     | 0.0416   |
| loss_cal_q2  | 0.0416   |
| loss_diff    | 0.145    |
| loss_diff_q2 | 0.145    |
| loss_q2      | 0.145    |
| param_norm   | 228      |
| samples      | 466      |
| step         | 465      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.03     |
| loss         | 0.042    |
| loss_cal     | 0.027    |
| loss_cal_q1  | 0.027    |
| loss_diff    | 0.042    |
| loss_diff_q1 | 0.042    |
| loss_q1      | 0.042    |
| param_norm   | 228      |
| samples      | 467      |
| step         | 466      |
---------------------------
---------------------------
| grad_norm    | 1.66     |
| loss         | 0.151    |
| loss_cal     | 0.0292   |
| loss_cal_q2  | 0.0292   |
| loss_diff    | 0.151    |
| loss_diff_q2 | 0.151    |
| loss_q2      | 0.151    |
| param_norm   | 228      |
| samples      | 468      |
| step         | 467      |
---------------------------
---------------------------
| grad_norm    | 6.28     |
| loss         | 0.315    |
| loss_cal     | 0.0317   |
| loss_cal_q1  | 0.0317   |
| loss_diff    | 0.315    |
| loss_diff_q1 | 0.315    |
| loss_q1      | 0.315    |
| param_norm   | 228      |
| samples      | 469      |
| step         | 468      |
---------------------------
---------------------------
| grad_norm    | 3.69     |
| loss         | 0.224    |
| loss_cal     | 0.0289   |
| loss_cal_q0  | 0.0289   |
| loss_diff    | 0.224    |
| loss_diff_q0 | 0.224    |
| loss_q0      | 0.224    |
| param_norm   | 228      |
| samples      | 470      |
| step         | 469      |
---------------------------
---------------------------
| grad_norm    | 3.17     |
| loss         | 0.149    |
| loss_cal     | 0.0288   |
| loss_cal_q1  | 0.0288   |
| loss_diff    | 0.149    |
| loss_diff_q1 | 0.149    |
| loss_q1      | 0.149    |
| param_norm   | 228      |
| samples      | 471      |
| step         | 470      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.92     |
| loss         | 0.361    |
| loss_cal     | 0.0431   |
| loss_cal_q0  | 0.0431   |
| loss_diff    | 0.361    |
| loss_diff_q0 | 0.361    |
| loss_q0      | 0.361    |
| param_norm   | 228      |
| samples      | 472      |
| step         | 471      |
---------------------------
---------------------------
| grad_norm    | 2.31     |
| loss         | 0.131    |
| loss_cal     | 0.0456   |
| loss_cal_q2  | 0.0456   |
| loss_diff    | 0.131    |
| loss_diff_q2 | 0.131    |
| loss_q2      | 0.131    |
| param_norm   | 228      |
| samples      | 473      |
| step         | 472      |
---------------------------
---------------------------
| grad_norm    | 3.66     |
| loss         | 0.172    |
| loss_cal     | 0.0466   |
| loss_cal_q2  | 0.0466   |
| loss_diff    | 0.172    |
| loss_diff_q2 | 0.172    |
| loss_q2      | 0.172    |
| param_norm   | 228      |
| samples      | 474      |
| step         | 473      |
---------------------------
---------------------------
| grad_norm    | 2.14     |
| loss         | 0.264    |
| loss_cal     | 0.0298   |
| loss_cal_q3  | 0.0298   |
| loss_diff    | 0.264    |
| loss_diff_q3 | 0.264    |
| loss_q3      | 0.264    |
| param_norm   | 228      |
| samples      | 475      |
| step         | 474      |
---------------------------
---------------------------
| grad_norm    | 8.72     |
| loss         | 0.414    |
| loss_cal     | 0.0816   |
| loss_cal_q0  | 0.0816   |
| loss_diff    | 0.414    |
| loss_diff_q0 | 0.414    |
| loss_q0      | 0.414    |
| param_norm   | 228      |
| samples      | 476      |
| step         | 475      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.94     |
| loss         | 0.715    |
| loss_cal     | 0.037    |
| loss_cal_q0  | 0.037    |
| loss_diff    | 0.715    |
| loss_diff_q0 | 0.715    |
| loss_q0      | 0.715    |
| param_norm   | 228      |
| samples      | 477      |
| step         | 476      |
---------------------------
---------------------------
| grad_norm    | 11.6     |
| loss         | 0.0424   |
| loss_cal     | 0.0268   |
| loss_cal_q3  | 0.0268   |
| loss_diff    | 0.0424   |
| loss_diff_q3 | 0.0424   |
| loss_q3      | 0.0424   |
| param_norm   | 228      |
| samples      | 478      |
| step         | 477      |
---------------------------
---------------------------
| grad_norm    | 2.61     |
| loss         | 0.251    |
| loss_cal     | 0.0614   |
| loss_cal_q1  | 0.0614   |
| loss_diff    | 0.251    |
| loss_diff_q1 | 0.251    |
| loss_q1      | 0.251    |
| param_norm   | 228      |
| samples      | 479      |
| step         | 478      |
---------------------------
---------------------------
| grad_norm    | 3.4      |
| loss         | 0.222    |
| loss_cal     | 0.0279   |
| loss_cal_q0  | 0.0279   |
| loss_diff    | 0.222    |
| loss_diff_q0 | 0.222    |
| loss_q0      | 0.222    |
| param_norm   | 228      |
| samples      | 480      |
| step         | 479      |
---------------------------
---------------------------
| grad_norm    | 1.57     |
| loss         | 0.108    |
| loss_cal     | 0.0274   |
| loss_cal_q1  | 0.0274   |
| loss_diff    | 0.108    |
| loss_diff_q1 | 0.108    |
| loss_q1      | 0.108    |
| param_norm   | 228      |
| samples      | 481      |
| step         | 480      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 7.21     |
| loss         | 0.65     |
| loss_cal     | 0.0299   |
| loss_cal_q0  | 0.0299   |
| loss_diff    | 0.65     |
| loss_diff_q0 | 0.65     |
| loss_q0      | 0.65     |
| param_norm   | 228      |
| samples      | 482      |
| step         | 481      |
---------------------------
---------------------------
| grad_norm    | 6.04     |
| loss         | 0.0481   |
| loss_cal     | 0.027    |
| loss_cal_q3  | 0.027    |
| loss_diff    | 0.0481   |
| loss_diff_q3 | 0.0481   |
| loss_q3      | 0.0481   |
| param_norm   | 228      |
| samples      | 483      |
| step         | 482      |
---------------------------
---------------------------
| grad_norm    | 3.85     |
| loss         | 0.318    |
| loss_cal     | 0.0281   |
| loss_cal_q0  | 0.0281   |
| loss_diff    | 0.318    |
| loss_diff_q0 | 0.318    |
| loss_q0      | 0.318    |
| param_norm   | 228      |
| samples      | 484      |
| step         | 483      |
---------------------------
---------------------------
| grad_norm    | 2.93     |
| loss         | 0.257    |
| loss_cal     | 0.0706   |
| loss_cal_q3  | 0.0706   |
| loss_diff    | 0.257    |
| loss_diff_q3 | 0.257    |
| loss_q3      | 0.257    |
| param_norm   | 228      |
| samples      | 485      |
| step         | 484      |
---------------------------
---------------------------
| grad_norm    | 2.36     |
| loss         | 0.172    |
| loss_cal     | 0.0297   |
| loss_cal_q1  | 0.0297   |
| loss_diff    | 0.172    |
| loss_diff_q1 | 0.172    |
| loss_q1      | 0.172    |
| param_norm   | 228      |
| samples      | 486      |
| step         | 485      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.18     |
| loss         | 0.17     |
| loss_cal     | 0.0287   |
| loss_cal_q0  | 0.0287   |
| loss_diff    | 0.17     |
| loss_diff_q0 | 0.17     |
| loss_q0      | 0.17     |
| param_norm   | 228      |
| samples      | 487      |
| step         | 486      |
---------------------------
---------------------------
| grad_norm    | 2.47     |
| loss         | 0.254    |
| loss_cal     | 0.0298   |
| loss_cal_q1  | 0.0298   |
| loss_diff    | 0.254    |
| loss_diff_q1 | 0.254    |
| loss_q1      | 0.254    |
| param_norm   | 228      |
| samples      | 488      |
| step         | 487      |
---------------------------
---------------------------
| grad_norm    | 6.24     |
| loss         | 0.0592   |
| loss_cal     | 0.0261   |
| loss_cal_q2  | 0.0261   |
| loss_diff    | 0.0592   |
| loss_diff_q2 | 0.0592   |
| loss_q2      | 0.0592   |
| param_norm   | 228      |
| samples      | 489      |
| step         | 488      |
---------------------------
---------------------------
| grad_norm    | 2.23     |
| loss         | 0.292    |
| loss_cal     | 0.0292   |
| loss_cal_q1  | 0.0292   |
| loss_diff    | 0.292    |
| loss_diff_q1 | 0.292    |
| loss_q1      | 0.292    |
| param_norm   | 228      |
| samples      | 490      |
| step         | 489      |
---------------------------
---------------------------
| grad_norm    | 2.94     |
| loss         | 0.307    |
| loss_cal     | 0.0374   |
| loss_cal_q3  | 0.0374   |
| loss_diff    | 0.307    |
| loss_diff_q3 | 0.307    |
| loss_q3      | 0.307    |
| param_norm   | 228      |
| samples      | 491      |
| step         | 490      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.3      |
| loss         | 0.116    |
| loss_cal     | 0.0269   |
| loss_cal_q1  | 0.0269   |
| loss_diff    | 0.116    |
| loss_diff_q1 | 0.116    |
| loss_q1      | 0.116    |
| param_norm   | 228      |
| samples      | 492      |
| step         | 491      |
---------------------------
---------------------------
| grad_norm    | 12.6     |
| loss         | 0.0497   |
| loss_cal     | 0.0272   |
| loss_cal_q1  | 0.0272   |
| loss_diff    | 0.0497   |
| loss_diff_q1 | 0.0497   |
| loss_q1      | 0.0497   |
| param_norm   | 228      |
| samples      | 493      |
| step         | 492      |
---------------------------
---------------------------
| grad_norm    | 2.4      |
| loss         | 0.307    |
| loss_cal     | 0.0296   |
| loss_cal_q2  | 0.0296   |
| loss_diff    | 0.307    |
| loss_diff_q2 | 0.307    |
| loss_q2      | 0.307    |
| param_norm   | 228      |
| samples      | 494      |
| step         | 493      |
---------------------------
---------------------------
| grad_norm    | 1.33     |
| loss         | 0.125    |
| loss_cal     | 0.0272   |
| loss_cal_q3  | 0.0272   |
| loss_diff    | 0.125    |
| loss_diff_q3 | 0.125    |
| loss_q3      | 0.125    |
| param_norm   | 228      |
| samples      | 495      |
| step         | 494      |
---------------------------
---------------------------
| grad_norm    | 3.81     |
| loss         | 0.628    |
| loss_cal     | 0.0271   |
| loss_cal_q0  | 0.0271   |
| loss_diff    | 0.628    |
| loss_diff_q0 | 0.628    |
| loss_q0      | 0.628    |
| param_norm   | 228      |
| samples      | 496      |
| step         | 495      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.46     |
| loss         | 0.0911   |
| loss_cal     | 0.0272   |
| loss_cal_q1  | 0.0272   |
| loss_diff    | 0.0911   |
| loss_diff_q1 | 0.0911   |
| loss_q1      | 0.0911   |
| param_norm   | 228      |
| samples      | 497      |
| step         | 496      |
---------------------------
---------------------------
| grad_norm    | 1.41     |
| loss         | 0.11     |
| loss_cal     | 0.0268   |
| loss_cal_q1  | 0.0268   |
| loss_diff    | 0.11     |
| loss_diff_q1 | 0.11     |
| loss_q1      | 0.11     |
| param_norm   | 228      |
| samples      | 498      |
| step         | 497      |
---------------------------
---------------------------
| grad_norm    | 1.39     |
| loss         | 0.121    |
| loss_cal     | 0.0274   |
| loss_cal_q3  | 0.0274   |
| loss_diff    | 0.121    |
| loss_diff_q3 | 0.121    |
| loss_q3      | 0.121    |
| param_norm   | 228      |
| samples      | 499      |
| step         | 498      |
---------------------------
---------------------------
| grad_norm    | 2.71     |
| loss         | 0.201    |
| loss_cal     | 0.0447   |
| loss_cal_q2  | 0.0447   |
| loss_diff    | 0.201    |
| loss_diff_q2 | 0.201    |
| loss_q2      | 0.201    |
| param_norm   | 228      |
| samples      | 500      |
| step         | 499      |
---------------------------
---------------------------
| grad_norm    | 3.76     |
| loss         | 0.326    |
| loss_cal     | 0.0462   |
| loss_cal_q0  | 0.0462   |
| loss_diff    | 0.326    |
| loss_diff_q0 | 0.326    |
| loss_q0      | 0.326    |
| param_norm   | 228      |
| samples      | 501      |
| step         | 500      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.71     |
| loss         | 0.248    |
| loss_cal     | 0.0274   |
| loss_cal_q2  | 0.0274   |
| loss_diff    | 0.248    |
| loss_diff_q2 | 0.248    |
| loss_q2      | 0.248    |
| param_norm   | 228      |
| samples      | 502      |
| step         | 501      |
---------------------------
---------------------------
| grad_norm    | 1.4      |
| loss         | 0.0961   |
| loss_cal     | 0.0269   |
| loss_cal_q1  | 0.0269   |
| loss_diff    | 0.0961   |
| loss_diff_q1 | 0.0961   |
| loss_q1      | 0.0961   |
| param_norm   | 228      |
| samples      | 503      |
| step         | 502      |
---------------------------
---------------------------
| grad_norm    | 3.08     |
| loss         | 0.215    |
| loss_cal     | 0.0288   |
| loss_cal_q2  | 0.0288   |
| loss_diff    | 0.215    |
| loss_diff_q2 | 0.215    |
| loss_q2      | 0.215    |
| param_norm   | 228      |
| samples      | 504      |
| step         | 503      |
---------------------------
---------------------------
| grad_norm    | 5.43     |
| loss         | 0.422    |
| loss_cal     | 0.0282   |
| loss_cal_q0  | 0.0282   |
| loss_diff    | 0.422    |
| loss_diff_q0 | 0.422    |
| loss_q0      | 0.422    |
| param_norm   | 228      |
| samples      | 505      |
| step         | 504      |
---------------------------
---------------------------
| grad_norm    | 6.78     |
| loss         | 0.0432   |
| loss_cal     | 0.0254   |
| loss_cal_q0  | 0.0254   |
| loss_diff    | 0.0432   |
| loss_diff_q0 | 0.0432   |
| loss_q0      | 0.0432   |
| param_norm   | 228      |
| samples      | 506      |
| step         | 505      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.24     |
| loss         | 0.0495   |
| loss_cal     | 0.0257   |
| loss_cal_q2  | 0.0257   |
| loss_diff    | 0.0495   |
| loss_diff_q2 | 0.0495   |
| loss_q2      | 0.0495   |
| param_norm   | 228      |
| samples      | 507      |
| step         | 506      |
---------------------------
---------------------------
| grad_norm    | 1.87     |
| loss         | 0.17     |
| loss_cal     | 0.0274   |
| loss_cal_q3  | 0.0274   |
| loss_diff    | 0.17     |
| loss_diff_q3 | 0.17     |
| loss_q3      | 0.17     |
| param_norm   | 228      |
| samples      | 508      |
| step         | 507      |
---------------------------
---------------------------
| grad_norm    | 3.87     |
| loss         | 0.0441   |
| loss_cal     | 0.0251   |
| loss_cal_q3  | 0.0251   |
| loss_diff    | 0.0441   |
| loss_diff_q3 | 0.0441   |
| loss_q3      | 0.0441   |
| param_norm   | 228      |
| samples      | 509      |
| step         | 508      |
---------------------------
---------------------------
| grad_norm    | 1.69     |
| loss         | 0.0881   |
| loss_cal     | 0.0256   |
| loss_cal_q0  | 0.0256   |
| loss_diff    | 0.0881   |
| loss_diff_q0 | 0.0881   |
| loss_q0      | 0.0881   |
| param_norm   | 228      |
| samples      | 510      |
| step         | 509      |
---------------------------
---------------------------
| grad_norm    | 3.14     |
| loss         | 0.188    |
| loss_cal     | 0.0409   |
| loss_cal_q1  | 0.0409   |
| loss_diff    | 0.188    |
| loss_diff_q1 | 0.188    |
| loss_q1      | 0.188    |
| param_norm   | 228      |
| samples      | 511      |
| step         | 510      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.29     |
| loss         | 0.116    |
| loss_cal     | 0.0258   |
| loss_cal_q2  | 0.0258   |
| loss_diff    | 0.116    |
| loss_diff_q2 | 0.116    |
| loss_q2      | 0.116    |
| param_norm   | 228      |
| samples      | 512      |
| step         | 511      |
---------------------------
---------------------------
| grad_norm    | 8.48     |
| loss         | 1.1      |
| loss_cal     | 0.0301   |
| loss_cal_q0  | 0.0301   |
| loss_diff    | 1.1      |
| loss_diff_q0 | 1.1      |
| loss_q0      | 1.1      |
| param_norm   | 228      |
| samples      | 513      |
| step         | 512      |
---------------------------
---------------------------
| grad_norm    | 1.48     |
| loss         | 0.119    |
| loss_cal     | 0.0268   |
| loss_cal_q1  | 0.0268   |
| loss_diff    | 0.119    |
| loss_diff_q1 | 0.119    |
| loss_q1      | 0.119    |
| param_norm   | 228      |
| samples      | 514      |
| step         | 513      |
---------------------------
---------------------------
| grad_norm    | 1.21     |
| loss         | 0.0788   |
| loss_cal     | 0.0252   |
| loss_cal_q2  | 0.0252   |
| loss_diff    | 0.0788   |
| loss_diff_q2 | 0.0788   |
| loss_q2      | 0.0788   |
| param_norm   | 228      |
| samples      | 515      |
| step         | 514      |
---------------------------
---------------------------
| grad_norm    | 2.73     |
| loss         | 0.283    |
| loss_cal     | 0.0448   |
| loss_cal_q3  | 0.0448   |
| loss_diff    | 0.283    |
| loss_diff_q3 | 0.283    |
| loss_q3      | 0.283    |
| param_norm   | 228      |
| samples      | 516      |
| step         | 515      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.52     |
| loss         | 0.311    |
| loss_cal     | 0.0268   |
| loss_cal_q2  | 0.0268   |
| loss_diff    | 0.311    |
| loss_diff_q2 | 0.311    |
| loss_q2      | 0.311    |
| param_norm   | 228      |
| samples      | 517      |
| step         | 516      |
---------------------------
---------------------------
| grad_norm    | 2.59     |
| loss         | 0.257    |
| loss_cal     | 0.0394   |
| loss_cal_q1  | 0.0394   |
| loss_diff    | 0.257    |
| loss_diff_q1 | 0.257    |
| loss_q1      | 0.257    |
| param_norm   | 228      |
| samples      | 518      |
| step         | 517      |
---------------------------
---------------------------
| grad_norm    | 1.18     |
| loss         | 0.0694   |
| loss_cal     | 0.0248   |
| loss_cal_q2  | 0.0248   |
| loss_diff    | 0.0694   |
| loss_diff_q2 | 0.0694   |
| loss_q2      | 0.0694   |
| param_norm   | 228      |
| samples      | 519      |
| step         | 518      |
---------------------------
---------------------------
| grad_norm    | 3.49     |
| loss         | 0.339    |
| loss_cal     | 0.0279   |
| loss_cal_q2  | 0.0279   |
| loss_diff    | 0.339    |
| loss_diff_q2 | 0.339    |
| loss_q2      | 0.339    |
| param_norm   | 228      |
| samples      | 520      |
| step         | 519      |
---------------------------
---------------------------
| grad_norm    | 6.38     |
| loss         | 0.738    |
| loss_cal     | 0.0261   |
| loss_cal_q0  | 0.0261   |
| loss_diff    | 0.738    |
| loss_diff_q0 | 0.738    |
| loss_q0      | 0.738    |
| param_norm   | 228      |
| samples      | 521      |
| step         | 520      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.53     |
| loss         | 0.0884   |
| loss_cal     | 0.0246   |
| loss_cal_q2  | 0.0246   |
| loss_diff    | 0.0884   |
| loss_diff_q2 | 0.0884   |
| loss_q2      | 0.0884   |
| param_norm   | 228      |
| samples      | 522      |
| step         | 521      |
---------------------------
---------------------------
| grad_norm    | 3.23     |
| loss         | 0.0399   |
| loss_cal     | 0.0243   |
| loss_cal_q3  | 0.0243   |
| loss_diff    | 0.0399   |
| loss_diff_q3 | 0.0399   |
| loss_q3      | 0.0399   |
| param_norm   | 228      |
| samples      | 523      |
| step         | 522      |
---------------------------
---------------------------
| grad_norm    | 2.26     |
| loss         | 0.246    |
| loss_cal     | 0.0304   |
| loss_cal_q3  | 0.0304   |
| loss_diff    | 0.246    |
| loss_diff_q3 | 0.246    |
| loss_q3      | 0.246    |
| param_norm   | 228      |
| samples      | 524      |
| step         | 523      |
---------------------------
---------------------------
| grad_norm    | 2.84     |
| loss         | 0.223    |
| loss_cal     | 0.0263   |
| loss_cal_q0  | 0.0263   |
| loss_diff    | 0.223    |
| loss_diff_q0 | 0.223    |
| loss_q0      | 0.223    |
| param_norm   | 228      |
| samples      | 525      |
| step         | 524      |
---------------------------
---------------------------
| grad_norm    | 1.98     |
| loss         | 0.258    |
| loss_cal     | 0.0265   |
| loss_cal_q3  | 0.0265   |
| loss_diff    | 0.258    |
| loss_diff_q3 | 0.258    |
| loss_q3      | 0.258    |
| param_norm   | 228      |
| samples      | 526      |
| step         | 525      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.32     |
| loss         | 0.0819   |
| loss_cal     | 0.0248   |
| loss_cal_q3  | 0.0248   |
| loss_diff    | 0.0819   |
| loss_diff_q3 | 0.0819   |
| loss_q3      | 0.0819   |
| param_norm   | 228      |
| samples      | 527      |
| step         | 526      |
---------------------------
---------------------------
| grad_norm    | 1.76     |
| loss         | 0.203    |
| loss_cal     | 0.0411   |
| loss_cal_q1  | 0.0411   |
| loss_diff    | 0.203    |
| loss_diff_q1 | 0.203    |
| loss_q1      | 0.203    |
| param_norm   | 228      |
| samples      | 528      |
| step         | 527      |
---------------------------
---------------------------
| grad_norm    | 1.98     |
| loss         | 0.223    |
| loss_cal     | 0.0264   |
| loss_cal_q3  | 0.0264   |
| loss_diff    | 0.223    |
| loss_diff_q3 | 0.223    |
| loss_q3      | 0.223    |
| param_norm   | 228      |
| samples      | 529      |
| step         | 528      |
---------------------------
---------------------------
| grad_norm    | 7.68     |
| loss         | 0.0441   |
| loss_cal     | 0.024    |
| loss_cal_q1  | 0.024    |
| loss_diff    | 0.0441   |
| loss_diff_q1 | 0.0441   |
| loss_q1      | 0.0441   |
| param_norm   | 228      |
| samples      | 530      |
| step         | 529      |
---------------------------
---------------------------
| grad_norm    | 5.83     |
| loss         | 0.898    |
| loss_cal     | 0.025    |
| loss_cal_q0  | 0.025    |
| loss_diff    | 0.898    |
| loss_diff_q0 | 0.898    |
| loss_q0      | 0.898    |
| param_norm   | 228      |
| samples      | 531      |
| step         | 530      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.78     |
| loss         | 0.249    |
| loss_cal     | 0.0409   |
| loss_cal_q3  | 0.0409   |
| loss_diff    | 0.249    |
| loss_diff_q3 | 0.249    |
| loss_q3      | 0.249    |
| param_norm   | 228      |
| samples      | 532      |
| step         | 531      |
---------------------------
---------------------------
| grad_norm    | 5.92     |
| loss         | 0.386    |
| loss_cal     | 0.042    |
| loss_cal_q0  | 0.042    |
| loss_diff    | 0.386    |
| loss_diff_q0 | 0.386    |
| loss_q0      | 0.386    |
| param_norm   | 228      |
| samples      | 533      |
| step         | 532      |
---------------------------
---------------------------
| grad_norm    | 1.16     |
| loss         | 0.0853   |
| loss_cal     | 0.0247   |
| loss_cal_q3  | 0.0247   |
| loss_diff    | 0.0853   |
| loss_diff_q3 | 0.0853   |
| loss_q3      | 0.0853   |
| param_norm   | 228      |
| samples      | 534      |
| step         | 533      |
---------------------------
---------------------------
| grad_norm    | 2.24     |
| loss         | 0.214    |
| loss_cal     | 0.0248   |
| loss_cal_q0  | 0.0248   |
| loss_diff    | 0.214    |
| loss_diff_q0 | 0.214    |
| loss_q0      | 0.214    |
| param_norm   | 228      |
| samples      | 535      |
| step         | 534      |
---------------------------
---------------------------
| grad_norm    | 4.49     |
| loss         | 0.0442   |
| loss_cal     | 0.0237   |
| loss_cal_q3  | 0.0237   |
| loss_diff    | 0.0442   |
| loss_diff_q3 | 0.0442   |
| loss_q3      | 0.0442   |
| param_norm   | 228      |
| samples      | 536      |
| step         | 535      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 5.38     |
| loss         | 0.0436   |
| loss_cal     | 0.0235   |
| loss_cal_q2  | 0.0235   |
| loss_diff    | 0.0436   |
| loss_diff_q2 | 0.0436   |
| loss_q2      | 0.0436   |
| param_norm   | 228      |
| samples      | 537      |
| step         | 536      |
---------------------------
---------------------------
| grad_norm    | 5.43     |
| loss         | 0.804    |
| loss_cal     | 0.026    |
| loss_cal_q0  | 0.026    |
| loss_diff    | 0.804    |
| loss_diff_q0 | 0.804    |
| loss_q0      | 0.804    |
| param_norm   | 228      |
| samples      | 538      |
| step         | 537      |
---------------------------
---------------------------
| grad_norm    | 1.51     |
| loss         | 0.169    |
| loss_cal     | 0.0248   |
| loss_cal_q3  | 0.0248   |
| loss_diff    | 0.169    |
| loss_diff_q3 | 0.169    |
| loss_q3      | 0.169    |
| param_norm   | 228      |
| samples      | 539      |
| step         | 538      |
---------------------------
---------------------------
| grad_norm    | 1.36     |
| loss         | 0.177    |
| loss_cal     | 0.0248   |
| loss_cal_q2  | 0.0248   |
| loss_diff    | 0.177    |
| loss_diff_q2 | 0.177    |
| loss_q2      | 0.177    |
| param_norm   | 228      |
| samples      | 540      |
| step         | 539      |
---------------------------
---------------------------
| grad_norm    | 1.17     |
| loss         | 0.0673   |
| loss_cal     | 0.0236   |
| loss_cal_q2  | 0.0236   |
| loss_diff    | 0.0673   |
| loss_diff_q2 | 0.0673   |
| loss_q2      | 0.0673   |
| param_norm   | 228      |
| samples      | 541      |
| step         | 540      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.47     |
| loss         | 0.0378   |
| loss_cal     | 0.0234   |
| loss_cal_q1  | 0.0234   |
| loss_diff    | 0.0378   |
| loss_diff_q1 | 0.0378   |
| loss_q1      | 0.0378   |
| param_norm   | 228      |
| samples      | 542      |
| step         | 541      |
---------------------------
---------------------------
| grad_norm    | 2.86     |
| loss         | 0.219    |
| loss_cal     | 0.027    |
| loss_cal_q2  | 0.027    |
| loss_diff    | 0.219    |
| loss_diff_q2 | 0.219    |
| loss_q2      | 0.219    |
| param_norm   | 228      |
| samples      | 543      |
| step         | 542      |
---------------------------
---------------------------
| grad_norm    | 4.63     |
| loss         | 0.52     |
| loss_cal     | 0.0728   |
| loss_cal_q0  | 0.0728   |
| loss_diff    | 0.52     |
| loss_diff_q0 | 0.52     |
| loss_q0      | 0.52     |
| param_norm   | 228      |
| samples      | 544      |
| step         | 543      |
---------------------------
---------------------------
| grad_norm    | 1.31     |
| loss         | 0.122    |
| loss_cal     | 0.0249   |
| loss_cal_q3  | 0.0249   |
| loss_diff    | 0.122    |
| loss_diff_q3 | 0.122    |
| loss_q3      | 0.122    |
| param_norm   | 228      |
| samples      | 545      |
| step         | 544      |
---------------------------
---------------------------
| grad_norm    | 5.69     |
| loss         | 0.0393   |
| loss_cal     | 0.0229   |
| loss_cal_q1  | 0.0229   |
| loss_diff    | 0.0393   |
| loss_diff_q1 | 0.0393   |
| loss_q1      | 0.0393   |
| param_norm   | 228      |
| samples      | 546      |
| step         | 545      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.11     |
| loss         | 0.162    |
| loss_cal     | 0.0607   |
| loss_cal_q2  | 0.0607   |
| loss_diff    | 0.162    |
| loss_diff_q2 | 0.162    |
| loss_q2      | 0.162    |
| param_norm   | 228      |
| samples      | 547      |
| step         | 546      |
---------------------------
---------------------------
| grad_norm    | 2.46     |
| loss         | 0.23     |
| loss_cal     | 0.0666   |
| loss_cal_q3  | 0.0666   |
| loss_diff    | 0.23     |
| loss_diff_q3 | 0.23     |
| loss_q3      | 0.23     |
| param_norm   | 228      |
| samples      | 548      |
| step         | 547      |
---------------------------
---------------------------
| grad_norm    | 2.11     |
| loss         | 0.16     |
| loss_cal     | 0.0335   |
| loss_cal_q3  | 0.0335   |
| loss_diff    | 0.16     |
| loss_diff_q3 | 0.16     |
| loss_q3      | 0.16     |
| param_norm   | 228      |
| samples      | 549      |
| step         | 548      |
---------------------------
---------------------------
| grad_norm    | 2.52     |
| loss         | 0.159    |
| loss_cal     | 0.0608   |
| loss_cal_q2  | 0.0608   |
| loss_diff    | 0.159    |
| loss_diff_q2 | 0.159    |
| loss_q2      | 0.159    |
| param_norm   | 228      |
| samples      | 550      |
| step         | 549      |
---------------------------
---------------------------
| grad_norm    | 1.34     |
| loss         | 0.104    |
| loss_cal     | 0.0237   |
| loss_cal_q3  | 0.0237   |
| loss_diff    | 0.104    |
| loss_diff_q3 | 0.104    |
| loss_q3      | 0.104    |
| param_norm   | 228      |
| samples      | 551      |
| step         | 550      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.37     |
| loss         | 0.114    |
| loss_cal     | 0.0238   |
| loss_cal_q1  | 0.0238   |
| loss_diff    | 0.114    |
| loss_diff_q1 | 0.114    |
| loss_q1      | 0.114    |
| param_norm   | 228      |
| samples      | 552      |
| step         | 551      |
---------------------------
---------------------------
| grad_norm    | 1.22     |
| loss         | 0.0883   |
| loss_cal     | 0.0233   |
| loss_cal_q1  | 0.0233   |
| loss_diff    | 0.0883   |
| loss_diff_q1 | 0.0883   |
| loss_q1      | 0.0883   |
| param_norm   | 228      |
| samples      | 553      |
| step         | 552      |
---------------------------
---------------------------
| grad_norm    | 6.58     |
| loss         | 0.0341   |
| loss_cal     | 0.023    |
| loss_cal_q1  | 0.023    |
| loss_diff    | 0.0341   |
| loss_diff_q1 | 0.0341   |
| loss_q1      | 0.0341   |
| param_norm   | 228      |
| samples      | 554      |
| step         | 553      |
---------------------------
---------------------------
| grad_norm    | 1.39     |
| loss         | 0.094    |
| loss_cal     | 0.0242   |
| loss_cal_q2  | 0.0242   |
| loss_diff    | 0.094    |
| loss_diff_q2 | 0.094    |
| loss_q2      | 0.094    |
| param_norm   | 228      |
| samples      | 555      |
| step         | 554      |
---------------------------
---------------------------
| grad_norm    | 1.63     |
| loss         | 0.124    |
| loss_cal     | 0.0302   |
| loss_cal_q3  | 0.0302   |
| loss_diff    | 0.124    |
| loss_diff_q3 | 0.124    |
| loss_q3      | 0.124    |
| param_norm   | 228      |
| samples      | 556      |
| step         | 555      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 6.53     |
| loss         | 0.297    |
| loss_cal     | 0.0225   |
| loss_cal_q0  | 0.0225   |
| loss_diff    | 0.297    |
| loss_diff_q0 | 0.297    |
| loss_q0      | 0.297    |
| param_norm   | 228      |
| samples      | 557      |
| step         | 556      |
---------------------------
---------------------------
| grad_norm    | 1.27     |
| loss         | 0.0674   |
| loss_cal     | 0.0236   |
| loss_cal_q2  | 0.0236   |
| loss_diff    | 0.0674   |
| loss_diff_q2 | 0.0674   |
| loss_q2      | 0.0674   |
| param_norm   | 228      |
| samples      | 558      |
| step         | 557      |
---------------------------
---------------------------
| grad_norm    | 3.9      |
| loss         | 0.215    |
| loss_cal     | 0.0291   |
| loss_cal_q1  | 0.0291   |
| loss_diff    | 0.215    |
| loss_diff_q1 | 0.215    |
| loss_q1      | 0.215    |
| param_norm   | 228      |
| samples      | 559      |
| step         | 558      |
---------------------------
---------------------------
| grad_norm    | 1.51     |
| loss         | 0.0746   |
| loss_cal     | 0.0232   |
| loss_cal_q2  | 0.0232   |
| loss_diff    | 0.0746   |
| loss_diff_q2 | 0.0746   |
| loss_q2      | 0.0746   |
| param_norm   | 228      |
| samples      | 560      |
| step         | 559      |
---------------------------
---------------------------
| grad_norm    | 1.43     |
| loss         | 0.0692   |
| loss_cal     | 0.0238   |
| loss_cal_q3  | 0.0238   |
| loss_diff    | 0.0692   |
| loss_diff_q3 | 0.0692   |
| loss_q3      | 0.0692   |
| param_norm   | 228      |
| samples      | 561      |
| step         | 560      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.4      |
| loss         | 0.101    |
| loss_cal     | 0.0232   |
| loss_cal_q3  | 0.0232   |
| loss_diff    | 0.101    |
| loss_diff_q3 | 0.101    |
| loss_q3      | 0.101    |
| param_norm   | 228      |
| samples      | 562      |
| step         | 561      |
---------------------------
---------------------------
| grad_norm    | 3.99     |
| loss         | 0.314    |
| loss_cal     | 0.0487   |
| loss_cal_q1  | 0.0487   |
| loss_diff    | 0.314    |
| loss_diff_q1 | 0.314    |
| loss_q1      | 0.314    |
| param_norm   | 228      |
| samples      | 563      |
| step         | 562      |
---------------------------
---------------------------
| grad_norm    | 3.03     |
| loss         | 0.163    |
| loss_cal     | 0.0251   |
| loss_cal_q1  | 0.0251   |
| loss_diff    | 0.163    |
| loss_diff_q1 | 0.163    |
| loss_q1      | 0.163    |
| param_norm   | 228      |
| samples      | 564      |
| step         | 563      |
---------------------------
---------------------------
| grad_norm    | 2.38     |
| loss         | 0.203    |
| loss_cal     | 0.0461   |
| loss_cal_q3  | 0.0461   |
| loss_diff    | 0.203    |
| loss_diff_q3 | 0.203    |
| loss_q3      | 0.203    |
| param_norm   | 228      |
| samples      | 565      |
| step         | 564      |
---------------------------
---------------------------
| grad_norm    | 2.31     |
| loss         | 0.158    |
| loss_cal     | 0.032    |
| loss_cal_q3  | 0.032    |
| loss_diff    | 0.158    |
| loss_diff_q3 | 0.158    |
| loss_q3      | 0.158    |
| param_norm   | 228      |
| samples      | 566      |
| step         | 565      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.05     |
| loss         | 0.19     |
| loss_cal     | 0.0246   |
| loss_cal_q3  | 0.0246   |
| loss_diff    | 0.19     |
| loss_diff_q3 | 0.19     |
| loss_q3      | 0.19     |
| param_norm   | 228      |
| samples      | 567      |
| step         | 566      |
---------------------------
---------------------------
| grad_norm    | 1.61     |
| loss         | 0.0926   |
| loss_cal     | 0.0227   |
| loss_cal_q0  | 0.0227   |
| loss_diff    | 0.0926   |
| loss_diff_q0 | 0.0926   |
| loss_q0      | 0.0926   |
| param_norm   | 228      |
| samples      | 568      |
| step         | 567      |
---------------------------
---------------------------
| grad_norm    | 2.56     |
| loss         | 0.156    |
| loss_cal     | 0.0719   |
| loss_cal_q2  | 0.0719   |
| loss_diff    | 0.156    |
| loss_diff_q2 | 0.156    |
| loss_q2      | 0.156    |
| param_norm   | 228      |
| samples      | 569      |
| step         | 568      |
---------------------------
---------------------------
| grad_norm    | 1.16     |
| loss         | 0.0729   |
| loss_cal     | 0.0226   |
| loss_cal_q1  | 0.0226   |
| loss_diff    | 0.0729   |
| loss_diff_q1 | 0.0729   |
| loss_q1      | 0.0729   |
| param_norm   | 228      |
| samples      | 570      |
| step         | 569      |
---------------------------
---------------------------
| grad_norm    | 1.33     |
| loss         | 0.0784   |
| loss_cal     | 0.024    |
| loss_cal_q2  | 0.024    |
| loss_diff    | 0.0784   |
| loss_diff_q2 | 0.0784   |
| loss_q2      | 0.0784   |
| param_norm   | 228      |
| samples      | 571      |
| step         | 570      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.56     |
| loss         | 0.089    |
| loss_cal     | 0.0317   |
| loss_cal_q2  | 0.0317   |
| loss_diff    | 0.089    |
| loss_diff_q2 | 0.089    |
| loss_q2      | 0.089    |
| param_norm   | 228      |
| samples      | 572      |
| step         | 571      |
---------------------------
---------------------------
| grad_norm    | 6.24     |
| loss         | 0.292    |
| loss_cal     | 0.0343   |
| loss_cal_q0  | 0.0343   |
| loss_diff    | 0.292    |
| loss_diff_q0 | 0.292    |
| loss_q0      | 0.292    |
| param_norm   | 228      |
| samples      | 573      |
| step         | 572      |
---------------------------
---------------------------
| grad_norm    | 3.51     |
| loss         | 0.202    |
| loss_cal     | 0.0422   |
| loss_cal_q1  | 0.0422   |
| loss_diff    | 0.202    |
| loss_diff_q1 | 0.202    |
| loss_q1      | 0.202    |
| param_norm   | 228      |
| samples      | 574      |
| step         | 573      |
---------------------------
---------------------------
| grad_norm    | 2.6      |
| loss         | 0.147    |
| loss_cal     | 0.0474   |
| loss_cal_q1  | 0.0474   |
| loss_diff    | 0.147    |
| loss_diff_q1 | 0.147    |
| loss_q1      | 0.147    |
| param_norm   | 228      |
| samples      | 575      |
| step         | 574      |
---------------------------
---------------------------
| grad_norm    | 1.3      |
| loss         | 0.0678   |
| loss_cal     | 0.0228   |
| loss_cal_q2  | 0.0228   |
| loss_diff    | 0.0678   |
| loss_diff_q2 | 0.0678   |
| loss_q2      | 0.0678   |
| param_norm   | 228      |
| samples      | 576      |
| step         | 575      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 6.7      |
| loss         | 0.647    |
| loss_cal     | 0.0237   |
| loss_cal_q0  | 0.0237   |
| loss_diff    | 0.647    |
| loss_diff_q0 | 0.647    |
| loss_q0      | 0.647    |
| param_norm   | 228      |
| samples      | 577      |
| step         | 576      |
---------------------------
---------------------------
| grad_norm    | 8.76     |
| loss         | 0.834    |
| loss_cal     | 0.0249   |
| loss_cal_q0  | 0.0249   |
| loss_diff    | 0.834    |
| loss_diff_q0 | 0.834    |
| loss_q0      | 0.834    |
| param_norm   | 228      |
| samples      | 578      |
| step         | 577      |
---------------------------
---------------------------
| grad_norm    | 1.24     |
| loss         | 0.0908   |
| loss_cal     | 0.0229   |
| loss_cal_q0  | 0.0229   |
| loss_diff    | 0.0908   |
| loss_diff_q0 | 0.0908   |
| loss_q0      | 0.0908   |
| param_norm   | 228      |
| samples      | 579      |
| step         | 578      |
---------------------------
---------------------------
| grad_norm    | 3.05     |
| loss         | 0.218    |
| loss_cal     | 0.0233   |
| loss_cal_q0  | 0.0233   |
| loss_diff    | 0.218    |
| loss_diff_q0 | 0.218    |
| loss_q0      | 0.218    |
| param_norm   | 228      |
| samples      | 580      |
| step         | 579      |
---------------------------
---------------------------
| grad_norm    | 1.14     |
| loss         | 0.0524   |
| loss_cal     | 0.0218   |
| loss_cal_q1  | 0.0218   |
| loss_diff    | 0.0524   |
| loss_diff_q1 | 0.0524   |
| loss_q1      | 0.0524   |
| param_norm   | 228      |
| samples      | 581      |
| step         | 580      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.49     |
| loss         | 0.238    |
| loss_cal     | 0.0293   |
| loss_cal_q2  | 0.0293   |
| loss_diff    | 0.238    |
| loss_diff_q2 | 0.238    |
| loss_q2      | 0.238    |
| param_norm   | 228      |
| samples      | 582      |
| step         | 581      |
---------------------------
---------------------------
| grad_norm    | 1.96     |
| loss         | 0.223    |
| loss_cal     | 0.0356   |
| loss_cal_q2  | 0.0356   |
| loss_diff    | 0.223    |
| loss_diff_q2 | 0.223    |
| loss_q2      | 0.223    |
| param_norm   | 228      |
| samples      | 583      |
| step         | 582      |
---------------------------
---------------------------
| grad_norm    | 1.58     |
| loss         | 0.212    |
| loss_cal     | 0.0337   |
| loss_cal_q2  | 0.0337   |
| loss_diff    | 0.212    |
| loss_diff_q2 | 0.212    |
| loss_q2      | 0.212    |
| param_norm   | 228      |
| samples      | 584      |
| step         | 583      |
---------------------------
---------------------------
| grad_norm    | 1.42     |
| loss         | 0.147    |
| loss_cal     | 0.0231   |
| loss_cal_q2  | 0.0231   |
| loss_diff    | 0.147    |
| loss_diff_q2 | 0.147    |
| loss_q2      | 0.147    |
| param_norm   | 228      |
| samples      | 585      |
| step         | 584      |
---------------------------
---------------------------
| grad_norm    | 3.35     |
| loss         | 0.272    |
| loss_cal     | 0.0594   |
| loss_cal_q1  | 0.0594   |
| loss_diff    | 0.272    |
| loss_diff_q1 | 0.272    |
| loss_q1      | 0.272    |
| param_norm   | 228      |
| samples      | 586      |
| step         | 585      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.12     |
| loss         | 0.187    |
| loss_cal     | 0.0231   |
| loss_cal_q3  | 0.0231   |
| loss_diff    | 0.187    |
| loss_diff_q3 | 0.187    |
| loss_q3      | 0.187    |
| param_norm   | 228      |
| samples      | 587      |
| step         | 586      |
---------------------------
---------------------------
| grad_norm    | 4.83     |
| loss         | 0.0458   |
| loss_cal     | 0.0214   |
| loss_cal_q3  | 0.0214   |
| loss_diff    | 0.0458   |
| loss_diff_q3 | 0.0458   |
| loss_q3      | 0.0458   |
| param_norm   | 228      |
| samples      | 588      |
| step         | 587      |
---------------------------
---------------------------
| grad_norm    | 1.7      |
| loss         | 0.138    |
| loss_cal     | 0.0213   |
| loss_cal_q0  | 0.0213   |
| loss_diff    | 0.138    |
| loss_diff_q0 | 0.138    |
| loss_q0      | 0.138    |
| param_norm   | 228      |
| samples      | 589      |
| step         | 588      |
---------------------------
---------------------------
| grad_norm    | 1.81     |
| loss         | 0.157    |
| loss_cal     | 0.0241   |
| loss_cal_q3  | 0.0241   |
| loss_diff    | 0.157    |
| loss_diff_q3 | 0.157    |
| loss_q3      | 0.157    |
| param_norm   | 228      |
| samples      | 590      |
| step         | 589      |
---------------------------
---------------------------
| grad_norm    | 3.26     |
| loss         | 0.208    |
| loss_cal     | 0.0233   |
| loss_cal_q0  | 0.0233   |
| loss_diff    | 0.208    |
| loss_diff_q0 | 0.208    |
| loss_q0      | 0.208    |
| param_norm   | 228      |
| samples      | 591      |
| step         | 590      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.06     |
| loss         | 0.31     |
| loss_cal     | 0.0284   |
| loss_cal_q0  | 0.0284   |
| loss_diff    | 0.31     |
| loss_diff_q0 | 0.31     |
| loss_q0      | 0.31     |
| param_norm   | 228      |
| samples      | 592      |
| step         | 591      |
---------------------------
---------------------------
| grad_norm    | 1.61     |
| loss         | 0.111    |
| loss_cal     | 0.0238   |
| loss_cal_q0  | 0.0238   |
| loss_diff    | 0.111    |
| loss_diff_q0 | 0.111    |
| loss_q0      | 0.111    |
| param_norm   | 228      |
| samples      | 593      |
| step         | 592      |
---------------------------
---------------------------
| grad_norm    | 1.43     |
| loss         | 0.112    |
| loss_cal     | 0.0228   |
| loss_cal_q3  | 0.0228   |
| loss_diff    | 0.112    |
| loss_diff_q3 | 0.112    |
| loss_q3      | 0.112    |
| param_norm   | 228      |
| samples      | 594      |
| step         | 593      |
---------------------------
---------------------------
| grad_norm    | 2.48     |
| loss         | 0.184    |
| loss_cal     | 0.0505   |
| loss_cal_q1  | 0.0505   |
| loss_diff    | 0.184    |
| loss_diff_q1 | 0.184    |
| loss_q1      | 0.184    |
| param_norm   | 228      |
| samples      | 595      |
| step         | 594      |
---------------------------
---------------------------
| grad_norm    | 1.97     |
| loss         | 0.248    |
| loss_cal     | 0.0232   |
| loss_cal_q2  | 0.0232   |
| loss_diff    | 0.248    |
| loss_diff_q2 | 0.248    |
| loss_q2      | 0.248    |
| param_norm   | 228      |
| samples      | 596      |
| step         | 595      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.81     |
| loss         | 0.235    |
| loss_cal     | 0.0247   |
| loss_cal_q0  | 0.0247   |
| loss_diff    | 0.235    |
| loss_diff_q0 | 0.235    |
| loss_q0      | 0.235    |
| param_norm   | 228      |
| samples      | 597      |
| step         | 596      |
---------------------------
---------------------------
| grad_norm    | 3.25     |
| loss         | 0.858    |
| loss_cal     | 0.0661   |
| loss_cal_q0  | 0.0661   |
| loss_diff    | 0.858    |
| loss_diff_q0 | 0.858    |
| loss_q0      | 0.858    |
| param_norm   | 228      |
| samples      | 598      |
| step         | 597      |
---------------------------
---------------------------
| grad_norm    | 1.34     |
| loss         | 0.134    |
| loss_cal     | 0.0217   |
| loss_cal_q1  | 0.0217   |
| loss_diff    | 0.134    |
| loss_diff_q1 | 0.134    |
| loss_q1      | 0.134    |
| param_norm   | 228      |
| samples      | 599      |
| step         | 598      |
---------------------------
---------------------------
| grad_norm    | 1.19     |
| loss         | 0.0893   |
| loss_cal     | 0.0215   |
| loss_cal_q1  | 0.0215   |
| loss_diff    | 0.0893   |
| loss_diff_q1 | 0.0893   |
| loss_q1      | 0.0893   |
| param_norm   | 228      |
| samples      | 600      |
| step         | 599      |
---------------------------
---------------------------
| grad_norm    | 2.52     |
| loss         | 0.312    |
| loss_cal     | 0.0593   |
| loss_cal_q3  | 0.0593   |
| loss_diff    | 0.312    |
| loss_diff_q3 | 0.312    |
| loss_q3      | 0.312    |
| param_norm   | 228      |
| samples      | 601      |
| step         | 600      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.32     |
| loss         | 0.144    |
| loss_cal     | 0.0215   |
| loss_cal_q2  | 0.0215   |
| loss_diff    | 0.144    |
| loss_diff_q2 | 0.144    |
| loss_q2      | 0.144    |
| param_norm   | 228      |
| samples      | 602      |
| step         | 601      |
---------------------------
---------------------------
| grad_norm    | 1.14     |
| loss         | 0.0767   |
| loss_cal     | 0.0216   |
| loss_cal_q2  | 0.0216   |
| loss_diff    | 0.0767   |
| loss_diff_q2 | 0.0767   |
| loss_q2      | 0.0767   |
| param_norm   | 228      |
| samples      | 603      |
| step         | 602      |
---------------------------
---------------------------
| grad_norm    | 1.04     |
| loss         | 0.0406   |
| loss_cal     | 0.0207   |
| loss_cal_q2  | 0.0207   |
| loss_diff    | 0.0406   |
| loss_diff_q2 | 0.0406   |
| loss_q2      | 0.0406   |
| param_norm   | 228      |
| samples      | 604      |
| step         | 603      |
---------------------------
---------------------------
| grad_norm    | 1.47     |
| loss         | 0.0958   |
| loss_cal     | 0.0223   |
| loss_cal_q1  | 0.0223   |
| loss_diff    | 0.0958   |
| loss_diff_q1 | 0.0958   |
| loss_q1      | 0.0958   |
| param_norm   | 228      |
| samples      | 605      |
| step         | 604      |
---------------------------
---------------------------
| grad_norm    | 3.28     |
| loss         | 0.167    |
| loss_cal     | 0.0391   |
| loss_cal_q1  | 0.0391   |
| loss_diff    | 0.167    |
| loss_diff_q1 | 0.167    |
| loss_q1      | 0.167    |
| param_norm   | 228      |
| samples      | 606      |
| step         | 605      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.2      |
| loss         | 0.0889   |
| loss_cal     | 0.0213   |
| loss_cal_q1  | 0.0213   |
| loss_diff    | 0.0889   |
| loss_diff_q1 | 0.0889   |
| loss_q1      | 0.0889   |
| param_norm   | 228      |
| samples      | 607      |
| step         | 606      |
---------------------------
---------------------------
| grad_norm    | 1.85     |
| loss         | 0.12     |
| loss_cal     | 0.0293   |
| loss_cal_q0  | 0.0293   |
| loss_diff    | 0.12     |
| loss_diff_q0 | 0.12     |
| loss_q0      | 0.12     |
| param_norm   | 228      |
| samples      | 608      |
| step         | 607      |
---------------------------
---------------------------
| grad_norm    | 2.86     |
| loss         | 0.226    |
| loss_cal     | 0.0517   |
| loss_cal_q2  | 0.0517   |
| loss_diff    | 0.226    |
| loss_diff_q2 | 0.226    |
| loss_q2      | 0.226    |
| param_norm   | 228      |
| samples      | 609      |
| step         | 608      |
---------------------------
---------------------------
| grad_norm    | 3.51     |
| loss         | 0.218    |
| loss_cal     | 0.0278   |
| loss_cal_q1  | 0.0278   |
| loss_diff    | 0.218    |
| loss_diff_q1 | 0.218    |
| loss_q1      | 0.218    |
| param_norm   | 228      |
| samples      | 610      |
| step         | 609      |
---------------------------
---------------------------
| grad_norm    | 1.53     |
| loss         | 0.113    |
| loss_cal     | 0.0214   |
| loss_cal_q0  | 0.0214   |
| loss_diff    | 0.113    |
| loss_diff_q0 | 0.113    |
| loss_q0      | 0.113    |
| param_norm   | 228      |
| samples      | 611      |
| step         | 610      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.2      |
| loss         | 0.0823   |
| loss_cal     | 0.022    |
| loss_cal_q2  | 0.022    |
| loss_diff    | 0.0823   |
| loss_diff_q2 | 0.0823   |
| loss_q2      | 0.0823   |
| param_norm   | 228      |
| samples      | 612      |
| step         | 611      |
---------------------------
---------------------------
| grad_norm    | 3.72     |
| loss         | 0.149    |
| loss_cal     | 0.0227   |
| loss_cal_q1  | 0.0227   |
| loss_diff    | 0.149    |
| loss_diff_q1 | 0.149    |
| loss_q1      | 0.149    |
| param_norm   | 228      |
| samples      | 613      |
| step         | 612      |
---------------------------
---------------------------
| grad_norm    | 1.21     |
| loss         | 0.0741   |
| loss_cal     | 0.0206   |
| loss_cal_q3  | 0.0206   |
| loss_diff    | 0.0741   |
| loss_diff_q3 | 0.0741   |
| loss_q3      | 0.0741   |
| param_norm   | 228      |
| samples      | 614      |
| step         | 613      |
---------------------------
---------------------------
| grad_norm    | 3.69     |
| loss         | 0.238    |
| loss_cal     | 0.021    |
| loss_cal_q0  | 0.021    |
| loss_diff    | 0.238    |
| loss_diff_q0 | 0.238    |
| loss_q0      | 0.238    |
| param_norm   | 228      |
| samples      | 615      |
| step         | 614      |
---------------------------
---------------------------
| grad_norm    | 10.4     |
| loss         | 0.535    |
| loss_cal     | 0.0215   |
| loss_cal_q0  | 0.0215   |
| loss_diff    | 0.535    |
| loss_diff_q0 | 0.535    |
| loss_q0      | 0.535    |
| param_norm   | 228      |
| samples      | 616      |
| step         | 615      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.6      |
| loss         | 0.133    |
| loss_cal     | 0.0371   |
| loss_cal_q0  | 0.0371   |
| loss_diff    | 0.133    |
| loss_diff_q0 | 0.133    |
| loss_q0      | 0.133    |
| param_norm   | 228      |
| samples      | 617      |
| step         | 616      |
---------------------------
---------------------------
| grad_norm    | 1.98     |
| loss         | 0.126    |
| loss_cal     | 0.023    |
| loss_cal_q0  | 0.023    |
| loss_diff    | 0.126    |
| loss_diff_q0 | 0.126    |
| loss_q0      | 0.126    |
| param_norm   | 228      |
| samples      | 618      |
| step         | 617      |
---------------------------
---------------------------
| grad_norm    | 2.96     |
| loss         | 0.913    |
| loss_cal     | 0.023    |
| loss_cal_q0  | 0.023    |
| loss_diff    | 0.913    |
| loss_diff_q0 | 0.913    |
| loss_q0      | 0.913    |
| param_norm   | 228      |
| samples      | 619      |
| step         | 618      |
---------------------------
---------------------------
| grad_norm    | 2.36     |
| loss         | 0.254    |
| loss_cal     | 0.0343   |
| loss_cal_q3  | 0.0343   |
| loss_diff    | 0.254    |
| loss_diff_q3 | 0.254    |
| loss_q3      | 0.254    |
| param_norm   | 228      |
| samples      | 620      |
| step         | 619      |
---------------------------
---------------------------
| grad_norm    | 2.26     |
| loss         | 0.304    |
| loss_cal     | 0.0238   |
| loss_cal_q3  | 0.0238   |
| loss_diff    | 0.304    |
| loss_diff_q3 | 0.304    |
| loss_q3      | 0.304    |
| param_norm   | 228      |
| samples      | 621      |
| step         | 620      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.71     |
| loss         | 0.171    |
| loss_cal     | 0.024    |
| loss_cal_q3  | 0.024    |
| loss_diff    | 0.171    |
| loss_diff_q3 | 0.171    |
| loss_q3      | 0.171    |
| param_norm   | 228      |
| samples      | 622      |
| step         | 621      |
---------------------------
---------------------------
| grad_norm    | 1.92     |
| loss         | 0.16     |
| loss_cal     | 0.0385   |
| loss_cal_q3  | 0.0385   |
| loss_diff    | 0.16     |
| loss_diff_q3 | 0.16     |
| loss_q3      | 0.16     |
| param_norm   | 228      |
| samples      | 623      |
| step         | 622      |
---------------------------
---------------------------
| grad_norm    | 2.21     |
| loss         | 0.271    |
| loss_cal     | 0.0427   |
| loss_cal_q2  | 0.0427   |
| loss_diff    | 0.271    |
| loss_diff_q2 | 0.271    |
| loss_q2      | 0.271    |
| param_norm   | 228      |
| samples      | 624      |
| step         | 623      |
---------------------------
---------------------------
| grad_norm    | 2.06     |
| loss         | 0.29     |
| loss_cal     | 0.0421   |
| loss_cal_q3  | 0.0421   |
| loss_diff    | 0.29     |
| loss_diff_q3 | 0.29     |
| loss_q3      | 0.29     |
| param_norm   | 228      |
| samples      | 625      |
| step         | 624      |
---------------------------
---------------------------
| grad_norm    | 4.91     |
| loss         | 0.427    |
| loss_cal     | 0.0415   |
| loss_cal_q0  | 0.0415   |
| loss_diff    | 0.427    |
| loss_diff_q0 | 0.427    |
| loss_q0      | 0.427    |
| param_norm   | 228      |
| samples      | 626      |
| step         | 625      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.15     |
| loss         | 0.127    |
| loss_cal     | 0.0212   |
| loss_cal_q3  | 0.0212   |
| loss_diff    | 0.127    |
| loss_diff_q3 | 0.127    |
| loss_q3      | 0.127    |
| param_norm   | 228      |
| samples      | 627      |
| step         | 626      |
---------------------------
---------------------------
| grad_norm    | 2.58     |
| loss         | 0.195    |
| loss_cal     | 0.0666   |
| loss_cal_q1  | 0.0666   |
| loss_diff    | 0.195    |
| loss_diff_q1 | 0.195    |
| loss_q1      | 0.195    |
| param_norm   | 228      |
| samples      | 628      |
| step         | 627      |
---------------------------
---------------------------
| grad_norm    | 5.02     |
| loss         | 0.346    |
| loss_cal     | 0.0232   |
| loss_cal_q0  | 0.0232   |
| loss_diff    | 0.346    |
| loss_diff_q0 | 0.346    |
| loss_q0      | 0.346    |
| param_norm   | 228      |
| samples      | 629      |
| step         | 628      |
---------------------------
---------------------------
| grad_norm    | 3.04     |
| loss         | 0.333    |
| loss_cal     | 0.0634   |
| loss_cal_q2  | 0.0634   |
| loss_diff    | 0.333    |
| loss_diff_q2 | 0.333    |
| loss_q2      | 0.333    |
| param_norm   | 228      |
| samples      | 630      |
| step         | 629      |
---------------------------
---------------------------
| grad_norm    | 6.27     |
| loss         | 0.575    |
| loss_cal     | 0.0215   |
| loss_cal_q0  | 0.0215   |
| loss_diff    | 0.575    |
| loss_diff_q0 | 0.575    |
| loss_q0      | 0.575    |
| param_norm   | 228      |
| samples      | 631      |
| step         | 630      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 5.82     |
| loss         | 0.54     |
| loss_cal     | 0.0394   |
| loss_cal_q0  | 0.0394   |
| loss_diff    | 0.54     |
| loss_diff_q0 | 0.54     |
| loss_q0      | 0.54     |
| param_norm   | 228      |
| samples      | 632      |
| step         | 631      |
---------------------------
---------------------------
| grad_norm    | 2.82     |
| loss         | 0.281    |
| loss_cal     | 0.0765   |
| loss_cal_q3  | 0.0765   |
| loss_diff    | 0.281    |
| loss_diff_q3 | 0.281    |
| loss_q3      | 0.281    |
| param_norm   | 228      |
| samples      | 633      |
| step         | 632      |
---------------------------
---------------------------
| grad_norm    | 7.24     |
| loss         | 1.1      |
| loss_cal     | 0.0586   |
| loss_cal_q0  | 0.0586   |
| loss_diff    | 1.1      |
| loss_diff_q0 | 1.1      |
| loss_q0      | 1.1      |
| param_norm   | 228      |
| samples      | 634      |
| step         | 633      |
---------------------------
---------------------------
| grad_norm    | 1.3      |
| loss         | 0.102    |
| loss_cal     | 0.0274   |
| loss_cal_q2  | 0.0274   |
| loss_diff    | 0.102    |
| loss_diff_q2 | 0.102    |
| loss_q2      | 0.102    |
| param_norm   | 228      |
| samples      | 635      |
| step         | 634      |
---------------------------
---------------------------
| grad_norm    | 1.3      |
| loss         | 0.139    |
| loss_cal     | 0.0206   |
| loss_cal_q2  | 0.0206   |
| loss_diff    | 0.139    |
| loss_diff_q2 | 0.139    |
| loss_q2      | 0.139    |
| param_norm   | 228      |
| samples      | 636      |
| step         | 635      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.21     |
| loss         | 0.0438   |
| loss_cal     | 0.0196   |
| loss_cal_q3  | 0.0196   |
| loss_diff    | 0.0438   |
| loss_diff_q3 | 0.0438   |
| loss_q3      | 0.0438   |
| param_norm   | 228      |
| samples      | 637      |
| step         | 636      |
---------------------------
---------------------------
| grad_norm    | 3.52     |
| loss         | 0.0451   |
| loss_cal     | 0.0195   |
| loss_cal_q1  | 0.0195   |
| loss_diff    | 0.0451   |
| loss_diff_q1 | 0.0451   |
| loss_q1      | 0.0451   |
| param_norm   | 228      |
| samples      | 638      |
| step         | 637      |
---------------------------
---------------------------
| grad_norm    | 1.31     |
| loss         | 0.14     |
| loss_cal     | 0.0207   |
| loss_cal_q1  | 0.0207   |
| loss_diff    | 0.14     |
| loss_diff_q1 | 0.14     |
| loss_q1      | 0.14     |
| param_norm   | 228      |
| samples      | 639      |
| step         | 638      |
---------------------------
---------------------------
| grad_norm    | 2.23     |
| loss         | 0.232    |
| loss_cal     | 0.0214   |
| loss_cal_q0  | 0.0214   |
| loss_diff    | 0.232    |
| loss_diff_q0 | 0.232    |
| loss_q0      | 0.232    |
| param_norm   | 228      |
| samples      | 640      |
| step         | 639      |
---------------------------
---------------------------
| grad_norm    | 4.22     |
| loss         | 0.486    |
| loss_cal     | 0.0544   |
| loss_cal_q0  | 0.0544   |
| loss_diff    | 0.486    |
| loss_diff_q0 | 0.486    |
| loss_q0      | 0.486    |
| param_norm   | 228      |
| samples      | 641      |
| step         | 640      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.02     |
| loss         | 0.346    |
| loss_cal     | 0.0639   |
| loss_cal_q0  | 0.0639   |
| loss_diff    | 0.346    |
| loss_diff_q0 | 0.346    |
| loss_q0      | 0.346    |
| param_norm   | 228      |
| samples      | 642      |
| step         | 641      |
---------------------------
---------------------------
| grad_norm    | 2.37     |
| loss         | 0.283    |
| loss_cal     | 0.0467   |
| loss_cal_q3  | 0.0467   |
| loss_diff    | 0.283    |
| loss_diff_q3 | 0.283    |
| loss_q3      | 0.283    |
| param_norm   | 228      |
| samples      | 643      |
| step         | 642      |
---------------------------
---------------------------
| grad_norm    | 1.53     |
| loss         | 0.257    |
| loss_cal     | 0.0259   |
| loss_cal_q3  | 0.0259   |
| loss_diff    | 0.257    |
| loss_diff_q3 | 0.257    |
| loss_q3      | 0.257    |
| param_norm   | 228      |
| samples      | 644      |
| step         | 643      |
---------------------------
---------------------------
| grad_norm    | 2.27     |
| loss         | 0.263    |
| loss_cal     | 0.0554   |
| loss_cal_q1  | 0.0554   |
| loss_diff    | 0.263    |
| loss_diff_q1 | 0.263    |
| loss_q1      | 0.263    |
| param_norm   | 228      |
| samples      | 645      |
| step         | 644      |
---------------------------
---------------------------
| grad_norm    | 2.97     |
| loss         | 0.308    |
| loss_cal     | 0.0221   |
| loss_cal_q0  | 0.0221   |
| loss_diff    | 0.308    |
| loss_diff_q0 | 0.308    |
| loss_q0      | 0.308    |
| param_norm   | 228      |
| samples      | 646      |
| step         | 645      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.64     |
| loss         | 0.15     |
| loss_cal     | 0.0207   |
| loss_cal_q0  | 0.0207   |
| loss_diff    | 0.15     |
| loss_diff_q0 | 0.15     |
| loss_q0      | 0.15     |
| param_norm   | 228      |
| samples      | 647      |
| step         | 646      |
---------------------------
---------------------------
| grad_norm    | 5.43     |
| loss         | 0.515    |
| loss_cal     | 0.0513   |
| loss_cal_q0  | 0.0513   |
| loss_diff    | 0.515    |
| loss_diff_q0 | 0.515    |
| loss_q0      | 0.515    |
| param_norm   | 228      |
| samples      | 648      |
| step         | 647      |
---------------------------
---------------------------
| grad_norm    | 1.86     |
| loss         | 0.191    |
| loss_cal     | 0.0222   |
| loss_cal_q3  | 0.0222   |
| loss_diff    | 0.191    |
| loss_diff_q3 | 0.191    |
| loss_q3      | 0.191    |
| param_norm   | 228      |
| samples      | 649      |
| step         | 648      |
---------------------------
---------------------------
| grad_norm    | 2.5      |
| loss         | 0.244    |
| loss_cal     | 0.0215   |
| loss_cal_q0  | 0.0215   |
| loss_diff    | 0.244    |
| loss_diff_q0 | 0.244    |
| loss_q0      | 0.244    |
| param_norm   | 228      |
| samples      | 650      |
| step         | 649      |
---------------------------
---------------------------
| grad_norm    | 2.76     |
| loss         | 0.0431   |
| loss_cal     | 0.0193   |
| loss_cal_q1  | 0.0193   |
| loss_diff    | 0.0431   |
| loss_diff_q1 | 0.0431   |
| loss_q1      | 0.0431   |
| param_norm   | 228      |
| samples      | 651      |
| step         | 650      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.84     |
| loss         | 0.179    |
| loss_cal     | 0.038    |
| loss_cal_q1  | 0.038    |
| loss_diff    | 0.179    |
| loss_diff_q1 | 0.179    |
| loss_q1      | 0.179    |
| param_norm   | 228      |
| samples      | 652      |
| step         | 651      |
---------------------------
---------------------------
| grad_norm    | 1.05     |
| loss         | 0.052    |
| loss_cal     | 0.0196   |
| loss_cal_q3  | 0.0196   |
| loss_diff    | 0.052    |
| loss_diff_q3 | 0.052    |
| loss_q3      | 0.052    |
| param_norm   | 228      |
| samples      | 653      |
| step         | 652      |
---------------------------
---------------------------
| grad_norm    | 2.58     |
| loss         | 0.213    |
| loss_cal     | 0.074    |
| loss_cal_q1  | 0.074    |
| loss_diff    | 0.213    |
| loss_diff_q1 | 0.213    |
| loss_q1      | 0.213    |
| param_norm   | 228      |
| samples      | 654      |
| step         | 653      |
---------------------------
---------------------------
| grad_norm    | 1.12     |
| loss         | 0.083    |
| loss_cal     | 0.0197   |
| loss_cal_q0  | 0.0197   |
| loss_diff    | 0.083    |
| loss_diff_q0 | 0.083    |
| loss_q0      | 0.083    |
| param_norm   | 228      |
| samples      | 655      |
| step         | 654      |
---------------------------
---------------------------
| grad_norm    | 1.94     |
| loss         | 0.181    |
| loss_cal     | 0.0324   |
| loss_cal_q2  | 0.0324   |
| loss_diff    | 0.181    |
| loss_diff_q2 | 0.181    |
| loss_q2      | 0.181    |
| param_norm   | 228      |
| samples      | 656      |
| step         | 655      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.09     |
| loss         | 0.074    |
| loss_cal     | 0.0201   |
| loss_cal_q2  | 0.0201   |
| loss_diff    | 0.074    |
| loss_diff_q2 | 0.074    |
| loss_q2      | 0.074    |
| param_norm   | 228      |
| samples      | 657      |
| step         | 656      |
---------------------------
---------------------------
| grad_norm    | 1.98     |
| loss         | 0.163    |
| loss_cal     | 0.0348   |
| loss_cal_q2  | 0.0348   |
| loss_diff    | 0.163    |
| loss_diff_q2 | 0.163    |
| loss_q2      | 0.163    |
| param_norm   | 228      |
| samples      | 658      |
| step         | 657      |
---------------------------
---------------------------
| grad_norm    | 1.19     |
| loss         | 0.0662   |
| loss_cal     | 0.021    |
| loss_cal_q1  | 0.021    |
| loss_diff    | 0.0662   |
| loss_diff_q1 | 0.0662   |
| loss_q1      | 0.0662   |
| param_norm   | 228      |
| samples      | 659      |
| step         | 658      |
---------------------------
---------------------------
| grad_norm    | 1.72     |
| loss         | 0.11     |
| loss_cal     | 0.024    |
| loss_cal_q3  | 0.024    |
| loss_diff    | 0.11     |
| loss_diff_q3 | 0.11     |
| loss_q3      | 0.11     |
| param_norm   | 228      |
| samples      | 660      |
| step         | 659      |
---------------------------
---------------------------
| grad_norm    | 0.977    |
| loss         | 0.041    |
| loss_cal     | 0.02     |
| loss_cal_q0  | 0.02     |
| loss_diff    | 0.041    |
| loss_diff_q0 | 0.041    |
| loss_q0      | 0.041    |
| param_norm   | 228      |
| samples      | 661      |
| step         | 660      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.16     |
| loss         | 0.197    |
| loss_cal     | 0.0236   |
| loss_cal_q1  | 0.0236   |
| loss_diff    | 0.197    |
| loss_diff_q1 | 0.197    |
| loss_q1      | 0.197    |
| param_norm   | 228      |
| samples      | 662      |
| step         | 661      |
---------------------------
---------------------------
| grad_norm    | 1.02     |
| loss         | 0.0515   |
| loss_cal     | 0.0191   |
| loss_cal_q2  | 0.0191   |
| loss_diff    | 0.0515   |
| loss_diff_q2 | 0.0515   |
| loss_q2      | 0.0515   |
| param_norm   | 228      |
| samples      | 663      |
| step         | 662      |
---------------------------
---------------------------
| grad_norm    | 2.02     |
| loss         | 0.154    |
| loss_cal     | 0.0224   |
| loss_cal_q1  | 0.0224   |
| loss_diff    | 0.154    |
| loss_diff_q1 | 0.154    |
| loss_q1      | 0.154    |
| param_norm   | 228      |
| samples      | 664      |
| step         | 663      |
---------------------------
---------------------------
| grad_norm    | 2.68     |
| loss         | 0.199    |
| loss_cal     | 0.0434   |
| loss_cal_q2  | 0.0434   |
| loss_diff    | 0.199    |
| loss_diff_q2 | 0.199    |
| loss_q2      | 0.199    |
| param_norm   | 228      |
| samples      | 665      |
| step         | 664      |
---------------------------
---------------------------
| grad_norm    | 4.21     |
| loss         | 0.199    |
| loss_cal     | 0.0414   |
| loss_cal_q1  | 0.0414   |
| loss_diff    | 0.199    |
| loss_diff_q1 | 0.199    |
| loss_q1      | 0.199    |
| param_norm   | 228      |
| samples      | 666      |
| step         | 665      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 10.4     |
| loss         | 1.12     |
| loss_cal     | 0.0203   |
| loss_cal_q0  | 0.0203   |
| loss_diff    | 1.12     |
| loss_diff_q0 | 1.12     |
| loss_q0      | 1.12     |
| param_norm   | 228      |
| samples      | 667      |
| step         | 666      |
---------------------------
---------------------------
| grad_norm    | 2.34     |
| loss         | 0.0645   |
| loss_cal     | 0.0186   |
| loss_cal_q0  | 0.0186   |
| loss_diff    | 0.0645   |
| loss_diff_q0 | 0.0645   |
| loss_q0      | 0.0645   |
| param_norm   | 228      |
| samples      | 668      |
| step         | 667      |
---------------------------
---------------------------
| grad_norm    | 0.983    |
| loss         | 0.0474   |
| loss_cal     | 0.0192   |
| loss_cal_q0  | 0.0192   |
| loss_diff    | 0.0474   |
| loss_diff_q0 | 0.0474   |
| loss_q0      | 0.0474   |
| param_norm   | 228      |
| samples      | 669      |
| step         | 668      |
---------------------------
---------------------------
| grad_norm    | 4.17     |
| loss         | 0.218    |
| loss_cal     | 0.0476   |
| loss_cal_q1  | 0.0476   |
| loss_diff    | 0.218    |
| loss_diff_q1 | 0.218    |
| loss_q1      | 0.218    |
| param_norm   | 228      |
| samples      | 670      |
| step         | 669      |
---------------------------
---------------------------
| grad_norm    | 2.31     |
| loss         | 0.214    |
| loss_cal     | 0.0211   |
| loss_cal_q2  | 0.0211   |
| loss_diff    | 0.214    |
| loss_diff_q2 | 0.214    |
| loss_q2      | 0.214    |
| param_norm   | 228      |
| samples      | 671      |
| step         | 670      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.7      |
| loss         | 0.21     |
| loss_cal     | 0.0576   |
| loss_cal_q2  | 0.0576   |
| loss_diff    | 0.21     |
| loss_diff_q2 | 0.21     |
| loss_q2      | 0.21     |
| param_norm   | 228      |
| samples      | 672      |
| step         | 671      |
---------------------------
---------------------------
| grad_norm    | 3.99     |
| loss         | 0.0352   |
| loss_cal     | 0.0188   |
| loss_cal_q2  | 0.0188   |
| loss_diff    | 0.0352   |
| loss_diff_q2 | 0.0352   |
| loss_q2      | 0.0352   |
| param_norm   | 228      |
| samples      | 673      |
| step         | 672      |
---------------------------
---------------------------
| grad_norm    | 4.51     |
| loss         | 0.33     |
| loss_cal     | 0.0631   |
| loss_cal_q3  | 0.0631   |
| loss_diff    | 0.33     |
| loss_diff_q3 | 0.33     |
| loss_q3      | 0.33     |
| param_norm   | 228      |
| samples      | 674      |
| step         | 673      |
---------------------------
---------------------------
| grad_norm    | 2.93     |
| loss         | 0.29     |
| loss_cal     | 0.0207   |
| loss_cal_q3  | 0.0207   |
| loss_diff    | 0.29     |
| loss_diff_q3 | 0.29     |
| loss_q3      | 0.29     |
| param_norm   | 228      |
| samples      | 675      |
| step         | 674      |
---------------------------
---------------------------
| grad_norm    | 2.23     |
| loss         | 0.217    |
| loss_cal     | 0.0233   |
| loss_cal_q3  | 0.0233   |
| loss_diff    | 0.217    |
| loss_diff_q3 | 0.217    |
| loss_q3      | 0.217    |
| param_norm   | 228      |
| samples      | 676      |
| step         | 675      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.11     |
| loss         | 0.19     |
| loss_cal     | 0.0247   |
| loss_cal_q1  | 0.0247   |
| loss_diff    | 0.19     |
| loss_diff_q1 | 0.19     |
| loss_q1      | 0.19     |
| param_norm   | 228      |
| samples      | 677      |
| step         | 676      |
---------------------------
---------------------------
| grad_norm    | 1.01     |
| loss         | 0.0492   |
| loss_cal     | 0.0187   |
| loss_cal_q2  | 0.0187   |
| loss_diff    | 0.0492   |
| loss_diff_q2 | 0.0492   |
| loss_q2      | 0.0492   |
| param_norm   | 228      |
| samples      | 678      |
| step         | 677      |
---------------------------
---------------------------
| grad_norm    | 1.55     |
| loss         | 0.136    |
| loss_cal     | 0.0208   |
| loss_cal_q3  | 0.0208   |
| loss_diff    | 0.136    |
| loss_diff_q3 | 0.136    |
| loss_q3      | 0.136    |
| param_norm   | 228      |
| samples      | 679      |
| step         | 678      |
---------------------------
---------------------------
| grad_norm    | 1.37     |
| loss         | 0.11     |
| loss_cal     | 0.0245   |
| loss_cal_q2  | 0.0245   |
| loss_diff    | 0.11     |
| loss_diff_q2 | 0.11     |
| loss_q2      | 0.11     |
| param_norm   | 228      |
| samples      | 680      |
| step         | 679      |
---------------------------
---------------------------
| grad_norm    | 1.85     |
| loss         | 0.137    |
| loss_cal     | 0.0228   |
| loss_cal_q3  | 0.0228   |
| loss_diff    | 0.137    |
| loss_diff_q3 | 0.137    |
| loss_q3      | 0.137    |
| param_norm   | 228      |
| samples      | 681      |
| step         | 680      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.79     |
| loss         | 0.182    |
| loss_cal     | 0.0257   |
| loss_cal_q0  | 0.0257   |
| loss_diff    | 0.182    |
| loss_diff_q0 | 0.182    |
| loss_q0      | 0.182    |
| param_norm   | 228      |
| samples      | 682      |
| step         | 681      |
---------------------------
---------------------------
| grad_norm    | 2.34     |
| loss         | 0.147    |
| loss_cal     | 0.027    |
| loss_cal_q3  | 0.027    |
| loss_diff    | 0.147    |
| loss_diff_q3 | 0.147    |
| loss_q3      | 0.147    |
| param_norm   | 228      |
| samples      | 683      |
| step         | 682      |
---------------------------
---------------------------
| grad_norm    | 1.9      |
| loss         | 0.13     |
| loss_cal     | 0.0565   |
| loss_cal_q2  | 0.0565   |
| loss_diff    | 0.13     |
| loss_diff_q2 | 0.13     |
| loss_q2      | 0.13     |
| param_norm   | 228      |
| samples      | 684      |
| step         | 683      |
---------------------------
---------------------------
| grad_norm    | 1.13     |
| loss         | 0.08     |
| loss_cal     | 0.0192   |
| loss_cal_q2  | 0.0192   |
| loss_diff    | 0.08     |
| loss_diff_q2 | 0.08     |
| loss_q2      | 0.08     |
| param_norm   | 228      |
| samples      | 685      |
| step         | 684      |
---------------------------
---------------------------
| grad_norm    | 2.39     |
| loss         | 0.174    |
| loss_cal     | 0.0448   |
| loss_cal_q1  | 0.0448   |
| loss_diff    | 0.174    |
| loss_diff_q1 | 0.174    |
| loss_q1      | 0.174    |
| param_norm   | 228      |
| samples      | 686      |
| step         | 685      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.13     |
| loss         | 0.214    |
| loss_cal     | 0.0197   |
| loss_cal_q1  | 0.0197   |
| loss_diff    | 0.214    |
| loss_diff_q1 | 0.214    |
| loss_q1      | 0.214    |
| param_norm   | 228      |
| samples      | 687      |
| step         | 686      |
---------------------------
---------------------------
| grad_norm    | 1.36     |
| loss         | 0.102    |
| loss_cal     | 0.019    |
| loss_cal_q1  | 0.019    |
| loss_diff    | 0.102    |
| loss_diff_q1 | 0.102    |
| loss_q1      | 0.102    |
| param_norm   | 228      |
| samples      | 688      |
| step         | 687      |
---------------------------
---------------------------
| grad_norm    | 1.04     |
| loss         | 0.0372   |
| loss_cal     | 0.0186   |
| loss_cal_q1  | 0.0186   |
| loss_diff    | 0.0372   |
| loss_diff_q1 | 0.0372   |
| loss_q1      | 0.0372   |
| param_norm   | 228      |
| samples      | 689      |
| step         | 688      |
---------------------------
---------------------------
| grad_norm    | 3.29     |
| loss         | 0.213    |
| loss_cal     | 0.0185   |
| loss_cal_q0  | 0.0185   |
| loss_diff    | 0.213    |
| loss_diff_q0 | 0.213    |
| loss_q0      | 0.213    |
| param_norm   | 228      |
| samples      | 690      |
| step         | 689      |
---------------------------
---------------------------
| grad_norm    | 1.83     |
| loss         | 0.0851   |
| loss_cal     | 0.0203   |
| loss_cal_q3  | 0.0203   |
| loss_diff    | 0.0851   |
| loss_diff_q3 | 0.0851   |
| loss_q3      | 0.0851   |
| param_norm   | 228      |
| samples      | 691      |
| step         | 690      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.03     |
| loss         | 0.157    |
| loss_cal     | 0.0441   |
| loss_cal_q2  | 0.0441   |
| loss_diff    | 0.157    |
| loss_diff_q2 | 0.157    |
| loss_q2      | 0.157    |
| param_norm   | 228      |
| samples      | 692      |
| step         | 691      |
---------------------------
---------------------------
| grad_norm    | 1.47     |
| loss         | 0.102    |
| loss_cal     | 0.0191   |
| loss_cal_q0  | 0.0191   |
| loss_diff    | 0.102    |
| loss_diff_q0 | 0.102    |
| loss_q0      | 0.102    |
| param_norm   | 228      |
| samples      | 693      |
| step         | 692      |
---------------------------
---------------------------
| grad_norm    | 2.86     |
| loss         | 0.0441   |
| loss_cal     | 0.0178   |
| loss_cal_q3  | 0.0178   |
| loss_diff    | 0.0441   |
| loss_diff_q3 | 0.0441   |
| loss_q3      | 0.0441   |
| param_norm   | 228      |
| samples      | 694      |
| step         | 693      |
---------------------------
---------------------------
| grad_norm    | 3.1      |
| loss         | 0.17     |
| loss_cal     | 0.0192   |
| loss_cal_q0  | 0.0192   |
| loss_diff    | 0.17     |
| loss_diff_q0 | 0.17     |
| loss_q0      | 0.17     |
| param_norm   | 228      |
| samples      | 695      |
| step         | 694      |
---------------------------
---------------------------
| grad_norm    | 1.45     |
| loss         | 0.0767   |
| loss_cal     | 0.0196   |
| loss_cal_q3  | 0.0196   |
| loss_diff    | 0.0767   |
| loss_diff_q3 | 0.0767   |
| loss_q3      | 0.0767   |
| param_norm   | 228      |
| samples      | 696      |
| step         | 695      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.09     |
| loss         | 0.176    |
| loss_cal     | 0.0407   |
| loss_cal_q2  | 0.0407   |
| loss_diff    | 0.176    |
| loss_diff_q2 | 0.176    |
| loss_q2      | 0.176    |
| param_norm   | 228      |
| samples      | 697      |
| step         | 696      |
---------------------------
---------------------------
| grad_norm    | 1.61     |
| loss         | 0.136    |
| loss_cal     | 0.0188   |
| loss_cal_q1  | 0.0188   |
| loss_diff    | 0.136    |
| loss_diff_q1 | 0.136    |
| loss_q1      | 0.136    |
| param_norm   | 228      |
| samples      | 698      |
| step         | 697      |
---------------------------
---------------------------
| grad_norm    | 1.92     |
| loss         | 0.1      |
| loss_cal     | 0.0202   |
| loss_cal_q1  | 0.0202   |
| loss_diff    | 0.1      |
| loss_diff_q1 | 0.1      |
| loss_q1      | 0.1      |
| param_norm   | 228      |
| samples      | 699      |
| step         | 698      |
---------------------------
---------------------------
| grad_norm    | 2.4      |
| loss         | 0.132    |
| loss_cal     | 0.0485   |
| loss_cal_q2  | 0.0485   |
| loss_diff    | 0.132    |
| loss_diff_q2 | 0.132    |
| loss_q2      | 0.132    |
| param_norm   | 228      |
| samples      | 700      |
| step         | 699      |
---------------------------
---------------------------
| grad_norm    | 3.99     |
| loss         | 0.913    |
| loss_cal     | 0.0196   |
| loss_cal_q0  | 0.0196   |
| loss_diff    | 0.913    |
| loss_diff_q0 | 0.913    |
| loss_q0      | 0.913    |
| param_norm   | 228      |
| samples      | 701      |
| step         | 700      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.16     |
| loss         | 0.0811   |
| loss_cal     | 0.0198   |
| loss_cal_q2  | 0.0198   |
| loss_diff    | 0.0811   |
| loss_diff_q2 | 0.0811   |
| loss_q2      | 0.0811   |
| param_norm   | 228      |
| samples      | 702      |
| step         | 701      |
---------------------------
---------------------------
| grad_norm    | 3.78     |
| loss         | 0.0362   |
| loss_cal     | 0.0179   |
| loss_cal_q1  | 0.0179   |
| loss_diff    | 0.0362   |
| loss_diff_q1 | 0.0362   |
| loss_q1      | 0.0362   |
| param_norm   | 228      |
| samples      | 703      |
| step         | 702      |
---------------------------
---------------------------
| grad_norm    | 8.67     |
| loss         | 0.725    |
| loss_cal     | 0.0196   |
| loss_cal_q0  | 0.0196   |
| loss_diff    | 0.725    |
| loss_diff_q0 | 0.725    |
| loss_q0      | 0.725    |
| param_norm   | 228      |
| samples      | 704      |
| step         | 703      |
---------------------------
---------------------------
| grad_norm    | 1.53     |
| loss         | 0.07     |
| loss_cal     | 0.0181   |
| loss_cal_q0  | 0.0181   |
| loss_diff    | 0.07     |
| loss_diff_q0 | 0.07     |
| loss_q0      | 0.07     |
| param_norm   | 228      |
| samples      | 705      |
| step         | 704      |
---------------------------
---------------------------
| grad_norm    | 3.21     |
| loss         | 0.224    |
| loss_cal     | 0.0723   |
| loss_cal_q3  | 0.0723   |
| loss_diff    | 0.224    |
| loss_diff_q3 | 0.224    |
| loss_q3      | 0.224    |
| param_norm   | 228      |
| samples      | 706      |
| step         | 705      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.42     |
| loss         | 0.122    |
| loss_cal     | 0.0193   |
| loss_cal_q0  | 0.0193   |
| loss_diff    | 0.122    |
| loss_diff_q0 | 0.122    |
| loss_q0      | 0.122    |
| param_norm   | 228      |
| samples      | 707      |
| step         | 706      |
---------------------------
---------------------------
| grad_norm    | 2.52     |
| loss         | 0.173    |
| loss_cal     | 0.0201   |
| loss_cal_q1  | 0.0201   |
| loss_diff    | 0.173    |
| loss_diff_q1 | 0.173    |
| loss_q1      | 0.173    |
| param_norm   | 228      |
| samples      | 708      |
| step         | 707      |
---------------------------
---------------------------
| grad_norm    | 3.89     |
| loss         | 0.0345   |
| loss_cal     | 0.0176   |
| loss_cal_q3  | 0.0176   |
| loss_diff    | 0.0345   |
| loss_diff_q3 | 0.0345   |
| loss_q3      | 0.0345   |
| param_norm   | 228      |
| samples      | 709      |
| step         | 708      |
---------------------------
---------------------------
| grad_norm    | 1.02     |
| loss         | 0.0355   |
| loss_cal     | 0.018    |
| loss_cal_q2  | 0.018    |
| loss_diff    | 0.0355   |
| loss_diff_q2 | 0.0355   |
| loss_q2      | 0.0355   |
| param_norm   | 228      |
| samples      | 710      |
| step         | 709      |
---------------------------
---------------------------
| grad_norm    | 4.24     |
| loss         | 0.0701   |
| loss_cal     | 0.0172   |
| loss_cal_q0  | 0.0172   |
| loss_diff    | 0.0701   |
| loss_diff_q0 | 0.0701   |
| loss_q0      | 0.0701   |
| param_norm   | 228      |
| samples      | 711      |
| step         | 710      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.65     |
| loss         | 0.172    |
| loss_cal     | 0.0195   |
| loss_cal_q0  | 0.0195   |
| loss_diff    | 0.172    |
| loss_diff_q0 | 0.172    |
| loss_q0      | 0.172    |
| param_norm   | 228      |
| samples      | 712      |
| step         | 711      |
---------------------------
---------------------------
| grad_norm    | 1.69     |
| loss         | 0.103    |
| loss_cal     | 0.0303   |
| loss_cal_q2  | 0.0303   |
| loss_diff    | 0.103    |
| loss_diff_q2 | 0.103    |
| loss_q2      | 0.103    |
| param_norm   | 228      |
| samples      | 713      |
| step         | 712      |
---------------------------
---------------------------
| grad_norm    | 1.28     |
| loss         | 0.0752   |
| loss_cal     | 0.0177   |
| loss_cal_q1  | 0.0177   |
| loss_diff    | 0.0752   |
| loss_diff_q1 | 0.0752   |
| loss_q1      | 0.0752   |
| param_norm   | 228      |
| samples      | 714      |
| step         | 713      |
---------------------------
---------------------------
| grad_norm    | 2.23     |
| loss         | 0.16     |
| loss_cal     | 0.0195   |
| loss_cal_q1  | 0.0195   |
| loss_diff    | 0.16     |
| loss_diff_q1 | 0.16     |
| loss_q1      | 0.16     |
| param_norm   | 228      |
| samples      | 715      |
| step         | 714      |
---------------------------
---------------------------
| grad_norm    | 2.45     |
| loss         | 0.15     |
| loss_cal     | 0.0194   |
| loss_cal_q0  | 0.0194   |
| loss_diff    | 0.15     |
| loss_diff_q0 | 0.15     |
| loss_q0      | 0.15     |
| param_norm   | 228      |
| samples      | 716      |
| step         | 715      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.45     |
| loss         | 0.153    |
| loss_cal     | 0.0831   |
| loss_cal_q2  | 0.0831   |
| loss_diff    | 0.153    |
| loss_diff_q2 | 0.153    |
| loss_q2      | 0.153    |
| param_norm   | 228      |
| samples      | 717      |
| step         | 716      |
---------------------------
---------------------------
| grad_norm    | 2.7      |
| loss         | 0.219    |
| loss_cal     | 0.0389   |
| loss_cal_q2  | 0.0389   |
| loss_diff    | 0.219    |
| loss_diff_q2 | 0.219    |
| loss_q2      | 0.219    |
| param_norm   | 228      |
| samples      | 718      |
| step         | 717      |
---------------------------
---------------------------
| grad_norm    | 2.13     |
| loss         | 0.111    |
| loss_cal     | 0.0352   |
| loss_cal_q2  | 0.0352   |
| loss_diff    | 0.111    |
| loss_diff_q2 | 0.111    |
| loss_q2      | 0.111    |
| param_norm   | 228      |
| samples      | 719      |
| step         | 718      |
---------------------------
---------------------------
| grad_norm    | 1.45     |
| loss         | 0.138    |
| loss_cal     | 0.0181   |
| loss_cal_q1  | 0.0181   |
| loss_diff    | 0.138    |
| loss_diff_q1 | 0.138    |
| loss_q1      | 0.138    |
| param_norm   | 228      |
| samples      | 720      |
| step         | 719      |
---------------------------
---------------------------
| grad_norm    | 5.1      |
| loss         | 0.334    |
| loss_cal     | 0.0441   |
| loss_cal_q0  | 0.0441   |
| loss_diff    | 0.334    |
| loss_diff_q0 | 0.334    |
| loss_q0      | 0.334    |
| param_norm   | 228      |
| samples      | 721      |
| step         | 720      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.23     |
| loss         | 0.0343   |
| loss_cal     | 0.017    |
| loss_cal_q1  | 0.017    |
| loss_diff    | 0.0343   |
| loss_diff_q1 | 0.0343   |
| loss_q1      | 0.0343   |
| param_norm   | 228      |
| samples      | 722      |
| step         | 721      |
---------------------------
---------------------------
| grad_norm    | 1.09     |
| loss         | 0.06     |
| loss_cal     | 0.0178   |
| loss_cal_q1  | 0.0178   |
| loss_diff    | 0.06     |
| loss_diff_q1 | 0.06     |
| loss_q1      | 0.06     |
| param_norm   | 228      |
| samples      | 723      |
| step         | 722      |
---------------------------
---------------------------
| grad_norm    | 3.59     |
| loss         | 0.033    |
| loss_cal     | 0.0168   |
| loss_cal_q3  | 0.0168   |
| loss_diff    | 0.033    |
| loss_diff_q3 | 0.033    |
| loss_q3      | 0.033    |
| param_norm   | 228      |
| samples      | 724      |
| step         | 723      |
---------------------------
---------------------------
| grad_norm    | 2.72     |
| loss         | 0.118    |
| loss_cal     | 0.0441   |
| loss_cal_q1  | 0.0441   |
| loss_diff    | 0.118    |
| loss_diff_q1 | 0.118    |
| loss_q1      | 0.118    |
| param_norm   | 228      |
| samples      | 725      |
| step         | 724      |
---------------------------
---------------------------
| grad_norm    | 4.1      |
| loss         | 0.199    |
| loss_cal     | 0.0193   |
| loss_cal_q1  | 0.0193   |
| loss_diff    | 0.199    |
| loss_diff_q1 | 0.199    |
| loss_q1      | 0.199    |
| param_norm   | 228      |
| samples      | 726      |
| step         | 725      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.53     |
| loss         | 0.207    |
| loss_cal     | 0.0185   |
| loss_cal_q2  | 0.0185   |
| loss_diff    | 0.207    |
| loss_diff_q2 | 0.207    |
| loss_q2      | 0.207    |
| param_norm   | 228      |
| samples      | 727      |
| step         | 726      |
---------------------------
---------------------------
| grad_norm    | 0.89     |
| loss         | 0.0582   |
| loss_cal     | 0.017    |
| loss_cal_q3  | 0.017    |
| loss_diff    | 0.0582   |
| loss_diff_q3 | 0.0582   |
| loss_q3      | 0.0582   |
| param_norm   | 228      |
| samples      | 728      |
| step         | 727      |
---------------------------
---------------------------
| grad_norm    | 8.87     |
| loss         | 0.859    |
| loss_cal     | 0.0192   |
| loss_cal_q0  | 0.0192   |
| loss_diff    | 0.859    |
| loss_diff_q0 | 0.859    |
| loss_q0      | 0.859    |
| param_norm   | 228      |
| samples      | 729      |
| step         | 728      |
---------------------------
---------------------------
| grad_norm    | 2.73     |
| loss         | 0.202    |
| loss_cal     | 0.0272   |
| loss_cal_q2  | 0.0272   |
| loss_diff    | 0.202    |
| loss_diff_q2 | 0.202    |
| loss_q2      | 0.202    |
| param_norm   | 228      |
| samples      | 730      |
| step         | 729      |
---------------------------
---------------------------
| grad_norm    | 2.25     |
| loss         | 0.122    |
| loss_cal     | 0.0356   |
| loss_cal_q3  | 0.0356   |
| loss_diff    | 0.122    |
| loss_diff_q3 | 0.122    |
| loss_q3      | 0.122    |
| param_norm   | 228      |
| samples      | 731      |
| step         | 730      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.34     |
| loss         | 0.111    |
| loss_cal     | 0.0178   |
| loss_cal_q2  | 0.0178   |
| loss_diff    | 0.111    |
| loss_diff_q2 | 0.111    |
| loss_q2      | 0.111    |
| param_norm   | 228      |
| samples      | 732      |
| step         | 731      |
---------------------------
---------------------------
| grad_norm    | 1.69     |
| loss         | 0.124    |
| loss_cal     | 0.0188   |
| loss_cal_q3  | 0.0188   |
| loss_diff    | 0.124    |
| loss_diff_q3 | 0.124    |
| loss_q3      | 0.124    |
| param_norm   | 228      |
| samples      | 733      |
| step         | 732      |
---------------------------
---------------------------
| grad_norm    | 3.66     |
| loss         | 0.256    |
| loss_cal     | 0.0245   |
| loss_cal_q1  | 0.0245   |
| loss_diff    | 0.256    |
| loss_diff_q1 | 0.256    |
| loss_q1      | 0.256    |
| param_norm   | 228      |
| samples      | 734      |
| step         | 733      |
---------------------------
---------------------------
| grad_norm    | 1.82     |
| loss         | 0.0299   |
| loss_cal     | 0.0167   |
| loss_cal_q2  | 0.0167   |
| loss_diff    | 0.0299   |
| loss_diff_q2 | 0.0299   |
| loss_q2      | 0.0299   |
| param_norm   | 228      |
| samples      | 735      |
| step         | 734      |
---------------------------
---------------------------
| grad_norm    | 2.67     |
| loss         | 0.193    |
| loss_cal     | 0.0245   |
| loss_cal_q2  | 0.0245   |
| loss_diff    | 0.193    |
| loss_diff_q2 | 0.193    |
| loss_q2      | 0.193    |
| param_norm   | 228      |
| samples      | 736      |
| step         | 735      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.09     |
| loss         | 0.0532   |
| loss_cal     | 0.0179   |
| loss_cal_q1  | 0.0179   |
| loss_diff    | 0.0532   |
| loss_diff_q1 | 0.0532   |
| loss_q1      | 0.0532   |
| param_norm   | 228      |
| samples      | 737      |
| step         | 736      |
---------------------------
---------------------------
| grad_norm    | 3.7      |
| loss         | 0.211    |
| loss_cal     | 0.0401   |
| loss_cal_q0  | 0.0401   |
| loss_diff    | 0.211    |
| loss_diff_q0 | 0.211    |
| loss_q0      | 0.211    |
| param_norm   | 228      |
| samples      | 738      |
| step         | 737      |
---------------------------
---------------------------
| grad_norm    | 1.39     |
| loss         | 0.108    |
| loss_cal     | 0.0182   |
| loss_cal_q0  | 0.0182   |
| loss_diff    | 0.108    |
| loss_diff_q0 | 0.108    |
| loss_q0      | 0.108    |
| param_norm   | 228      |
| samples      | 739      |
| step         | 738      |
---------------------------
---------------------------
| grad_norm    | 3.69     |
| loss         | 0.945    |
| loss_cal     | 0.0176   |
| loss_cal_q0  | 0.0176   |
| loss_diff    | 0.945    |
| loss_diff_q0 | 0.945    |
| loss_q0      | 0.945    |
| param_norm   | 228      |
| samples      | 740      |
| step         | 739      |
---------------------------
---------------------------
| grad_norm    | 5.42     |
| loss         | 0.0302   |
| loss_cal     | 0.0167   |
| loss_cal_q2  | 0.0167   |
| loss_diff    | 0.0302   |
| loss_diff_q2 | 0.0302   |
| loss_q2      | 0.0302   |
| param_norm   | 228      |
| samples      | 741      |
| step         | 740      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.2      |
| loss         | 0.165    |
| loss_cal     | 0.0516   |
| loss_cal_q2  | 0.0516   |
| loss_diff    | 0.165    |
| loss_diff_q2 | 0.165    |
| loss_q2      | 0.165    |
| param_norm   | 228      |
| samples      | 742      |
| step         | 741      |
---------------------------
---------------------------
| grad_norm    | 1.05     |
| loss         | 0.0634   |
| loss_cal     | 0.0174   |
| loss_cal_q1  | 0.0174   |
| loss_diff    | 0.0634   |
| loss_diff_q1 | 0.0634   |
| loss_q1      | 0.0634   |
| param_norm   | 228      |
| samples      | 743      |
| step         | 742      |
---------------------------
---------------------------
| grad_norm    | 3.85     |
| loss         | 0.285    |
| loss_cal     | 0.0181   |
| loss_cal_q0  | 0.0181   |
| loss_diff    | 0.285    |
| loss_diff_q0 | 0.285    |
| loss_q0      | 0.285    |
| param_norm   | 228      |
| samples      | 744      |
| step         | 743      |
---------------------------
---------------------------
| grad_norm    | 2.07     |
| loss         | 0.162    |
| loss_cal     | 0.0321   |
| loss_cal_q3  | 0.0321   |
| loss_diff    | 0.162    |
| loss_diff_q3 | 0.162    |
| loss_q3      | 0.162    |
| param_norm   | 228      |
| samples      | 745      |
| step         | 744      |
---------------------------
---------------------------
| grad_norm    | 2.33     |
| loss         | 0.0462   |
| loss_cal     | 0.0162   |
| loss_cal_q0  | 0.0162   |
| loss_diff    | 0.0462   |
| loss_diff_q0 | 0.0462   |
| loss_q0      | 0.0462   |
| param_norm   | 228      |
| samples      | 746      |
| step         | 745      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.71     |
| loss         | 0.181    |
| loss_cal     | 0.0447   |
| loss_cal_q2  | 0.0447   |
| loss_diff    | 0.181    |
| loss_diff_q2 | 0.181    |
| loss_q2      | 0.181    |
| param_norm   | 228      |
| samples      | 747      |
| step         | 746      |
---------------------------
---------------------------
| grad_norm    | 3.15     |
| loss         | 0.188    |
| loss_cal     | 0.0176   |
| loss_cal_q0  | 0.0176   |
| loss_diff    | 0.188    |
| loss_diff_q0 | 0.188    |
| loss_q0      | 0.188    |
| param_norm   | 228      |
| samples      | 748      |
| step         | 747      |
---------------------------
---------------------------
| grad_norm    | 2.12     |
| loss         | 0.116    |
| loss_cal     | 0.0638   |
| loss_cal_q1  | 0.0638   |
| loss_diff    | 0.116    |
| loss_diff_q1 | 0.116    |
| loss_q1      | 0.116    |
| param_norm   | 228      |
| samples      | 749      |
| step         | 748      |
---------------------------
---------------------------
| grad_norm    | 1.27     |
| loss         | 0.0623   |
| loss_cal     | 0.0171   |
| loss_cal_q3  | 0.0171   |
| loss_diff    | 0.0623   |
| loss_diff_q3 | 0.0623   |
| loss_q3      | 0.0623   |
| param_norm   | 228      |
| samples      | 750      |
| step         | 749      |
---------------------------
---------------------------
| grad_norm    | 1.85     |
| loss         | 0.132    |
| loss_cal     | 0.019    |
| loss_cal_q1  | 0.019    |
| loss_diff    | 0.132    |
| loss_diff_q1 | 0.132    |
| loss_q1      | 0.132    |
| param_norm   | 228      |
| samples      | 751      |
| step         | 750      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.13     |
| loss         | 0.0536   |
| loss_cal     | 0.0173   |
| loss_cal_q2  | 0.0173   |
| loss_diff    | 0.0536   |
| loss_diff_q2 | 0.0536   |
| loss_q2      | 0.0536   |
| param_norm   | 228      |
| samples      | 752      |
| step         | 751      |
---------------------------
---------------------------
| grad_norm    | 1.16     |
| loss         | 0.07     |
| loss_cal     | 0.0299   |
| loss_cal_q1  | 0.0299   |
| loss_diff    | 0.07     |
| loss_diff_q1 | 0.07     |
| loss_q1      | 0.07     |
| param_norm   | 228      |
| samples      | 753      |
| step         | 752      |
---------------------------
---------------------------
| grad_norm    | 0.85     |
| loss         | 0.043    |
| loss_cal     | 0.0165   |
| loss_cal_q2  | 0.0165   |
| loss_diff    | 0.043    |
| loss_diff_q2 | 0.043    |
| loss_q2      | 0.043    |
| param_norm   | 228      |
| samples      | 754      |
| step         | 753      |
---------------------------
---------------------------
| grad_norm    | 9.44     |
| loss         | 0.336    |
| loss_cal     | 0.0367   |
| loss_cal_q0  | 0.0367   |
| loss_diff    | 0.336    |
| loss_diff_q0 | 0.336    |
| loss_q0      | 0.336    |
| param_norm   | 228      |
| samples      | 755      |
| step         | 754      |
---------------------------
---------------------------
| grad_norm    | 2.99     |
| loss         | 0.0271   |
| loss_cal     | 0.0162   |
| loss_cal_q1  | 0.0162   |
| loss_diff    | 0.0271   |
| loss_diff_q1 | 0.0271   |
| loss_q1      | 0.0271   |
| param_norm   | 228      |
| samples      | 756      |
| step         | 755      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.45     |
| loss         | 0.0979   |
| loss_cal     | 0.0224   |
| loss_cal_q1  | 0.0224   |
| loss_diff    | 0.0979   |
| loss_diff_q1 | 0.0979   |
| loss_q1      | 0.0979   |
| param_norm   | 228      |
| samples      | 757      |
| step         | 756      |
---------------------------
---------------------------
| grad_norm    | 2.39     |
| loss         | 0.0299   |
| loss_cal     | 0.016    |
| loss_cal_q0  | 0.016    |
| loss_diff    | 0.0299   |
| loss_diff_q0 | 0.0299   |
| loss_q0      | 0.0299   |
| param_norm   | 228      |
| samples      | 758      |
| step         | 757      |
---------------------------
---------------------------
| grad_norm    | 1.13     |
| loss         | 0.0322   |
| loss_cal     | 0.0163   |
| loss_cal_q2  | 0.0163   |
| loss_diff    | 0.0322   |
| loss_diff_q2 | 0.0322   |
| loss_q2      | 0.0322   |
| param_norm   | 228      |
| samples      | 759      |
| step         | 758      |
---------------------------
---------------------------
| grad_norm    | 2.72     |
| loss         | 0.198    |
| loss_cal     | 0.0271   |
| loss_cal_q0  | 0.0271   |
| loss_diff    | 0.198    |
| loss_diff_q0 | 0.198    |
| loss_q0      | 0.198    |
| param_norm   | 228      |
| samples      | 760      |
| step         | 759      |
---------------------------
---------------------------
| grad_norm    | 3.41     |
| loss         | 0.199    |
| loss_cal     | 0.0506   |
| loss_cal_q1  | 0.0506   |
| loss_diff    | 0.199    |
| loss_diff_q1 | 0.199    |
| loss_q1      | 0.199    |
| param_norm   | 228      |
| samples      | 761      |
| step         | 760      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.18     |
| loss         | 0.219    |
| loss_cal     | 0.0187   |
| loss_cal_q2  | 0.0187   |
| loss_diff    | 0.219    |
| loss_diff_q2 | 0.219    |
| loss_q2      | 0.219    |
| param_norm   | 228      |
| samples      | 762      |
| step         | 761      |
---------------------------
---------------------------
| grad_norm    | 4.13     |
| loss         | 0.884    |
| loss_cal     | 0.0396   |
| loss_cal_q0  | 0.0396   |
| loss_diff    | 0.884    |
| loss_diff_q0 | 0.884    |
| loss_q0      | 0.884    |
| param_norm   | 228      |
| samples      | 763      |
| step         | 762      |
---------------------------
---------------------------
| grad_norm    | 1.04     |
| loss         | 0.0554   |
| loss_cal     | 0.0168   |
| loss_cal_q1  | 0.0168   |
| loss_diff    | 0.0554   |
| loss_diff_q1 | 0.0554   |
| loss_q1      | 0.0554   |
| param_norm   | 228      |
| samples      | 764      |
| step         | 763      |
---------------------------
---------------------------
| grad_norm    | 2.04     |
| loss         | 0.179    |
| loss_cal     | 0.0551   |
| loss_cal_q2  | 0.0551   |
| loss_diff    | 0.179    |
| loss_diff_q2 | 0.179    |
| loss_q2      | 0.179    |
| param_norm   | 228      |
| samples      | 765      |
| step         | 764      |
---------------------------
---------------------------
| grad_norm    | 1.28     |
| loss         | 0.141    |
| loss_cal     | 0.0172   |
| loss_cal_q2  | 0.0172   |
| loss_diff    | 0.141    |
| loss_diff_q2 | 0.141    |
| loss_q2      | 0.141    |
| param_norm   | 228      |
| samples      | 766      |
| step         | 765      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.71     |
| loss         | 0.303    |
| loss_cal     | 0.0181   |
| loss_cal_q0  | 0.0181   |
| loss_diff    | 0.303    |
| loss_diff_q0 | 0.303    |
| loss_q0      | 0.303    |
| param_norm   | 228      |
| samples      | 767      |
| step         | 766      |
---------------------------
---------------------------
| grad_norm    | 1.26     |
| loss         | 0.0651   |
| loss_cal     | 0.0161   |
| loss_cal_q0  | 0.0161   |
| loss_diff    | 0.0651   |
| loss_diff_q0 | 0.0651   |
| loss_q0      | 0.0651   |
| param_norm   | 228      |
| samples      | 768      |
| step         | 767      |
---------------------------
---------------------------
| grad_norm    | 1.51     |
| loss         | 0.0871   |
| loss_cal     | 0.0468   |
| loss_cal_q1  | 0.0468   |
| loss_diff    | 0.0871   |
| loss_diff_q1 | 0.0871   |
| loss_q1      | 0.0871   |
| param_norm   | 228      |
| samples      | 769      |
| step         | 768      |
---------------------------
---------------------------
| grad_norm    | 2.08     |
| loss         | 0.108    |
| loss_cal     | 0.0533   |
| loss_cal_q1  | 0.0533   |
| loss_diff    | 0.108    |
| loss_diff_q1 | 0.108    |
| loss_q1      | 0.108    |
| param_norm   | 228      |
| samples      | 770      |
| step         | 769      |
---------------------------
---------------------------
| grad_norm    | 1.37     |
| loss         | 0.0809   |
| loss_cal     | 0.0169   |
| loss_cal_q2  | 0.0169   |
| loss_diff    | 0.0809   |
| loss_diff_q2 | 0.0809   |
| loss_q2      | 0.0809   |
| param_norm   | 228      |
| samples      | 771      |
| step         | 770      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.4      |
| loss         | 0.143    |
| loss_cal     | 0.0415   |
| loss_cal_q0  | 0.0415   |
| loss_diff    | 0.143    |
| loss_diff_q0 | 0.143    |
| loss_q0      | 0.143    |
| param_norm   | 228      |
| samples      | 772      |
| step         | 771      |
---------------------------
---------------------------
| grad_norm    | 1.37     |
| loss         | 0.0708   |
| loss_cal     | 0.027    |
| loss_cal_q2  | 0.027    |
| loss_diff    | 0.0708   |
| loss_diff_q2 | 0.0708   |
| loss_q2      | 0.0708   |
| param_norm   | 228      |
| samples      | 773      |
| step         | 772      |
---------------------------
---------------------------
| grad_norm    | 1.49     |
| loss         | 0.0719   |
| loss_cal     | 0.0177   |
| loss_cal_q2  | 0.0177   |
| loss_diff    | 0.0719   |
| loss_diff_q2 | 0.0719   |
| loss_q2      | 0.0719   |
| param_norm   | 228      |
| samples      | 774      |
| step         | 773      |
---------------------------
---------------------------
| grad_norm    | 1.26     |
| loss         | 0.049    |
| loss_cal     | 0.0166   |
| loss_cal_q1  | 0.0166   |
| loss_diff    | 0.049    |
| loss_diff_q1 | 0.049    |
| loss_q1      | 0.049    |
| param_norm   | 228      |
| samples      | 775      |
| step         | 774      |
---------------------------
---------------------------
| grad_norm    | 3.23     |
| loss         | 0.246    |
| loss_cal     | 0.0203   |
| loss_cal_q3  | 0.0203   |
| loss_diff    | 0.246    |
| loss_diff_q3 | 0.246    |
| loss_q3      | 0.246    |
| param_norm   | 228      |
| samples      | 776      |
| step         | 775      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.38     |
| loss         | 0.0633   |
| loss_cal     | 0.0165   |
| loss_cal_q1  | 0.0165   |
| loss_diff    | 0.0633   |
| loss_diff_q1 | 0.0633   |
| loss_q1      | 0.0633   |
| param_norm   | 228      |
| samples      | 777      |
| step         | 776      |
---------------------------
---------------------------
| grad_norm    | 3.05     |
| loss         | 0.209    |
| loss_cal     | 0.0639   |
| loss_cal_q3  | 0.0639   |
| loss_diff    | 0.209    |
| loss_diff_q3 | 0.209    |
| loss_q3      | 0.209    |
| param_norm   | 228      |
| samples      | 778      |
| step         | 777      |
---------------------------
---------------------------
| grad_norm    | 1.62     |
| loss         | 0.0878   |
| loss_cal     | 0.0172   |
| loss_cal_q1  | 0.0172   |
| loss_diff    | 0.0878   |
| loss_diff_q1 | 0.0878   |
| loss_q1      | 0.0878   |
| param_norm   | 228      |
| samples      | 779      |
| step         | 778      |
---------------------------
---------------------------
| grad_norm    | 3.51     |
| loss         | 0.218    |
| loss_cal     | 0.0258   |
| loss_cal_q0  | 0.0258   |
| loss_diff    | 0.218    |
| loss_diff_q0 | 0.218    |
| loss_q0      | 0.218    |
| param_norm   | 228      |
| samples      | 780      |
| step         | 779      |
---------------------------
---------------------------
| grad_norm    | 3.03     |
| loss         | 0.173    |
| loss_cal     | 0.041    |
| loss_cal_q2  | 0.041    |
| loss_diff    | 0.173    |
| loss_diff_q2 | 0.173    |
| loss_q2      | 0.173    |
| param_norm   | 228      |
| samples      | 781      |
| step         | 780      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.51     |
| loss         | 0.0866   |
| loss_cal     | 0.0244   |
| loss_cal_q2  | 0.0244   |
| loss_diff    | 0.0866   |
| loss_diff_q2 | 0.0866   |
| loss_q2      | 0.0866   |
| param_norm   | 228      |
| samples      | 782      |
| step         | 781      |
---------------------------
---------------------------
| grad_norm    | 0.815    |
| loss         | 0.0255   |
| loss_cal     | 0.0158   |
| loss_cal_q0  | 0.0158   |
| loss_diff    | 0.0255   |
| loss_diff_q0 | 0.0255   |
| loss_q0      | 0.0255   |
| param_norm   | 228      |
| samples      | 783      |
| step         | 782      |
---------------------------
---------------------------
| grad_norm    | 1.29     |
| loss         | 0.0669   |
| loss_cal     | 0.0169   |
| loss_cal_q2  | 0.0169   |
| loss_diff    | 0.0669   |
| loss_diff_q2 | 0.0669   |
| loss_q2      | 0.0669   |
| param_norm   | 228      |
| samples      | 784      |
| step         | 783      |
---------------------------
---------------------------
| grad_norm    | 1.7      |
| loss         | 0.0629   |
| loss_cal     | 0.0168   |
| loss_cal_q2  | 0.0168   |
| loss_diff    | 0.0629   |
| loss_diff_q2 | 0.0629   |
| loss_q2      | 0.0629   |
| param_norm   | 228      |
| samples      | 785      |
| step         | 784      |
---------------------------
---------------------------
| grad_norm    | 3.74     |
| loss         | 0.176    |
| loss_cal     | 0.0475   |
| loss_cal_q3  | 0.0475   |
| loss_diff    | 0.176    |
| loss_diff_q3 | 0.176    |
| loss_q3      | 0.176    |
| param_norm   | 228      |
| samples      | 786      |
| step         | 785      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 6.45     |
| loss         | 0.82     |
| loss_cal     | 0.0175   |
| loss_cal_q0  | 0.0175   |
| loss_diff    | 0.82     |
| loss_diff_q0 | 0.82     |
| loss_q0      | 0.82     |
| param_norm   | 228      |
| samples      | 787      |
| step         | 786      |
---------------------------
---------------------------
| grad_norm    | 4.63     |
| loss         | 0.207    |
| loss_cal     | 0.0161   |
| loss_cal_q0  | 0.0161   |
| loss_diff    | 0.207    |
| loss_diff_q0 | 0.207    |
| loss_q0      | 0.207    |
| param_norm   | 228      |
| samples      | 788      |
| step         | 787      |
---------------------------
---------------------------
| grad_norm    | 1.59     |
| loss         | 0.109    |
| loss_cal     | 0.0161   |
| loss_cal_q1  | 0.0161   |
| loss_diff    | 0.109    |
| loss_diff_q1 | 0.109    |
| loss_q1      | 0.109    |
| param_norm   | 228      |
| samples      | 789      |
| step         | 788      |
---------------------------
---------------------------
| grad_norm    | 6.05     |
| loss         | 0.255    |
| loss_cal     | 0.0355   |
| loss_cal_q0  | 0.0355   |
| loss_diff    | 0.255    |
| loss_diff_q0 | 0.255    |
| loss_q0      | 0.255    |
| param_norm   | 228      |
| samples      | 790      |
| step         | 789      |
---------------------------
---------------------------
| grad_norm    | 1.38     |
| loss         | 0.101    |
| loss_cal     | 0.0166   |
| loss_cal_q1  | 0.0166   |
| loss_diff    | 0.101    |
| loss_diff_q1 | 0.101    |
| loss_q1      | 0.101    |
| param_norm   | 228      |
| samples      | 791      |
| step         | 790      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.43     |
| loss         | 0.18     |
| loss_cal     | 0.0168   |
| loss_cal_q1  | 0.0168   |
| loss_diff    | 0.18     |
| loss_diff_q1 | 0.18     |
| loss_q1      | 0.18     |
| param_norm   | 228      |
| samples      | 792      |
| step         | 791      |
---------------------------
---------------------------
| grad_norm    | 2.48     |
| loss         | 0.1      |
| loss_cal     | 0.0372   |
| loss_cal_q3  | 0.0372   |
| loss_diff    | 0.1      |
| loss_diff_q3 | 0.1      |
| loss_q3      | 0.1      |
| param_norm   | 228      |
| samples      | 793      |
| step         | 792      |
---------------------------
---------------------------
| grad_norm    | 1.54     |
| loss         | 0.155    |
| loss_cal     | 0.0211   |
| loss_cal_q3  | 0.0211   |
| loss_diff    | 0.155    |
| loss_diff_q3 | 0.155    |
| loss_q3      | 0.155    |
| param_norm   | 228      |
| samples      | 794      |
| step         | 793      |
---------------------------
---------------------------
| grad_norm    | 3.16     |
| loss         | 0.0296   |
| loss_cal     | 0.0151   |
| loss_cal_q2  | 0.0151   |
| loss_diff    | 0.0296   |
| loss_diff_q2 | 0.0296   |
| loss_q2      | 0.0296   |
| param_norm   | 228      |
| samples      | 795      |
| step         | 794      |
---------------------------
---------------------------
| grad_norm    | 1.62     |
| loss         | 0.0878   |
| loss_cal     | 0.0164   |
| loss_cal_q2  | 0.0164   |
| loss_diff    | 0.0878   |
| loss_diff_q2 | 0.0878   |
| loss_q2      | 0.0878   |
| param_norm   | 228      |
| samples      | 796      |
| step         | 795      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.51     |
| loss         | 0.102    |
| loss_cal     | 0.0152   |
| loss_cal_q2  | 0.0152   |
| loss_diff    | 0.102    |
| loss_diff_q2 | 0.102    |
| loss_q2      | 0.102    |
| param_norm   | 228      |
| samples      | 797      |
| step         | 796      |
---------------------------
---------------------------
| grad_norm    | 6.22     |
| loss         | 0.432    |
| loss_cal     | 0.0474   |
| loss_cal_q0  | 0.0474   |
| loss_diff    | 0.432    |
| loss_diff_q0 | 0.432    |
| loss_q0      | 0.432    |
| param_norm   | 228      |
| samples      | 798      |
| step         | 797      |
---------------------------
---------------------------
| grad_norm    | 1.36     |
| loss         | 0.0976   |
| loss_cal     | 0.0164   |
| loss_cal_q3  | 0.0164   |
| loss_diff    | 0.0976   |
| loss_diff_q3 | 0.0976   |
| loss_q3      | 0.0976   |
| param_norm   | 228      |
| samples      | 799      |
| step         | 798      |
---------------------------
---------------------------
| grad_norm    | 1.55     |
| loss         | 0.0544   |
| loss_cal     | 0.0334   |
| loss_cal_q1  | 0.0334   |
| loss_diff    | 0.0544   |
| loss_diff_q1 | 0.0544   |
| loss_q1      | 0.0544   |
| param_norm   | 228      |
| samples      | 800      |
| step         | 799      |
---------------------------
---------------------------
| grad_norm    | 5.73     |
| loss         | 0.582    |
| loss_cal     | 0.032    |
| loss_cal_q0  | 0.032    |
| loss_diff    | 0.582    |
| loss_diff_q0 | 0.582    |
| loss_q0      | 0.582    |
| param_norm   | 228      |
| samples      | 801      |
| step         | 800      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.45     |
| loss         | 0.0615   |
| loss_cal     | 0.0171   |
| loss_cal_q1  | 0.0171   |
| loss_diff    | 0.0615   |
| loss_diff_q1 | 0.0615   |
| loss_q1      | 0.0615   |
| param_norm   | 228      |
| samples      | 802      |
| step         | 801      |
---------------------------
---------------------------
| grad_norm    | 1.47     |
| loss         | 0.0829   |
| loss_cal     | 0.0158   |
| loss_cal_q3  | 0.0158   |
| loss_diff    | 0.0829   |
| loss_diff_q3 | 0.0829   |
| loss_q3      | 0.0829   |
| param_norm   | 228      |
| samples      | 803      |
| step         | 802      |
---------------------------
---------------------------
| grad_norm    | 4.58     |
| loss         | 0.195    |
| loss_cal     | 0.017    |
| loss_cal_q1  | 0.017    |
| loss_diff    | 0.195    |
| loss_diff_q1 | 0.195    |
| loss_q1      | 0.195    |
| param_norm   | 228      |
| samples      | 804      |
| step         | 803      |
---------------------------
---------------------------
| grad_norm    | 3.85     |
| loss         | 0.0268   |
| loss_cal     | 0.0151   |
| loss_cal_q3  | 0.0151   |
| loss_diff    | 0.0268   |
| loss_diff_q3 | 0.0268   |
| loss_q3      | 0.0268   |
| param_norm   | 228      |
| samples      | 805      |
| step         | 804      |
---------------------------
---------------------------
| grad_norm    | 2.39     |
| loss         | 0.151    |
| loss_cal     | 0.0254   |
| loss_cal_q0  | 0.0254   |
| loss_diff    | 0.151    |
| loss_diff_q0 | 0.151    |
| loss_q0      | 0.151    |
| param_norm   | 228      |
| samples      | 806      |
| step         | 805      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.68     |
| loss         | 0.107    |
| loss_cal     | 0.0331   |
| loss_cal_q3  | 0.0331   |
| loss_diff    | 0.107    |
| loss_diff_q3 | 0.107    |
| loss_q3      | 0.107    |
| param_norm   | 228      |
| samples      | 807      |
| step         | 806      |
---------------------------
---------------------------
| grad_norm    | 1.07     |
| loss         | 0.0483   |
| loss_cal     | 0.0157   |
| loss_cal_q2  | 0.0157   |
| loss_diff    | 0.0483   |
| loss_diff_q2 | 0.0483   |
| loss_q2      | 0.0483   |
| param_norm   | 228      |
| samples      | 808      |
| step         | 807      |
---------------------------
---------------------------
| grad_norm    | 2.41     |
| loss         | 0.137    |
| loss_cal     | 0.0169   |
| loss_cal_q2  | 0.0169   |
| loss_diff    | 0.137    |
| loss_diff_q2 | 0.137    |
| loss_q2      | 0.137    |
| param_norm   | 228      |
| samples      | 809      |
| step         | 808      |
---------------------------
---------------------------
| grad_norm    | 3.46     |
| loss         | 0.189    |
| loss_cal     | 0.0152   |
| loss_cal_q0  | 0.0152   |
| loss_diff    | 0.189    |
| loss_diff_q0 | 0.189    |
| loss_q0      | 0.189    |
| param_norm   | 228      |
| samples      | 810      |
| step         | 809      |
---------------------------
---------------------------
| grad_norm    | 2.99     |
| loss         | 0.222    |
| loss_cal     | 0.0323   |
| loss_cal_q1  | 0.0323   |
| loss_diff    | 0.222    |
| loss_diff_q1 | 0.222    |
| loss_q1      | 0.222    |
| param_norm   | 228      |
| samples      | 811      |
| step         | 810      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.91     |
| loss         | 0.209    |
| loss_cal     | 0.033    |
| loss_cal_q1  | 0.033    |
| loss_diff    | 0.209    |
| loss_diff_q1 | 0.209    |
| loss_q1      | 0.209    |
| param_norm   | 228      |
| samples      | 812      |
| step         | 811      |
---------------------------
---------------------------
| grad_norm    | 3.4      |
| loss         | 0.3      |
| loss_cal     | 0.0309   |
| loss_cal_q0  | 0.0309   |
| loss_diff    | 0.3      |
| loss_diff_q0 | 0.3      |
| loss_q0      | 0.3      |
| param_norm   | 228      |
| samples      | 813      |
| step         | 812      |
---------------------------
---------------------------
| grad_norm    | 7.01     |
| loss         | 0.496    |
| loss_cal     | 0.0251   |
| loss_cal_q0  | 0.0251   |
| loss_diff    | 0.496    |
| loss_diff_q0 | 0.496    |
| loss_q0      | 0.496    |
| param_norm   | 228      |
| samples      | 814      |
| step         | 813      |
---------------------------
---------------------------
| grad_norm    | 3.24     |
| loss         | 0.0332   |
| loss_cal     | 0.0146   |
| loss_cal_q3  | 0.0146   |
| loss_diff    | 0.0332   |
| loss_diff_q3 | 0.0332   |
| loss_q3      | 0.0332   |
| param_norm   | 228      |
| samples      | 815      |
| step         | 814      |
---------------------------
---------------------------
| grad_norm    | 3.18     |
| loss         | 0.213    |
| loss_cal     | 0.0152   |
| loss_cal_q0  | 0.0152   |
| loss_diff    | 0.213    |
| loss_diff_q0 | 0.213    |
| loss_q0      | 0.213    |
| param_norm   | 228      |
| samples      | 816      |
| step         | 815      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.41     |
| loss         | 0.198    |
| loss_cal     | 0.0455   |
| loss_cal_q0  | 0.0455   |
| loss_diff    | 0.198    |
| loss_diff_q0 | 0.198    |
| loss_q0      | 0.198    |
| param_norm   | 228      |
| samples      | 817      |
| step         | 816      |
---------------------------
---------------------------
| grad_norm    | 1.11     |
| loss         | 0.039    |
| loss_cal     | 0.0152   |
| loss_cal_q0  | 0.0152   |
| loss_diff    | 0.039    |
| loss_diff_q0 | 0.039    |
| loss_q0      | 0.039    |
| param_norm   | 228      |
| samples      | 818      |
| step         | 817      |
---------------------------
---------------------------
| grad_norm    | 1.79     |
| loss         | 0.114    |
| loss_cal     | 0.0155   |
| loss_cal_q0  | 0.0155   |
| loss_diff    | 0.114    |
| loss_diff_q0 | 0.114    |
| loss_q0      | 0.114    |
| param_norm   | 228      |
| samples      | 819      |
| step         | 818      |
---------------------------
---------------------------
| grad_norm    | 1.1      |
| loss         | 0.0621   |
| loss_cal     | 0.0163   |
| loss_cal_q2  | 0.0163   |
| loss_diff    | 0.0621   |
| loss_diff_q2 | 0.0621   |
| loss_q2      | 0.0621   |
| param_norm   | 228      |
| samples      | 820      |
| step         | 819      |
---------------------------
---------------------------
| grad_norm    | 0.944    |
| loss         | 0.0504   |
| loss_cal     | 0.0145   |
| loss_cal_q1  | 0.0145   |
| loss_diff    | 0.0504   |
| loss_diff_q1 | 0.0504   |
| loss_q1      | 0.0504   |
| param_norm   | 228      |
| samples      | 821      |
| step         | 820      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 6.38     |
| loss         | 0.78     |
| loss_cal     | 0.0437   |
| loss_cal_q0  | 0.0437   |
| loss_diff    | 0.78     |
| loss_diff_q0 | 0.78     |
| loss_q0      | 0.78     |
| param_norm   | 228      |
| samples      | 822      |
| step         | 821      |
---------------------------
---------------------------
| grad_norm    | 2.87     |
| loss         | 0.21     |
| loss_cal     | 0.051    |
| loss_cal_q1  | 0.051    |
| loss_diff    | 0.21     |
| loss_diff_q1 | 0.21     |
| loss_q1      | 0.21     |
| param_norm   | 228      |
| samples      | 823      |
| step         | 822      |
---------------------------
---------------------------
| grad_norm    | 3.55     |
| loss         | 0.381    |
| loss_cal     | 0.016    |
| loss_cal_q0  | 0.016    |
| loss_diff    | 0.381    |
| loss_diff_q0 | 0.381    |
| loss_q0      | 0.381    |
| param_norm   | 228      |
| samples      | 824      |
| step         | 823      |
---------------------------
---------------------------
| grad_norm    | 3.61     |
| loss         | 0.35     |
| loss_cal     | 0.0349   |
| loss_cal_q0  | 0.0349   |
| loss_diff    | 0.35     |
| loss_diff_q0 | 0.35     |
| loss_q0      | 0.35     |
| param_norm   | 228      |
| samples      | 825      |
| step         | 824      |
---------------------------
---------------------------
| grad_norm    | 1.98     |
| loss         | 0.0985   |
| loss_cal     | 0.0177   |
| loss_cal_q1  | 0.0177   |
| loss_diff    | 0.0985   |
| loss_diff_q1 | 0.0985   |
| loss_q1      | 0.0985   |
| param_norm   | 228      |
| samples      | 826      |
| step         | 825      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.21     |
| loss         | 0.116    |
| loss_cal     | 0.0315   |
| loss_cal_q1  | 0.0315   |
| loss_diff    | 0.116    |
| loss_diff_q1 | 0.116    |
| loss_q1      | 0.116    |
| param_norm   | 228      |
| samples      | 827      |
| step         | 826      |
---------------------------
---------------------------
| grad_norm    | 3.76     |
| loss         | 0.032    |
| loss_cal     | 0.0143   |
| loss_cal_q2  | 0.0143   |
| loss_diff    | 0.032    |
| loss_diff_q2 | 0.032    |
| loss_q2      | 0.032    |
| param_norm   | 228      |
| samples      | 828      |
| step         | 827      |
---------------------------
---------------------------
| grad_norm    | 3.14     |
| loss         | 0.159    |
| loss_cal     | 0.0698   |
| loss_cal_q0  | 0.0698   |
| loss_diff    | 0.159    |
| loss_diff_q0 | 0.159    |
| loss_q0      | 0.159    |
| param_norm   | 228      |
| samples      | 829      |
| step         | 828      |
---------------------------
---------------------------
| grad_norm    | 0.94     |
| loss         | 0.0706   |
| loss_cal     | 0.0149   |
| loss_cal_q2  | 0.0149   |
| loss_diff    | 0.0706   |
| loss_diff_q2 | 0.0706   |
| loss_q2      | 0.0706   |
| param_norm   | 228      |
| samples      | 830      |
| step         | 829      |
---------------------------
---------------------------
| grad_norm    | 5.18     |
| loss         | 0.308    |
| loss_cal     | 0.0183   |
| loss_cal_q0  | 0.0183   |
| loss_diff    | 0.308    |
| loss_diff_q0 | 0.308    |
| loss_q0      | 0.308    |
| param_norm   | 228      |
| samples      | 831      |
| step         | 830      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.86     |
| loss         | 0.234    |
| loss_cal     | 0.0235   |
| loss_cal_q1  | 0.0235   |
| loss_diff    | 0.234    |
| loss_diff_q1 | 0.234    |
| loss_q1      | 0.234    |
| param_norm   | 228      |
| samples      | 832      |
| step         | 831      |
---------------------------
---------------------------
| grad_norm    | 2.3      |
| loss         | 0.161    |
| loss_cal     | 0.0459   |
| loss_cal_q3  | 0.0459   |
| loss_diff    | 0.161    |
| loss_diff_q3 | 0.161    |
| loss_q3      | 0.161    |
| param_norm   | 228      |
| samples      | 833      |
| step         | 832      |
---------------------------
---------------------------
| grad_norm    | 2.37     |
| loss         | 0.0924   |
| loss_cal     | 0.0483   |
| loss_cal_q2  | 0.0483   |
| loss_diff    | 0.0924   |
| loss_diff_q2 | 0.0924   |
| loss_q2      | 0.0924   |
| param_norm   | 228      |
| samples      | 834      |
| step         | 833      |
---------------------------
---------------------------
| grad_norm    | 2.12     |
| loss         | 0.0952   |
| loss_cal     | 0.0286   |
| loss_cal_q3  | 0.0286   |
| loss_diff    | 0.0952   |
| loss_diff_q3 | 0.0952   |
| loss_q3      | 0.0952   |
| param_norm   | 228      |
| samples      | 835      |
| step         | 834      |
---------------------------
---------------------------
| grad_norm    | 2.98     |
| loss         | 0.0986   |
| loss_cal     | 0.0785   |
| loss_cal_q2  | 0.0785   |
| loss_diff    | 0.0986   |
| loss_diff_q2 | 0.0986   |
| loss_q2      | 0.0986   |
| param_norm   | 228      |
| samples      | 836      |
| step         | 835      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.11     |
| loss         | 0.153    |
| loss_cal     | 0.0159   |
| loss_cal_q3  | 0.0159   |
| loss_diff    | 0.153    |
| loss_diff_q3 | 0.153    |
| loss_q3      | 0.153    |
| param_norm   | 228      |
| samples      | 837      |
| step         | 836      |
---------------------------
---------------------------
| grad_norm    | 2.34     |
| loss         | 0.119    |
| loss_cal     | 0.0178   |
| loss_cal_q2  | 0.0178   |
| loss_diff    | 0.119    |
| loss_diff_q2 | 0.119    |
| loss_q2      | 0.119    |
| param_norm   | 228      |
| samples      | 838      |
| step         | 837      |
---------------------------
---------------------------
| grad_norm    | 0.889    |
| loss         | 0.0376   |
| loss_cal     | 0.0145   |
| loss_cal_q3  | 0.0145   |
| loss_diff    | 0.0376   |
| loss_diff_q3 | 0.0376   |
| loss_q3      | 0.0376   |
| param_norm   | 228      |
| samples      | 839      |
| step         | 838      |
---------------------------
---------------------------
| grad_norm    | 1.37     |
| loss         | 0.0648   |
| loss_cal     | 0.0154   |
| loss_cal_q2  | 0.0154   |
| loss_diff    | 0.0648   |
| loss_diff_q2 | 0.0648   |
| loss_q2      | 0.0648   |
| param_norm   | 228      |
| samples      | 840      |
| step         | 839      |
---------------------------
---------------------------
| grad_norm    | 2.37     |
| loss         | 0.0793   |
| loss_cal     | 0.015    |
| loss_cal_q1  | 0.015    |
| loss_diff    | 0.0793   |
| loss_diff_q1 | 0.0793   |
| loss_q1      | 0.0793   |
| param_norm   | 228      |
| samples      | 841      |
| step         | 840      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.76     |
| loss         | 0.242    |
| loss_cal     | 0.0169   |
| loss_cal_q0  | 0.0169   |
| loss_diff    | 0.242    |
| loss_diff_q0 | 0.242    |
| loss_q0      | 0.242    |
| param_norm   | 228      |
| samples      | 842      |
| step         | 841      |
---------------------------
---------------------------
| grad_norm    | 1.04     |
| loss         | 0.0452   |
| loss_cal     | 0.0142   |
| loss_cal_q2  | 0.0142   |
| loss_diff    | 0.0452   |
| loss_diff_q2 | 0.0452   |
| loss_q2      | 0.0452   |
| param_norm   | 228      |
| samples      | 843      |
| step         | 842      |
---------------------------
---------------------------
| grad_norm    | 1.55     |
| loss         | 0.0654   |
| loss_cal     | 0.0173   |
| loss_cal_q2  | 0.0173   |
| loss_diff    | 0.0654   |
| loss_diff_q2 | 0.0654   |
| loss_q2      | 0.0654   |
| param_norm   | 228      |
| samples      | 844      |
| step         | 843      |
---------------------------
---------------------------
| grad_norm    | 1.32     |
| loss         | 0.0269   |
| loss_cal     | 0.0139   |
| loss_cal_q2  | 0.0139   |
| loss_diff    | 0.0269   |
| loss_diff_q2 | 0.0269   |
| loss_q2      | 0.0269   |
| param_norm   | 228      |
| samples      | 845      |
| step         | 844      |
---------------------------
---------------------------
| grad_norm    | 2.24     |
| loss         | 0.0913   |
| loss_cal     | 0.0368   |
| loss_cal_q3  | 0.0368   |
| loss_diff    | 0.0913   |
| loss_diff_q3 | 0.0913   |
| loss_q3      | 0.0913   |
| param_norm   | 228      |
| samples      | 846      |
| step         | 845      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.4      |
| loss         | 0.102    |
| loss_cal     | 0.0203   |
| loss_cal_q3  | 0.0203   |
| loss_diff    | 0.102    |
| loss_diff_q3 | 0.102    |
| loss_q3      | 0.102    |
| param_norm   | 228      |
| samples      | 847      |
| step         | 846      |
---------------------------
---------------------------
| grad_norm    | 3.02     |
| loss         | 0.0322   |
| loss_cal     | 0.0141   |
| loss_cal_q3  | 0.0141   |
| loss_diff    | 0.0322   |
| loss_diff_q3 | 0.0322   |
| loss_q3      | 0.0322   |
| param_norm   | 228      |
| samples      | 848      |
| step         | 847      |
---------------------------
---------------------------
| grad_norm    | 3.02     |
| loss         | 0.0982   |
| loss_cal     | 0.0503   |
| loss_cal_q0  | 0.0503   |
| loss_diff    | 0.0982   |
| loss_diff_q0 | 0.0982   |
| loss_q0      | 0.0982   |
| param_norm   | 228      |
| samples      | 849      |
| step         | 848      |
---------------------------
---------------------------
| grad_norm    | 1.26     |
| loss         | 0.0536   |
| loss_cal     | 0.0151   |
| loss_cal_q2  | 0.0151   |
| loss_diff    | 0.0536   |
| loss_diff_q2 | 0.0536   |
| loss_q2      | 0.0536   |
| param_norm   | 228      |
| samples      | 850      |
| step         | 849      |
---------------------------
---------------------------
| grad_norm    | 1.09     |
| loss         | 0.0627   |
| loss_cal     | 0.0147   |
| loss_cal_q1  | 0.0147   |
| loss_diff    | 0.0627   |
| loss_diff_q1 | 0.0627   |
| loss_q1      | 0.0627   |
| param_norm   | 228      |
| samples      | 851      |
| step         | 850      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.56     |
| loss         | 0.133    |
| loss_cal     | 0.0358   |
| loss_cal_q3  | 0.0358   |
| loss_diff    | 0.133    |
| loss_diff_q3 | 0.133    |
| loss_q3      | 0.133    |
| param_norm   | 228      |
| samples      | 852      |
| step         | 851      |
---------------------------
---------------------------
| grad_norm    | 1        |
| loss         | 0.0377   |
| loss_cal     | 0.0144   |
| loss_cal_q2  | 0.0144   |
| loss_diff    | 0.0377   |
| loss_diff_q2 | 0.0377   |
| loss_q2      | 0.0377   |
| param_norm   | 228      |
| samples      | 853      |
| step         | 852      |
---------------------------
---------------------------
| grad_norm    | 4.81     |
| loss         | 0.928    |
| loss_cal     | 0.0158   |
| loss_cal_q0  | 0.0158   |
| loss_diff    | 0.928    |
| loss_diff_q0 | 0.928    |
| loss_q0      | 0.928    |
| param_norm   | 228      |
| samples      | 854      |
| step         | 853      |
---------------------------
---------------------------
| grad_norm    | 0.963    |
| loss         | 0.0455   |
| loss_cal     | 0.0146   |
| loss_cal_q3  | 0.0146   |
| loss_diff    | 0.0455   |
| loss_diff_q3 | 0.0455   |
| loss_q3      | 0.0455   |
| param_norm   | 228      |
| samples      | 855      |
| step         | 854      |
---------------------------
---------------------------
| grad_norm    | 3.56     |
| loss         | 0.112    |
| loss_cal     | 0.0617   |
| loss_cal_q3  | 0.0617   |
| loss_diff    | 0.112    |
| loss_diff_q3 | 0.112    |
| loss_q3      | 0.112    |
| param_norm   | 228      |
| samples      | 856      |
| step         | 855      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.16     |
| loss         | 0.0498   |
| loss_cal     | 0.0143   |
| loss_cal_q1  | 0.0143   |
| loss_diff    | 0.0498   |
| loss_diff_q1 | 0.0498   |
| loss_q1      | 0.0498   |
| param_norm   | 228      |
| samples      | 857      |
| step         | 856      |
---------------------------
---------------------------
| grad_norm    | 1.08     |
| loss         | 0.0514   |
| loss_cal     | 0.0185   |
| loss_cal_q3  | 0.0185   |
| loss_diff    | 0.0514   |
| loss_diff_q3 | 0.0514   |
| loss_q3      | 0.0514   |
| param_norm   | 228      |
| samples      | 858      |
| step         | 857      |
---------------------------
---------------------------
| grad_norm    | 2.74     |
| loss         | 0.175    |
| loss_cal     | 0.0404   |
| loss_cal_q3  | 0.0404   |
| loss_diff    | 0.175    |
| loss_diff_q3 | 0.175    |
| loss_q3      | 0.175    |
| param_norm   | 228      |
| samples      | 859      |
| step         | 858      |
---------------------------
---------------------------
| grad_norm    | 1.76     |
| loss         | 0.0938   |
| loss_cal     | 0.0144   |
| loss_cal_q0  | 0.0144   |
| loss_diff    | 0.0938   |
| loss_diff_q0 | 0.0938   |
| loss_q0      | 0.0938   |
| param_norm   | 228      |
| samples      | 860      |
| step         | 859      |
---------------------------
---------------------------
| grad_norm    | 1.52     |
| loss         | 0.0447   |
| loss_cal     | 0.0136   |
| loss_cal_q0  | 0.0136   |
| loss_diff    | 0.0447   |
| loss_diff_q0 | 0.0447   |
| loss_q0      | 0.0447   |
| param_norm   | 228      |
| samples      | 861      |
| step         | 860      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.9      |
| loss         | 0.0263   |
| loss_cal     | 0.0137   |
| loss_cal_q2  | 0.0137   |
| loss_diff    | 0.0263   |
| loss_diff_q2 | 0.0263   |
| loss_q2      | 0.0263   |
| param_norm   | 228      |
| samples      | 862      |
| step         | 861      |
---------------------------
---------------------------
| grad_norm    | 3.25     |
| loss         | 0.177    |
| loss_cal     | 0.0667   |
| loss_cal_q1  | 0.0667   |
| loss_diff    | 0.177    |
| loss_diff_q1 | 0.177    |
| loss_q1      | 0.177    |
| param_norm   | 228      |
| samples      | 863      |
| step         | 862      |
---------------------------
---------------------------
| grad_norm    | 0.959    |
| loss         | 0.0302   |
| loss_cal     | 0.0139   |
| loss_cal_q2  | 0.0139   |
| loss_diff    | 0.0302   |
| loss_diff_q2 | 0.0302   |
| loss_q2      | 0.0302   |
| param_norm   | 228      |
| samples      | 864      |
| step         | 863      |
---------------------------
---------------------------
| grad_norm    | 1.37     |
| loss         | 0.112    |
| loss_cal     | 0.015    |
| loss_cal_q1  | 0.015    |
| loss_diff    | 0.112    |
| loss_diff_q1 | 0.112    |
| loss_q1      | 0.112    |
| param_norm   | 228      |
| samples      | 865      |
| step         | 864      |
---------------------------
---------------------------
| grad_norm    | 0.818    |
| loss         | 0.0474   |
| loss_cal     | 0.014    |
| loss_cal_q1  | 0.014    |
| loss_diff    | 0.0474   |
| loss_diff_q1 | 0.0474   |
| loss_q1      | 0.0474   |
| param_norm   | 228      |
| samples      | 866      |
| step         | 865      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.28     |
| loss         | 0.0796   |
| loss_cal     | 0.0143   |
| loss_cal_q0  | 0.0143   |
| loss_diff    | 0.0796   |
| loss_diff_q0 | 0.0796   |
| loss_q0      | 0.0796   |
| param_norm   | 228      |
| samples      | 867      |
| step         | 866      |
---------------------------
---------------------------
| grad_norm    | 4.63     |
| loss         | 0.262    |
| loss_cal     | 0.0323   |
| loss_cal_q0  | 0.0323   |
| loss_diff    | 0.262    |
| loss_diff_q0 | 0.262    |
| loss_q0      | 0.262    |
| param_norm   | 228      |
| samples      | 868      |
| step         | 867      |
---------------------------
---------------------------
| grad_norm    | 1.63     |
| loss         | 0.0755   |
| loss_cal     | 0.0256   |
| loss_cal_q3  | 0.0256   |
| loss_diff    | 0.0755   |
| loss_diff_q3 | 0.0755   |
| loss_q3      | 0.0755   |
| param_norm   | 228      |
| samples      | 869      |
| step         | 868      |
---------------------------
---------------------------
| grad_norm    | 0.907    |
| loss         | 0.036    |
| loss_cal     | 0.0145   |
| loss_cal_q3  | 0.0145   |
| loss_diff    | 0.036    |
| loss_diff_q3 | 0.036    |
| loss_q3      | 0.036    |
| param_norm   | 228      |
| samples      | 870      |
| step         | 869      |
---------------------------
---------------------------
| grad_norm    | 1.29     |
| loss         | 0.0478   |
| loss_cal     | 0.0161   |
| loss_cal_q1  | 0.0161   |
| loss_diff    | 0.0478   |
| loss_diff_q1 | 0.0478   |
| loss_q1      | 0.0478   |
| param_norm   | 228      |
| samples      | 871      |
| step         | 870      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 0.998    |
| loss         | 0.0661   |
| loss_cal     | 0.0146   |
| loss_cal_q2  | 0.0146   |
| loss_diff    | 0.0661   |
| loss_diff_q2 | 0.0661   |
| loss_q2      | 0.0661   |
| param_norm   | 228      |
| samples      | 872      |
| step         | 871      |
---------------------------
---------------------------
| grad_norm    | 9.05     |
| loss         | 0.21     |
| loss_cal     | 0.0141   |
| loss_cal_q0  | 0.0141   |
| loss_diff    | 0.21     |
| loss_diff_q0 | 0.21     |
| loss_q0      | 0.21     |
| param_norm   | 228      |
| samples      | 873      |
| step         | 872      |
---------------------------
---------------------------
| grad_norm    | 2.38     |
| loss         | 0.155    |
| loss_cal     | 0.0158   |
| loss_cal_q1  | 0.0158   |
| loss_diff    | 0.155    |
| loss_diff_q1 | 0.155    |
| loss_q1      | 0.155    |
| param_norm   | 228      |
| samples      | 874      |
| step         | 873      |
---------------------------
---------------------------
| grad_norm    | 1.74     |
| loss         | 0.11     |
| loss_cal     | 0.0142   |
| loss_cal_q1  | 0.0142   |
| loss_diff    | 0.11     |
| loss_diff_q1 | 0.11     |
| loss_q1      | 0.11     |
| param_norm   | 228      |
| samples      | 875      |
| step         | 874      |
---------------------------
---------------------------
| grad_norm    | 5.27     |
| loss         | 0.17     |
| loss_cal     | 0.015    |
| loss_cal_q0  | 0.015    |
| loss_diff    | 0.17     |
| loss_diff_q0 | 0.17     |
| loss_q0      | 0.17     |
| param_norm   | 228      |
| samples      | 876      |
| step         | 875      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.69     |
| loss         | 0.126    |
| loss_cal     | 0.0448   |
| loss_cal_q1  | 0.0448   |
| loss_diff    | 0.126    |
| loss_diff_q1 | 0.126    |
| loss_q1      | 0.126    |
| param_norm   | 228      |
| samples      | 877      |
| step         | 876      |
---------------------------
---------------------------
| grad_norm    | 1.65     |
| loss         | 0.121    |
| loss_cal     | 0.0215   |
| loss_cal_q1  | 0.0215   |
| loss_diff    | 0.121    |
| loss_diff_q1 | 0.121    |
| loss_q1      | 0.121    |
| param_norm   | 228      |
| samples      | 878      |
| step         | 877      |
---------------------------
---------------------------
| grad_norm    | 1.68     |
| loss         | 0.0807   |
| loss_cal     | 0.0186   |
| loss_cal_q3  | 0.0186   |
| loss_diff    | 0.0807   |
| loss_diff_q3 | 0.0807   |
| loss_q3      | 0.0807   |
| param_norm   | 228      |
| samples      | 879      |
| step         | 878      |
---------------------------
---------------------------
| grad_norm    | 1.54     |
| loss         | 0.108    |
| loss_cal     | 0.0156   |
| loss_cal_q1  | 0.0156   |
| loss_diff    | 0.108    |
| loss_diff_q1 | 0.108    |
| loss_q1      | 0.108    |
| param_norm   | 228      |
| samples      | 880      |
| step         | 879      |
---------------------------
---------------------------
| grad_norm    | 2.71     |
| loss         | 0.166    |
| loss_cal     | 0.033    |
| loss_cal_q2  | 0.033    |
| loss_diff    | 0.166    |
| loss_diff_q2 | 0.166    |
| loss_q2      | 0.166    |
| param_norm   | 228      |
| samples      | 881      |
| step         | 880      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 0.944    |
| loss         | 0.0456   |
| loss_cal     | 0.0135   |
| loss_cal_q2  | 0.0135   |
| loss_diff    | 0.0456   |
| loss_diff_q2 | 0.0456   |
| loss_q2      | 0.0456   |
| param_norm   | 228      |
| samples      | 882      |
| step         | 881      |
---------------------------
---------------------------
| grad_norm    | 2.07     |
| loss         | 0.0248   |
| loss_cal     | 0.0135   |
| loss_cal_q3  | 0.0135   |
| loss_diff    | 0.0248   |
| loss_diff_q3 | 0.0248   |
| loss_q3      | 0.0248   |
| param_norm   | 228      |
| samples      | 883      |
| step         | 882      |
---------------------------
---------------------------
| grad_norm    | 3.08     |
| loss         | 0.108    |
| loss_cal     | 0.0534   |
| loss_cal_q2  | 0.0534   |
| loss_diff    | 0.108    |
| loss_diff_q2 | 0.108    |
| loss_q2      | 0.108    |
| param_norm   | 228      |
| samples      | 884      |
| step         | 883      |
---------------------------
---------------------------
| grad_norm    | 3.01     |
| loss         | 0.125    |
| loss_cal     | 0.0147   |
| loss_cal_q2  | 0.0147   |
| loss_diff    | 0.125    |
| loss_diff_q2 | 0.125    |
| loss_q2      | 0.125    |
| param_norm   | 228      |
| samples      | 885      |
| step         | 884      |
---------------------------
---------------------------
| grad_norm    | 1.73     |
| loss         | 0.0863   |
| loss_cal     | 0.0138   |
| loss_cal_q3  | 0.0138   |
| loss_diff    | 0.0863   |
| loss_diff_q3 | 0.0863   |
| loss_q3      | 0.0863   |
| param_norm   | 228      |
| samples      | 886      |
| step         | 885      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.49     |
| loss         | 0.0855   |
| loss_cal     | 0.0145   |
| loss_cal_q2  | 0.0145   |
| loss_diff    | 0.0855   |
| loss_diff_q2 | 0.0855   |
| loss_q2      | 0.0855   |
| param_norm   | 228      |
| samples      | 887      |
| step         | 886      |
---------------------------
---------------------------
| grad_norm    | 2.01     |
| loss         | 0.0787   |
| loss_cal     | 0.016    |
| loss_cal_q3  | 0.016    |
| loss_diff    | 0.0787   |
| loss_diff_q3 | 0.0787   |
| loss_q3      | 0.0787   |
| param_norm   | 228      |
| samples      | 888      |
| step         | 887      |
---------------------------
---------------------------
| grad_norm    | 2.01     |
| loss         | 0.0561   |
| loss_cal     | 0.0346   |
| loss_cal_q2  | 0.0346   |
| loss_diff    | 0.0561   |
| loss_diff_q2 | 0.0561   |
| loss_q2      | 0.0561   |
| param_norm   | 228      |
| samples      | 889      |
| step         | 888      |
---------------------------
---------------------------
| grad_norm    | 3.8      |
| loss         | 0.118    |
| loss_cal     | 0.0308   |
| loss_cal_q3  | 0.0308   |
| loss_diff    | 0.118    |
| loss_diff_q3 | 0.118    |
| loss_q3      | 0.118    |
| param_norm   | 228      |
| samples      | 890      |
| step         | 889      |
---------------------------
---------------------------
| grad_norm    | 5.97     |
| loss         | 0.0234   |
| loss_cal     | 0.0133   |
| loss_cal_q1  | 0.0133   |
| loss_diff    | 0.0234   |
| loss_diff_q1 | 0.0234   |
| loss_q1      | 0.0234   |
| param_norm   | 228      |
| samples      | 891      |
| step         | 890      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.99     |
| loss         | 0.0699   |
| loss_cal     | 0.0547   |
| loss_cal_q2  | 0.0547   |
| loss_diff    | 0.0699   |
| loss_diff_q2 | 0.0699   |
| loss_q2      | 0.0699   |
| param_norm   | 228      |
| samples      | 892      |
| step         | 891      |
---------------------------
---------------------------
| grad_norm    | 6.45     |
| loss         | 0.193    |
| loss_cal     | 0.0626   |
| loss_cal_q0  | 0.0626   |
| loss_diff    | 0.193    |
| loss_diff_q0 | 0.193    |
| loss_q0      | 0.193    |
| param_norm   | 228      |
| samples      | 893      |
| step         | 892      |
---------------------------
---------------------------
| grad_norm    | 6.56     |
| loss         | 0.3      |
| loss_cal     | 0.0162   |
| loss_cal_q0  | 0.0162   |
| loss_diff    | 0.3      |
| loss_diff_q0 | 0.3      |
| loss_q0      | 0.3      |
| param_norm   | 228      |
| samples      | 894      |
| step         | 893      |
---------------------------
---------------------------
| grad_norm    | 1.28     |
| loss         | 0.0251   |
| loss_cal     | 0.0129   |
| loss_cal_q3  | 0.0129   |
| loss_diff    | 0.0251   |
| loss_diff_q3 | 0.0251   |
| loss_q3      | 0.0251   |
| param_norm   | 228      |
| samples      | 895      |
| step         | 894      |
---------------------------
---------------------------
| grad_norm    | 1.03     |
| loss         | 0.0474   |
| loss_cal     | 0.0136   |
| loss_cal_q3  | 0.0136   |
| loss_diff    | 0.0474   |
| loss_diff_q3 | 0.0474   |
| loss_q3      | 0.0474   |
| param_norm   | 228      |
| samples      | 896      |
| step         | 895      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 12       |
| loss         | 0.655    |
| loss_cal     | 0.0142   |
| loss_cal_q0  | 0.0142   |
| loss_diff    | 0.655    |
| loss_diff_q0 | 0.655    |
| loss_q0      | 0.655    |
| param_norm   | 228      |
| samples      | 897      |
| step         | 896      |
---------------------------
---------------------------
| grad_norm    | 6.21     |
| loss         | 0.759    |
| loss_cal     | 0.0342   |
| loss_cal_q0  | 0.0342   |
| loss_diff    | 0.759    |
| loss_diff_q0 | 0.759    |
| loss_q0      | 0.759    |
| param_norm   | 228      |
| samples      | 898      |
| step         | 897      |
---------------------------
---------------------------
| grad_norm    | 3.69     |
| loss         | 0.22     |
| loss_cal     | 0.0685   |
| loss_cal_q1  | 0.0685   |
| loss_diff    | 0.22     |
| loss_diff_q1 | 0.22     |
| loss_q1      | 0.22     |
| param_norm   | 228      |
| samples      | 899      |
| step         | 898      |
---------------------------
---------------------------
| grad_norm    | 2.53     |
| loss         | 0.027    |
| loss_cal     | 0.013    |
| loss_cal_q2  | 0.013    |
| loss_diff    | 0.027    |
| loss_diff_q2 | 0.027    |
| loss_q2      | 0.027    |
| param_norm   | 228      |
| samples      | 900      |
| step         | 899      |
---------------------------
---------------------------
| grad_norm    | 1.29     |
| loss         | 0.0782   |
| loss_cal     | 0.0142   |
| loss_cal_q2  | 0.0142   |
| loss_diff    | 0.0782   |
| loss_diff_q2 | 0.0782   |
| loss_q2      | 0.0782   |
| param_norm   | 228      |
| samples      | 901      |
| step         | 900      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.76     |
| loss         | 0.0993   |
| loss_cal     | 0.0136   |
| loss_cal_q2  | 0.0136   |
| loss_diff    | 0.0993   |
| loss_diff_q2 | 0.0993   |
| loss_q2      | 0.0993   |
| param_norm   | 228      |
| samples      | 902      |
| step         | 901      |
---------------------------
---------------------------
| grad_norm    | 0.829    |
| loss         | 0.0298   |
| loss_cal     | 0.0134   |
| loss_cal_q0  | 0.0134   |
| loss_diff    | 0.0298   |
| loss_diff_q0 | 0.0298   |
| loss_q0      | 0.0298   |
| param_norm   | 228      |
| samples      | 903      |
| step         | 902      |
---------------------------
---------------------------
| grad_norm    | 1.76     |
| loss         | 0.118    |
| loss_cal     | 0.0142   |
| loss_cal_q3  | 0.0142   |
| loss_diff    | 0.118    |
| loss_diff_q3 | 0.118    |
| loss_q3      | 0.118    |
| param_norm   | 228      |
| samples      | 904      |
| step         | 903      |
---------------------------
---------------------------
| grad_norm    | 1.36     |
| loss         | 0.0237   |
| loss_cal     | 0.0127   |
| loss_cal_q1  | 0.0127   |
| loss_diff    | 0.0237   |
| loss_diff_q1 | 0.0237   |
| loss_q1      | 0.0237   |
| param_norm   | 228      |
| samples      | 905      |
| step         | 904      |
---------------------------
---------------------------
| grad_norm    | 2.34     |
| loss         | 0.16     |
| loss_cal     | 0.0291   |
| loss_cal_q2  | 0.0291   |
| loss_diff    | 0.16     |
| loss_diff_q2 | 0.16     |
| loss_q2      | 0.16     |
| param_norm   | 228      |
| samples      | 906      |
| step         | 905      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 0.949    |
| loss         | 0.0576   |
| loss_cal     | 0.0136   |
| loss_cal_q1  | 0.0136   |
| loss_diff    | 0.0576   |
| loss_diff_q1 | 0.0576   |
| loss_q1      | 0.0576   |
| param_norm   | 228      |
| samples      | 907      |
| step         | 906      |
---------------------------
---------------------------
| grad_norm    | 1.52     |
| loss         | 0.112    |
| loss_cal     | 0.0152   |
| loss_cal_q3  | 0.0152   |
| loss_diff    | 0.112    |
| loss_diff_q3 | 0.112    |
| loss_q3      | 0.112    |
| param_norm   | 228      |
| samples      | 908      |
| step         | 907      |
---------------------------
---------------------------
| grad_norm    | 2.62     |
| loss         | 0.197    |
| loss_cal     | 0.0158   |
| loss_cal_q2  | 0.0158   |
| loss_diff    | 0.197    |
| loss_diff_q2 | 0.197    |
| loss_q2      | 0.197    |
| param_norm   | 228      |
| samples      | 909      |
| step         | 908      |
---------------------------
---------------------------
| grad_norm    | 2.36     |
| loss         | 0.155    |
| loss_cal     | 0.0715   |
| loss_cal_q3  | 0.0715   |
| loss_diff    | 0.155    |
| loss_diff_q3 | 0.155    |
| loss_q3      | 0.155    |
| param_norm   | 228      |
| samples      | 910      |
| step         | 909      |
---------------------------
---------------------------
| grad_norm    | 2.06     |
| loss         | 0.0229   |
| loss_cal     | 0.0128   |
| loss_cal_q1  | 0.0128   |
| loss_diff    | 0.0229   |
| loss_diff_q1 | 0.0229   |
| loss_q1      | 0.0229   |
| param_norm   | 228      |
| samples      | 911      |
| step         | 910      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 5.54     |
| loss         | 0.241    |
| loss_cal     | 0.0402   |
| loss_cal_q3  | 0.0402   |
| loss_diff    | 0.241    |
| loss_diff_q3 | 0.241    |
| loss_q3      | 0.241    |
| param_norm   | 228      |
| samples      | 912      |
| step         | 911      |
---------------------------
---------------------------
| grad_norm    | 3.13     |
| loss         | 0.168    |
| loss_cal     | 0.0386   |
| loss_cal_q2  | 0.0386   |
| loss_diff    | 0.168    |
| loss_diff_q2 | 0.168    |
| loss_q2      | 0.168    |
| param_norm   | 228      |
| samples      | 913      |
| step         | 912      |
---------------------------
---------------------------
| grad_norm    | 1.06     |
| loss         | 0.0622   |
| loss_cal     | 0.0143   |
| loss_cal_q3  | 0.0143   |
| loss_diff    | 0.0622   |
| loss_diff_q3 | 0.0622   |
| loss_q3      | 0.0622   |
| param_norm   | 228      |
| samples      | 914      |
| step         | 913      |
---------------------------
---------------------------
| grad_norm    | 2.61     |
| loss         | 0.202    |
| loss_cal     | 0.017    |
| loss_cal_q3  | 0.017    |
| loss_diff    | 0.202    |
| loss_diff_q3 | 0.202    |
| loss_q3      | 0.202    |
| param_norm   | 228      |
| samples      | 915      |
| step         | 914      |
---------------------------
---------------------------
| grad_norm    | 0.944    |
| loss         | 0.0369   |
| loss_cal     | 0.0134   |
| loss_cal_q0  | 0.0134   |
| loss_diff    | 0.0369   |
| loss_diff_q0 | 0.0369   |
| loss_q0      | 0.0369   |
| param_norm   | 228      |
| samples      | 916      |
| step         | 915      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.98     |
| loss         | 0.342    |
| loss_cal     | 0.0595   |
| loss_cal_q0  | 0.0595   |
| loss_diff    | 0.342    |
| loss_diff_q0 | 0.342    |
| loss_q0      | 0.342    |
| param_norm   | 228      |
| samples      | 917      |
| step         | 916      |
---------------------------
---------------------------
| grad_norm    | 1.32     |
| loss         | 0.0941   |
| loss_cal     | 0.014    |
| loss_cal_q3  | 0.014    |
| loss_diff    | 0.0941   |
| loss_diff_q3 | 0.0941   |
| loss_q3      | 0.0941   |
| param_norm   | 228      |
| samples      | 918      |
| step         | 917      |
---------------------------
---------------------------
| grad_norm    | 1.51     |
| loss         | 0.0228   |
| loss_cal     | 0.0126   |
| loss_cal_q2  | 0.0126   |
| loss_diff    | 0.0228   |
| loss_diff_q2 | 0.0228   |
| loss_q2      | 0.0228   |
| param_norm   | 228      |
| samples      | 919      |
| step         | 918      |
---------------------------
---------------------------
| grad_norm    | 2.12     |
| loss         | 0.147    |
| loss_cal     | 0.0328   |
| loss_cal_q1  | 0.0328   |
| loss_diff    | 0.147    |
| loss_diff_q1 | 0.147    |
| loss_q1      | 0.147    |
| param_norm   | 228      |
| samples      | 920      |
| step         | 919      |
---------------------------
---------------------------
| grad_norm    | 2.25     |
| loss         | 0.143    |
| loss_cal     | 0.0158   |
| loss_cal_q1  | 0.0158   |
| loss_diff    | 0.143    |
| loss_diff_q1 | 0.143    |
| loss_q1      | 0.143    |
| param_norm   | 228      |
| samples      | 921      |
| step         | 920      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.22     |
| loss         | 0.0791   |
| loss_cal     | 0.0142   |
| loss_cal_q2  | 0.0142   |
| loss_diff    | 0.0791   |
| loss_diff_q2 | 0.0791   |
| loss_q2      | 0.0791   |
| param_norm   | 228      |
| samples      | 922      |
| step         | 921      |
---------------------------
---------------------------
| grad_norm    | 2.84     |
| loss         | 0.165    |
| loss_cal     | 0.0418   |
| loss_cal_q2  | 0.0418   |
| loss_diff    | 0.165    |
| loss_diff_q2 | 0.165    |
| loss_q2      | 0.165    |
| param_norm   | 228      |
| samples      | 923      |
| step         | 922      |
---------------------------
---------------------------
| grad_norm    | 1.03     |
| loss         | 0.0546   |
| loss_cal     | 0.0152   |
| loss_cal_q3  | 0.0152   |
| loss_diff    | 0.0546   |
| loss_diff_q3 | 0.0546   |
| loss_q3      | 0.0546   |
| param_norm   | 228      |
| samples      | 924      |
| step         | 923      |
---------------------------
---------------------------
| grad_norm    | 1.07     |
| loss         | 0.0812   |
| loss_cal     | 0.0135   |
| loss_cal_q2  | 0.0135   |
| loss_diff    | 0.0812   |
| loss_diff_q2 | 0.0812   |
| loss_q2      | 0.0812   |
| param_norm   | 228      |
| samples      | 925      |
| step         | 924      |
---------------------------
---------------------------
| grad_norm    | 2.68     |
| loss         | 0.171    |
| loss_cal     | 0.0471   |
| loss_cal_q1  | 0.0471   |
| loss_diff    | 0.171    |
| loss_diff_q1 | 0.171    |
| loss_q1      | 0.171    |
| param_norm   | 228      |
| samples      | 926      |
| step         | 925      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 6.58     |
| loss         | 0.436    |
| loss_cal     | 0.0238   |
| loss_cal_q0  | 0.0238   |
| loss_diff    | 0.436    |
| loss_diff_q0 | 0.436    |
| loss_q0      | 0.436    |
| param_norm   | 228      |
| samples      | 927      |
| step         | 926      |
---------------------------
---------------------------
| grad_norm    | 0.657    |
| loss         | 0.0285   |
| loss_cal     | 0.0126   |
| loss_cal_q3  | 0.0126   |
| loss_diff    | 0.0285   |
| loss_diff_q3 | 0.0285   |
| loss_q3      | 0.0285   |
| param_norm   | 228      |
| samples      | 928      |
| step         | 927      |
---------------------------
---------------------------
| grad_norm    | 2.42     |
| loss         | 0.138    |
| loss_cal     | 0.0335   |
| loss_cal_q2  | 0.0335   |
| loss_diff    | 0.138    |
| loss_diff_q2 | 0.138    |
| loss_q2      | 0.138    |
| param_norm   | 228      |
| samples      | 929      |
| step         | 928      |
---------------------------
---------------------------
| grad_norm    | 0.986    |
| loss         | 0.0776   |
| loss_cal     | 0.0129   |
| loss_cal_q2  | 0.0129   |
| loss_diff    | 0.0776   |
| loss_diff_q2 | 0.0776   |
| loss_q2      | 0.0776   |
| param_norm   | 228      |
| samples      | 930      |
| step         | 929      |
---------------------------
---------------------------
| grad_norm    | 4.15     |
| loss         | 0.28     |
| loss_cal     | 0.0212   |
| loss_cal_q0  | 0.0212   |
| loss_diff    | 0.28     |
| loss_diff_q0 | 0.28     |
| loss_q0      | 0.28     |
| param_norm   | 228      |
| samples      | 931      |
| step         | 930      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.02     |
| loss         | 0.0469   |
| loss_cal     | 0.0142   |
| loss_cal_q2  | 0.0142   |
| loss_diff    | 0.0469   |
| loss_diff_q2 | 0.0469   |
| loss_q2      | 0.0469   |
| param_norm   | 228      |
| samples      | 932      |
| step         | 931      |
---------------------------
---------------------------
| grad_norm    | 1.2      |
| loss         | 0.0678   |
| loss_cal     | 0.0135   |
| loss_cal_q0  | 0.0135   |
| loss_diff    | 0.0678   |
| loss_diff_q0 | 0.0678   |
| loss_q0      | 0.0678   |
| param_norm   | 228      |
| samples      | 933      |
| step         | 932      |
---------------------------
---------------------------
| grad_norm    | 0.833    |
| loss         | 0.044    |
| loss_cal     | 0.0129   |
| loss_cal_q2  | 0.0129   |
| loss_diff    | 0.044    |
| loss_diff_q2 | 0.044    |
| loss_q2      | 0.044    |
| param_norm   | 228      |
| samples      | 934      |
| step         | 933      |
---------------------------
---------------------------
| grad_norm    | 2.88     |
| loss         | 0.0983   |
| loss_cal     | 0.0501   |
| loss_cal_q0  | 0.0501   |
| loss_diff    | 0.0983   |
| loss_diff_q0 | 0.0983   |
| loss_q0      | 0.0983   |
| param_norm   | 228      |
| samples      | 935      |
| step         | 934      |
---------------------------
---------------------------
| grad_norm    | 0.827    |
| loss         | 0.0308   |
| loss_cal     | 0.0131   |
| loss_cal_q2  | 0.0131   |
| loss_diff    | 0.0308   |
| loss_diff_q2 | 0.0308   |
| loss_q2      | 0.0308   |
| param_norm   | 228      |
| samples      | 936      |
| step         | 935      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.52     |
| loss         | 0.0654   |
| loss_cal     | 0.0144   |
| loss_cal_q1  | 0.0144   |
| loss_diff    | 0.0654   |
| loss_diff_q1 | 0.0654   |
| loss_q1      | 0.0654   |
| param_norm   | 228      |
| samples      | 937      |
| step         | 936      |
---------------------------
---------------------------
| grad_norm    | 3.28     |
| loss         | 0.182    |
| loss_cal     | 0.0255   |
| loss_cal_q0  | 0.0255   |
| loss_diff    | 0.182    |
| loss_diff_q0 | 0.182    |
| loss_q0      | 0.182    |
| param_norm   | 228      |
| samples      | 938      |
| step         | 937      |
---------------------------
---------------------------
| grad_norm    | 3.93     |
| loss         | 0.0209   |
| loss_cal     | 0.0125   |
| loss_cal_q2  | 0.0125   |
| loss_diff    | 0.0209   |
| loss_diff_q2 | 0.0209   |
| loss_q2      | 0.0209   |
| param_norm   | 228      |
| samples      | 939      |
| step         | 938      |
---------------------------
---------------------------
| grad_norm    | 1.54     |
| loss         | 0.0847   |
| loss_cal     | 0.0134   |
| loss_cal_q0  | 0.0134   |
| loss_diff    | 0.0847   |
| loss_diff_q0 | 0.0847   |
| loss_q0      | 0.0847   |
| param_norm   | 228      |
| samples      | 940      |
| step         | 939      |
---------------------------
---------------------------
| grad_norm    | 3.58     |
| loss         | 0.106    |
| loss_cal     | 0.0315   |
| loss_cal_q0  | 0.0315   |
| loss_diff    | 0.106    |
| loss_diff_q0 | 0.106    |
| loss_q0      | 0.106    |
| param_norm   | 228      |
| samples      | 941      |
| step         | 940      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.24     |
| loss         | 0.197    |
| loss_cal     | 0.0709   |
| loss_cal_q1  | 0.0709   |
| loss_diff    | 0.197    |
| loss_diff_q1 | 0.197    |
| loss_q1      | 0.197    |
| param_norm   | 228      |
| samples      | 942      |
| step         | 941      |
---------------------------
---------------------------
| grad_norm    | 5.67     |
| loss         | 0.295    |
| loss_cal     | 0.0135   |
| loss_cal_q0  | 0.0135   |
| loss_diff    | 0.295    |
| loss_diff_q0 | 0.295    |
| loss_q0      | 0.295    |
| param_norm   | 228      |
| samples      | 943      |
| step         | 942      |
---------------------------
---------------------------
| grad_norm    | 2.28     |
| loss         | 0.021    |
| loss_cal     | 0.0122   |
| loss_cal_q0  | 0.0122   |
| loss_diff    | 0.021    |
| loss_diff_q0 | 0.021    |
| loss_q0      | 0.021    |
| param_norm   | 228      |
| samples      | 944      |
| step         | 943      |
---------------------------
---------------------------
| grad_norm    | 2.22     |
| loss         | 0.066    |
| loss_cal     | 0.0301   |
| loss_cal_q2  | 0.0301   |
| loss_diff    | 0.066    |
| loss_diff_q2 | 0.066    |
| loss_q2      | 0.066    |
| param_norm   | 228      |
| samples      | 945      |
| step         | 944      |
---------------------------
---------------------------
| grad_norm    | 1.23     |
| loss         | 0.0561   |
| loss_cal     | 0.0132   |
| loss_cal_q3  | 0.0132   |
| loss_diff    | 0.0561   |
| loss_diff_q3 | 0.0561   |
| loss_q3      | 0.0561   |
| param_norm   | 228      |
| samples      | 946      |
| step         | 945      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.28     |
| loss         | 0.0644   |
| loss_cal     | 0.0132   |
| loss_cal_q2  | 0.0132   |
| loss_diff    | 0.0644   |
| loss_diff_q2 | 0.0644   |
| loss_q2      | 0.0644   |
| param_norm   | 228      |
| samples      | 947      |
| step         | 946      |
---------------------------
---------------------------
| grad_norm    | 1.49     |
| loss         | 0.0539   |
| loss_cal     | 0.0131   |
| loss_cal_q2  | 0.0131   |
| loss_diff    | 0.0539   |
| loss_diff_q2 | 0.0539   |
| loss_q2      | 0.0539   |
| param_norm   | 228      |
| samples      | 948      |
| step         | 947      |
---------------------------
---------------------------
| grad_norm    | 2.73     |
| loss         | 0.0901   |
| loss_cal     | 0.0607   |
| loss_cal_q1  | 0.0607   |
| loss_diff    | 0.0901   |
| loss_diff_q1 | 0.0901   |
| loss_q1      | 0.0901   |
| param_norm   | 228      |
| samples      | 949      |
| step         | 948      |
---------------------------
---------------------------
| grad_norm    | 1.19     |
| loss         | 0.0607   |
| loss_cal     | 0.0124   |
| loss_cal_q2  | 0.0124   |
| loss_diff    | 0.0607   |
| loss_diff_q2 | 0.0607   |
| loss_q2      | 0.0607   |
| param_norm   | 228      |
| samples      | 950      |
| step         | 949      |
---------------------------
---------------------------
| grad_norm    | 3.67     |
| loss         | 0.0523   |
| loss_cal     | 0.0121   |
| loss_cal_q0  | 0.0121   |
| loss_diff    | 0.0523   |
| loss_diff_q0 | 0.0523   |
| loss_q0      | 0.0523   |
| param_norm   | 228      |
| samples      | 951      |
| step         | 950      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.03     |
| loss         | 0.0803   |
| loss_cal     | 0.0135   |
| loss_cal_q0  | 0.0135   |
| loss_diff    | 0.0803   |
| loss_diff_q0 | 0.0803   |
| loss_q0      | 0.0803   |
| param_norm   | 228      |
| samples      | 952      |
| step         | 951      |
---------------------------
---------------------------
| grad_norm    | 2.05     |
| loss         | 0.0205   |
| loss_cal     | 0.0122   |
| loss_cal_q3  | 0.0122   |
| loss_diff    | 0.0205   |
| loss_diff_q3 | 0.0205   |
| loss_q3      | 0.0205   |
| param_norm   | 228      |
| samples      | 953      |
| step         | 952      |
---------------------------
---------------------------
| grad_norm    | 1.39     |
| loss         | 0.0387   |
| loss_cal     | 0.0215   |
| loss_cal_q3  | 0.0215   |
| loss_diff    | 0.0387   |
| loss_diff_q3 | 0.0387   |
| loss_q3      | 0.0387   |
| param_norm   | 228      |
| samples      | 954      |
| step         | 953      |
---------------------------
---------------------------
| grad_norm    | 1.62     |
| loss         | 0.0988   |
| loss_cal     | 0.0127   |
| loss_cal_q0  | 0.0127   |
| loss_diff    | 0.0988   |
| loss_diff_q0 | 0.0988   |
| loss_q0      | 0.0988   |
| param_norm   | 228      |
| samples      | 955      |
| step         | 954      |
---------------------------
---------------------------
| grad_norm    | 0.895    |
| loss         | 0.0419   |
| loss_cal     | 0.0124   |
| loss_cal_q3  | 0.0124   |
| loss_diff    | 0.0419   |
| loss_diff_q3 | 0.0419   |
| loss_q3      | 0.0419   |
| param_norm   | 228      |
| samples      | 956      |
| step         | 955      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.25     |
| loss         | 0.238    |
| loss_cal     | 0.0137   |
| loss_cal_q0  | 0.0137   |
| loss_diff    | 0.238    |
| loss_diff_q0 | 0.238    |
| loss_q0      | 0.238    |
| param_norm   | 228      |
| samples      | 957      |
| step         | 956      |
---------------------------
---------------------------
| grad_norm    | 1.9      |
| loss         | 0.0681   |
| loss_cal     | 0.0148   |
| loss_cal_q1  | 0.0148   |
| loss_diff    | 0.0681   |
| loss_diff_q1 | 0.0681   |
| loss_q1      | 0.0681   |
| param_norm   | 228      |
| samples      | 958      |
| step         | 957      |
---------------------------
---------------------------
| grad_norm    | 1.58     |
| loss         | 0.0666   |
| loss_cal     | 0.0135   |
| loss_cal_q2  | 0.0135   |
| loss_diff    | 0.0666   |
| loss_diff_q2 | 0.0666   |
| loss_q2      | 0.0666   |
| param_norm   | 228      |
| samples      | 959      |
| step         | 958      |
---------------------------
---------------------------
| grad_norm    | 1.96     |
| loss         | 0.0892   |
| loss_cal     | 0.0297   |
| loss_cal_q2  | 0.0297   |
| loss_diff    | 0.0892   |
| loss_diff_q2 | 0.0892   |
| loss_q2      | 0.0892   |
| param_norm   | 228      |
| samples      | 960      |
| step         | 959      |
---------------------------
---------------------------
| grad_norm    | 1.66     |
| loss         | 0.0213   |
| loss_cal     | 0.0117   |
| loss_cal_q3  | 0.0117   |
| loss_diff    | 0.0213   |
| loss_diff_q3 | 0.0213   |
| loss_q3      | 0.0213   |
| param_norm   | 228      |
| samples      | 961      |
| step         | 960      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.71     |
| loss         | 0.142    |
| loss_cal     | 0.0172   |
| loss_cal_q0  | 0.0172   |
| loss_diff    | 0.142    |
| loss_diff_q0 | 0.142    |
| loss_q0      | 0.142    |
| param_norm   | 228      |
| samples      | 962      |
| step         | 961      |
---------------------------
---------------------------
| grad_norm    | 1.54     |
| loss         | 0.0394   |
| loss_cal     | 0.0151   |
| loss_cal_q2  | 0.0151   |
| loss_diff    | 0.0394   |
| loss_diff_q2 | 0.0394   |
| loss_q2      | 0.0394   |
| param_norm   | 228      |
| samples      | 963      |
| step         | 962      |
---------------------------
---------------------------
| grad_norm    | 2.23     |
| loss         | 0.106    |
| loss_cal     | 0.013    |
| loss_cal_q0  | 0.013    |
| loss_diff    | 0.106    |
| loss_diff_q0 | 0.106    |
| loss_q0      | 0.106    |
| param_norm   | 228      |
| samples      | 964      |
| step         | 963      |
---------------------------
---------------------------
| grad_norm    | 2.16     |
| loss         | 0.0543   |
| loss_cal     | 0.0184   |
| loss_cal_q1  | 0.0184   |
| loss_diff    | 0.0543   |
| loss_diff_q1 | 0.0543   |
| loss_q1      | 0.0543   |
| param_norm   | 228      |
| samples      | 965      |
| step         | 964      |
---------------------------
---------------------------
| grad_norm    | 1.23     |
| loss         | 0.0754   |
| loss_cal     | 0.0132   |
| loss_cal_q3  | 0.0132   |
| loss_diff    | 0.0754   |
| loss_diff_q3 | 0.0754   |
| loss_q3      | 0.0754   |
| param_norm   | 228      |
| samples      | 966      |
| step         | 965      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 14.2     |
| loss         | 0.453    |
| loss_cal     | 0.0453   |
| loss_cal_q0  | 0.0453   |
| loss_diff    | 0.453    |
| loss_diff_q0 | 0.453    |
| loss_q0      | 0.453    |
| param_norm   | 228      |
| samples      | 967      |
| step         | 966      |
---------------------------
---------------------------
| grad_norm    | 2.92     |
| loss         | 0.122    |
| loss_cal     | 0.03     |
| loss_cal_q3  | 0.03     |
| loss_diff    | 0.122    |
| loss_diff_q3 | 0.122    |
| loss_q3      | 0.122    |
| param_norm   | 228      |
| samples      | 968      |
| step         | 967      |
---------------------------
---------------------------
| grad_norm    | 4.75     |
| loss         | 0.136    |
| loss_cal     | 0.0133   |
| loss_cal_q2  | 0.0133   |
| loss_diff    | 0.136    |
| loss_diff_q2 | 0.136    |
| loss_q2      | 0.136    |
| param_norm   | 228      |
| samples      | 969      |
| step         | 968      |
---------------------------
---------------------------
| grad_norm    | 6.32     |
| loss         | 0.287    |
| loss_cal     | 0.0315   |
| loss_cal_q1  | 0.0315   |
| loss_diff    | 0.287    |
| loss_diff_q1 | 0.287    |
| loss_q1      | 0.287    |
| param_norm   | 228      |
| samples      | 970      |
| step         | 969      |
---------------------------
---------------------------
| grad_norm    | 2.4      |
| loss         | 0.0767   |
| loss_cal     | 0.0136   |
| loss_cal_q2  | 0.0136   |
| loss_diff    | 0.0767   |
| loss_diff_q2 | 0.0767   |
| loss_q2      | 0.0767   |
| param_norm   | 228      |
| samples      | 971      |
| step         | 970      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 2.91     |
| loss         | 0.0199   |
| loss_cal     | 0.0117   |
| loss_cal_q2  | 0.0117   |
| loss_diff    | 0.0199   |
| loss_diff_q2 | 0.0199   |
| loss_q2      | 0.0199   |
| param_norm   | 228      |
| samples      | 972      |
| step         | 971      |
---------------------------
---------------------------
| grad_norm    | 0.871    |
| loss         | 0.0319   |
| loss_cal     | 0.0124   |
| loss_cal_q3  | 0.0124   |
| loss_diff    | 0.0319   |
| loss_diff_q3 | 0.0319   |
| loss_q3      | 0.0319   |
| param_norm   | 228      |
| samples      | 973      |
| step         | 972      |
---------------------------
---------------------------
| grad_norm    | 2.14     |
| loss         | 0.021    |
| loss_cal     | 0.0116   |
| loss_cal_q3  | 0.0116   |
| loss_diff    | 0.021    |
| loss_diff_q3 | 0.021    |
| loss_q3      | 0.021    |
| param_norm   | 228      |
| samples      | 974      |
| step         | 973      |
---------------------------
---------------------------
| grad_norm    | 0.765    |
| loss         | 0.04     |
| loss_cal     | 0.012    |
| loss_cal_q3  | 0.012    |
| loss_diff    | 0.04     |
| loss_diff_q3 | 0.04     |
| loss_q3      | 0.04     |
| param_norm   | 228      |
| samples      | 975      |
| step         | 974      |
---------------------------
---------------------------
| grad_norm    | 2.32     |
| loss         | 0.1      |
| loss_cal     | 0.0428   |
| loss_cal_q1  | 0.0428   |
| loss_diff    | 0.1      |
| loss_diff_q1 | 0.1      |
| loss_q1      | 0.1      |
| param_norm   | 228      |
| samples      | 976      |
| step         | 975      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.23     |
| loss         | 0.0191   |
| loss_cal     | 0.0116   |
| loss_cal_q2  | 0.0116   |
| loss_diff    | 0.0191   |
| loss_diff_q2 | 0.0191   |
| loss_q2      | 0.0191   |
| param_norm   | 228      |
| samples      | 977      |
| step         | 976      |
---------------------------
---------------------------
| grad_norm    | 2.56     |
| loss         | 0.262    |
| loss_cal     | 0.0248   |
| loss_cal_q1  | 0.0248   |
| loss_diff    | 0.262    |
| loss_diff_q1 | 0.262    |
| loss_q1      | 0.262    |
| param_norm   | 228      |
| samples      | 978      |
| step         | 977      |
---------------------------
---------------------------
| grad_norm    | 1.76     |
| loss         | 0.0671   |
| loss_cal     | 0.0404   |
| loss_cal_q3  | 0.0404   |
| loss_diff    | 0.0671   |
| loss_diff_q3 | 0.0671   |
| loss_q3      | 0.0671   |
| param_norm   | 228      |
| samples      | 979      |
| step         | 978      |
---------------------------
---------------------------
| grad_norm    | 2.35     |
| loss         | 0.123    |
| loss_cal     | 0.0122   |
| loss_cal_q0  | 0.0122   |
| loss_diff    | 0.123    |
| loss_diff_q0 | 0.123    |
| loss_q0      | 0.123    |
| param_norm   | 228      |
| samples      | 980      |
| step         | 979      |
---------------------------
---------------------------
| grad_norm    | 1.57     |
| loss         | 0.118    |
| loss_cal     | 0.0136   |
| loss_cal_q3  | 0.0136   |
| loss_diff    | 0.118    |
| loss_diff_q3 | 0.118    |
| loss_q3      | 0.118    |
| param_norm   | 228      |
| samples      | 981      |
| step         | 980      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 0.635    |
| loss         | 0.0195   |
| loss_cal     | 0.0122   |
| loss_cal_q3  | 0.0122   |
| loss_diff    | 0.0195   |
| loss_diff_q3 | 0.0195   |
| loss_q3      | 0.0195   |
| param_norm   | 228      |
| samples      | 982      |
| step         | 981      |
---------------------------
---------------------------
| grad_norm    | 0.72     |
| loss         | 0.0261   |
| loss_cal     | 0.0128   |
| loss_cal_q2  | 0.0128   |
| loss_diff    | 0.0261   |
| loss_diff_q2 | 0.0261   |
| loss_q2      | 0.0261   |
| param_norm   | 228      |
| samples      | 983      |
| step         | 982      |
---------------------------
---------------------------
| grad_norm    | 1.92     |
| loss         | 0.0174   |
| loss_cal     | 0.0114   |
| loss_cal_q0  | 0.0114   |
| loss_diff    | 0.0174   |
| loss_diff_q0 | 0.0174   |
| loss_q0      | 0.0174   |
| param_norm   | 228      |
| samples      | 984      |
| step         | 983      |
---------------------------
---------------------------
| grad_norm    | 2.97     |
| loss         | 0.0867   |
| loss_cal     | 0.0137   |
| loss_cal_q3  | 0.0137   |
| loss_diff    | 0.0867   |
| loss_diff_q3 | 0.0867   |
| loss_q3      | 0.0867   |
| param_norm   | 228      |
| samples      | 985      |
| step         | 984      |
---------------------------
---------------------------
| grad_norm    | 3.93     |
| loss         | 0.133    |
| loss_cal     | 0.0456   |
| loss_cal_q0  | 0.0456   |
| loss_diff    | 0.133    |
| loss_diff_q0 | 0.133    |
| loss_q0      | 0.133    |
| param_norm   | 228      |
| samples      | 986      |
| step         | 985      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 4.04     |
| loss         | 0.284    |
| loss_cal     | 0.0401   |
| loss_cal_q0  | 0.0401   |
| loss_diff    | 0.284    |
| loss_diff_q0 | 0.284    |
| loss_q0      | 0.284    |
| param_norm   | 228      |
| samples      | 987      |
| step         | 986      |
---------------------------
---------------------------
| grad_norm    | 2.75     |
| loss         | 0.0621   |
| loss_cal     | 0.062    |
| loss_cal_q2  | 0.062    |
| loss_diff    | 0.0621   |
| loss_diff_q2 | 0.0621   |
| loss_q2      | 0.0621   |
| param_norm   | 228      |
| samples      | 988      |
| step         | 987      |
---------------------------
---------------------------
| grad_norm    | 1.48     |
| loss         | 0.0472   |
| loss_cal     | 0.0134   |
| loss_cal_q1  | 0.0134   |
| loss_diff    | 0.0472   |
| loss_diff_q1 | 0.0472   |
| loss_q1      | 0.0472   |
| param_norm   | 228      |
| samples      | 989      |
| step         | 988      |
---------------------------
---------------------------
| grad_norm    | 2.03     |
| loss         | 0.107    |
| loss_cal     | 0.0149   |
| loss_cal_q2  | 0.0149   |
| loss_diff    | 0.107    |
| loss_diff_q2 | 0.107    |
| loss_q2      | 0.107    |
| param_norm   | 228      |
| samples      | 990      |
| step         | 989      |
---------------------------
---------------------------
| grad_norm    | 2.76     |
| loss         | 0.181    |
| loss_cal     | 0.0806   |
| loss_cal_q2  | 0.0806   |
| loss_diff    | 0.181    |
| loss_diff_q2 | 0.181    |
| loss_q2      | 0.181    |
| param_norm   | 228      |
| samples      | 991      |
| step         | 990      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 3.15     |
| loss         | 0.169    |
| loss_cal     | 0.0128   |
| loss_cal_q1  | 0.0128   |
| loss_diff    | 0.169    |
| loss_diff_q1 | 0.169    |
| loss_q1      | 0.169    |
| param_norm   | 228      |
| samples      | 992      |
| step         | 991      |
---------------------------
---------------------------
| grad_norm    | 2.21     |
| loss         | 0.111    |
| loss_cal     | 0.0169   |
| loss_cal_q1  | 0.0169   |
| loss_diff    | 0.111    |
| loss_diff_q1 | 0.111    |
| loss_q1      | 0.111    |
| param_norm   | 228      |
| samples      | 993      |
| step         | 992      |
---------------------------
---------------------------
| grad_norm    | 2.71     |
| loss         | 0.0191   |
| loss_cal     | 0.0112   |
| loss_cal_q2  | 0.0112   |
| loss_diff    | 0.0191   |
| loss_diff_q2 | 0.0191   |
| loss_q2      | 0.0191   |
| param_norm   | 228      |
| samples      | 994      |
| step         | 993      |
---------------------------
---------------------------
| grad_norm    | 3.47     |
| loss         | 0.0749   |
| loss_cal     | 0.0282   |
| loss_cal_q3  | 0.0282   |
| loss_diff    | 0.0749   |
| loss_diff_q3 | 0.0749   |
| loss_q3      | 0.0749   |
| param_norm   | 228      |
| samples      | 995      |
| step         | 994      |
---------------------------
---------------------------
| grad_norm    | 2.24     |
| loss         | 0.0504   |
| loss_cal     | 0.0122   |
| loss_cal_q0  | 0.0122   |
| loss_diff    | 0.0504   |
| loss_diff_q0 | 0.0504   |
| loss_q0      | 0.0504   |
| param_norm   | 228      |
| samples      | 996      |
| step         | 995      |
---------------------------
saving model 0...
saving model 0.9999...
---------------------------
| grad_norm    | 1.62     |
| loss         | 0.0173   |
| loss_cal     | 0.0114   |
| loss_cal_q1  | 0.0114   |
| loss_diff    | 0.0173   |
| loss_diff_q1 | 0.0173   |
| loss_q1      | 0.0173   |
| param_norm   | 228      |
| samples      | 997      |
| step         | 996      |
---------------------------
---------------------------
| grad_norm    | 2.5      |
| loss         | 0.0893   |
| loss_cal     | 0.0222   |
| loss_cal_q3  | 0.0222   |
| loss_diff    | 0.0893   |
| loss_diff_q3 | 0.0893   |
| loss_q3      | 0.0893   |
| param_norm   | 228      |
| samples      | 998      |
| step         | 997      |
---------------------------
---------------------------
| grad_norm    | 3.78     |
| loss         | 0.129    |
| loss_cal     | 0.0489   |
| loss_cal_q2  | 0.0489   |
| loss_diff    | 0.129    |
| loss_diff_q2 | 0.129    |
| loss_q2      | 0.129    |
| param_norm   | 228      |
| samples      | 999      |
| step         | 998      |
---------------------------
---------------------------
| grad_norm    | 1.43     |
| loss         | 0.0575   |
| loss_cal     | 0.0122   |
| loss_cal_q3  | 0.0122   |
| loss_diff    | 0.0575   |
| loss_diff_q3 | 0.0575   |
| loss_q3      | 0.0575   |
| param_norm   | 228      |
| samples      | 1e+03    |
| step         | 999      |
---------------------------
saving model 0...
saving model 0.9999...
